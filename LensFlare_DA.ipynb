{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Flare.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "metadata": {
      "interpreter": {
        "hash": "234cb04ac017d0352c57f5e1411e2bf9405af2737b8ada6cd6e111c1134dd379"
      }
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSFGYaIDG6f0"
      },
      "source": [
        "Cutout Data Augmentation.\n",
        "\n",
        "This code is implmented by following the official code (https://github.com/uoguelph-mlrg/Cutout)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCVSE5-UboYl"
      },
      "source": [
        "##**Import all neceassary packages**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YBMwPsubsbX"
      },
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import torch.backends.cudnn as cudnn\n",
        "from torch.optim.lr_scheduler import MultiStepLR\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "from tqdm.notebook import tqdm as tqdm\n",
        "\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "writer = SummaryWriter()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L88afYXKMSdL"
      },
      "source": [
        "##**Model - Define ResNet Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMFSLTnkMQdq"
      },
      "source": [
        "'''ResNet18/34/50/101/152 in Pytorch.'''\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = conv3x3(in_planes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = conv3x3(3,64)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def ResNet18(num_classes=10):\n",
        "    return ResNet(BasicBlock, [2,2,2,2], num_classes)\n",
        "\n",
        "def ResNet34(num_classes=10):\n",
        "    return ResNet(BasicBlock, [3,4,6,3], num_classes)\n",
        "\n",
        "def ResNet50(num_classes=10):\n",
        "    return ResNet(Bottleneck, [3,4,6,3], num_classes)\n",
        "\n",
        "def ResNet101(num_classes=10):\n",
        "    return ResNet(Bottleneck, [3,4,23,3], num_classes)\n",
        "\n",
        "def ResNet152(num_classes=10):\n",
        "    return ResNet(Bottleneck, [3,8,36,3], num_classes)\n",
        "\n",
        "def test_resnet():\n",
        "    net = ResNet50()\n",
        "    y = net(Variable(torch.randn(1,3,32,32)))\n",
        "    print(y.size())\n",
        "\n",
        "# test_resnet()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjM3cl279Lvg"
      },
      "source": [
        "##**Utils**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIvuSgE49Kvu"
      },
      "source": [
        "class AverageMeter(object):\n",
        "    r\"\"\"Computes and stores the average and current value\n",
        "    \"\"\"\n",
        "    def __init__(self, name, fmt=':f'):\n",
        "        self.name = name\n",
        "        self.fmt = fmt\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "    def __str__(self):\n",
        "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
        "        return fmtstr.format(**self.__dict__)\n",
        "\n",
        "\n",
        "class ProgressMeter(object):\n",
        "    def __init__(self, num_batches, *meters, prefix=\"\"):\n",
        "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
        "        self.meters = meters\n",
        "        self.prefix = prefix\n",
        "\n",
        "    def print(self, batch):\n",
        "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
        "        entries += [str(meter) for meter in self.meters]\n",
        "        print('\\t'.join(entries))\n",
        "\n",
        "    def _get_batch_fmtstr(self, num_batches):\n",
        "        num_digits = len(str(num_batches // 1))\n",
        "        fmt = '{:' + str(num_digits) + 'd}'\n",
        "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n",
        "\n",
        "\n",
        "def accuracy(output, target, topk=(1,)):\n",
        "    r\"\"\"Computes the accuracy over the $k$ top predictions for the specified values of k\n",
        "    \"\"\"\n",
        "    with torch.no_grad():\n",
        "        maxk = max(topk)\n",
        "        batch_size = target.size(0)\n",
        "\n",
        "        # _, pred = output.topk(maxk, 1, True, True)\n",
        "        # pred = pred.t()\n",
        "        # correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "        # faster topk (ref: https://github.com/pytorch/pytorch/issues/22812)\n",
        "        _, idx = output.sort(descending=True)\n",
        "        pred = idx[:,:maxk]\n",
        "        pred = pred.t()\n",
        "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "        res = []\n",
        "        for k in topk:\n",
        "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
        "            res.append(correct_k.mul_(100.0 / batch_size))\n",
        "        return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_A6X8IBmJlAi"
      },
      "source": [
        "# **Flare: Main Code for Applying Flare data augmentation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9X4ZwepWuG7u"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "class Flare(object):\n",
        "    \"\"\"Randomly creates flare on an image.\n",
        "\n",
        "    Args:\n",
        "        n_circles (int): Number of lens flare circles on each image.\n",
        "    \"\"\"\n",
        "    def __init__(self, n_circles):\n",
        "        self.n_circles = n_circles\n",
        "\n",
        "    def __call__(self, img):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            img (PIL): PIL image.\n",
        "        Returns:\n",
        "            PIL: Image with randomly generated lens flare effect.\n",
        "        \"\"\"\n",
        "        img = np.array(img) #PIL image를 numpy array로 변환\n",
        "        h, w, _ = img.shape #image의 height, width 추출\n",
        "\n",
        "        overlay = img.copy() #image와 합칠 overlay 레이어 선언\n",
        "\n",
        "        max_r = min(h,w)//6 #원의 최대 반지름을 제한\n",
        "        gradient = np.random.randint(h)/np.random.randint(1,w) #top-left corner와 random pixel의 gradient\n",
        "        alpha = 0.3 #overlay의 투명도, 즉 원들의 투명도\n",
        "\n",
        "        for _ in range(self.n_circles): #선언한 flare circle의 수 만큼 반복\n",
        "          x = np.random.randint(w) #random한 x좌표 선택\n",
        "          center = (int(gradient*x), x) #원의 중심 좌표 설정\n",
        "\n",
        "          c = np.random.randint(190,255) #원의 색(grey) 설정\n",
        "          cv2.circle(overlay, center, np.random.randint(max_r), (c,c,c), -1) #overlay 레이어 위에 원을 그림\n",
        "\n",
        "        img = cv2.addWeighted(overlay, alpha, img, 1-alpha, 0) #overlay에 투명도 부여 후 원본 image와 합성\n",
        "        img = Image.fromarray(img) #numpy array를 PIL image로 변환\n",
        "\n",
        "        return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9s8oXpzdMvol"
      },
      "source": [
        "##**Parameter Settings**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pjeqawi9cNK6"
      },
      "source": [
        "dataset = 'cifar100' # cifar10 or cifar100\n",
        "model = 'resnet34' # resnet18, resnet50, resnet101\n",
        "batch_size = 128  # Input batch size for training (default: 128)\n",
        "epochs = 150 # Number of epochs to train (default: 200)\n",
        "learning_rate = 0.1 # Learning rate\n",
        "data_augmentation = True # Traditional data augmentation such as augmantation by flipping and cropping?\n",
        "flare = True # Apply Flare? ###new parameter for flare-DA\n",
        "#n_holes = 1 # Number of holes to cut out from image ###not needed\n",
        "#length = 16 # Length of the holes ###not needed\n",
        "seed = 0 # Random seed (default: 0)\n",
        "print_freq = 30\n",
        "cuda = torch.cuda.is_available()\n",
        "cudnn.benchmark = True  # Should make training should go faster for large models\n",
        "\n",
        "torch.manual_seed(seed)\n",
        "if cuda:\n",
        "    torch.cuda.manual_seed(seed)\n",
        "\n",
        "test_id = dataset + '_' + model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXL_PBj6cVoe"
      },
      "source": [
        "##**Load and preprocess data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvQjH3T9caYs",
        "outputId": "c8f9988d-cfec-4c88-d13d-1df3744874e8"
      },
      "source": [
        "# Image Preprocessing\n",
        "normalize = transforms.Normalize(mean=[x / 255.0 for x in [125.3, 123.0, 113.9]],\n",
        "                                     std=[x / 255.0 for x in [63.0, 62.1, 66.7]])\n",
        "\n",
        "train_transform = transforms.Compose([])\n",
        "if flare:\n",
        "    train_transform.transforms.append(Flare(n_circles=16))\n",
        "if data_augmentation:\n",
        "    train_transform.transforms.append(transforms.RandomCrop(32, padding=4))\n",
        "    train_transform.transforms.append(transforms.RandomHorizontalFlip())\n",
        "train_transform.transforms.append(transforms.ToTensor())\n",
        "train_transform.transforms.append(normalize)\n",
        "\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    normalize])\n",
        "\n",
        "if dataset == 'cifar10':\n",
        "    num_classes = 10\n",
        "    train_dataset = datasets.CIFAR10(root='data/',\n",
        "                                     train=True,\n",
        "                                     transform=train_transform,\n",
        "                                     download=True)\n",
        "\n",
        "    test_dataset = datasets.CIFAR10(root='data/',\n",
        "                                    train=False,\n",
        "                                    transform=test_transform,\n",
        "                                    download=True)\n",
        "elif dataset == 'cifar100':\n",
        "    num_classes = 100\n",
        "    train_dataset = datasets.CIFAR100(root='data/',\n",
        "                                      train=True,\n",
        "                                      transform=train_transform,\n",
        "                                      download=True)\n",
        "\n",
        "    test_dataset = datasets.CIFAR100(root='data/',\n",
        "                                     train=False,\n",
        "                                     transform=test_transform,\n",
        "                                     download=True)\n",
        "\n",
        "\n",
        "# Data Loader (Input Pipeline)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True,\n",
        "                                           pin_memory=True,\n",
        "                                           num_workers=2)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False,\n",
        "                                          pin_memory=True,\n",
        "                                          num_workers=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gITLQIAr9lAZ"
      },
      "source": [
        "##**Main Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0-lYvAp9oHA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d8845a7-33a2-4cee-ba71-630da7f77465"
      },
      "source": [
        "def train(train_loader, epoch, model, optimizer, criterion):\n",
        "    batch_time = AverageMeter('Time', ':6.3f')\n",
        "    losses = AverageMeter('Loss', ':.4e')\n",
        "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
        "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
        "    progress = ProgressMeter(len(train_loader), batch_time, losses,\n",
        "                             top1, top5, prefix=\"Epoch: [{}]\".format(epoch))\n",
        "    # switch to train mode\n",
        "    model.train()\n",
        "\n",
        "    end = time.time()\n",
        "    for i, (input, target) in enumerate(train_loader):\n",
        "        # measure data loading time\n",
        "        input = input.cuda()\n",
        "        target = target.cuda()\n",
        "\n",
        "        # compute output\n",
        "        output = model(input)\n",
        "        loss = criterion(output, target)\n",
        "        writer.add_scalar(\"Loss/train\", loss, epoch)\n",
        "\n",
        "        # measure accuracy and record loss, accuracy \n",
        "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
        "        losses.update(loss.item(), input.size(0))\n",
        "        top1.update(acc1[0].item(), input.size(0))\n",
        "        top5.update(acc5[0].item(), input.size(0))\n",
        "\n",
        "        # compute gradient and do SGD step\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        if i % print_freq == 0:\n",
        "            progress.print(i)\n",
        "\n",
        "    print('==> Train Accuracy: Acc@1 {top1.avg:.3f} || Acc@5 {top5.avg:.3f}'.format(top1=top1, top5=top5))\n",
        "    return top1.avg\n",
        "\n",
        "def test(test_loader,epoch, model):\n",
        "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
        "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
        "    model.eval()\n",
        "    for i,(input,target) in enumerate(test_loader):\n",
        "        input = input.cuda()\n",
        "        target = target.cuda()\n",
        "\n",
        "        output = model(input)\n",
        "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
        "        top1.update(acc1[0].item(), input.size(0))\n",
        "        top5.update(acc5[0].item(), input.size(0))\n",
        "    print('==> Test Accuracy:  Acc@1 {top1.avg:.3f} || Acc@5 {top5.avg:.3f}'.format(top1=top1, top5=top5))\n",
        "    return top1.avg\n",
        "\n",
        "model = ResNet34(num_classes=num_classes).cuda()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate,momentum=0.9, nesterov=True, weight_decay=5e-4)\n",
        "\n",
        "scheduler = MultiStepLR(optimizer, milestones=[60, 90, 120], gamma=0.2)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss().cuda()\n",
        "###########################################################\n",
        "best_acc = 0\n",
        "for epoch in range(epochs):\n",
        "    print(\"\\n----- epoch: {}, lr: {} -----\".format(\n",
        "        epoch, optimizer.param_groups[0][\"lr\"]))\n",
        "\n",
        "    # train for one epoch\n",
        "    start_time = time.time()\n",
        "    train(train_loader, epoch, model, optimizer, criterion)\n",
        "    test_acc = test(test_loader,epoch,model)\n",
        "\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print('==> {:.2f} seconds to train this epoch\\n'.format(elapsed_time))\n",
        "    # learning rate scheduling\n",
        "    scheduler.step()\n",
        "    \n",
        "    # Save model for best accuracy\n",
        "    if best_acc < test_acc:\n",
        "        best_acc = test_acc\n",
        "        torch.save(model.state_dict(), 'model_best.pt')\n",
        "\n",
        "torch.save(model.state_dict(),'model_latest.pt')\n",
        "print(f\"Best Top-1 Accuracy: {best_acc}\")\n",
        "\n",
        "writer.flush()\n",
        "writer.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "----- epoch: 0, lr: 0.1 -----\n",
            "Epoch: [0][  0/391]\tTime  1.007 ( 1.007)\tLoss 4.7382e+00 (4.7382e+00)\tAcc@1   1.56 (  1.56)\tAcc@5   4.69 (  4.69)\n",
            "Epoch: [0][ 30/391]\tTime  0.090 ( 0.121)\tLoss 4.6213e+00 (5.2330e+00)\tAcc@1   1.56 (  1.44)\tAcc@5   6.25 (  5.97)\n",
            "Epoch: [0][ 60/391]\tTime  0.088 ( 0.107)\tLoss 4.5296e+00 (4.9275e+00)\tAcc@1   3.12 (  1.61)\tAcc@5   8.59 (  6.72)\n",
            "Epoch: [0][ 90/391]\tTime  0.098 ( 0.103)\tLoss 4.2295e+00 (4.7520e+00)\tAcc@1   7.81 (  2.25)\tAcc@5  18.75 (  9.09)\n",
            "Epoch: [0][120/391]\tTime  0.093 ( 0.100)\tLoss 4.1721e+00 (4.6325e+00)\tAcc@1   7.03 (  2.80)\tAcc@5  21.88 ( 11.12)\n",
            "Epoch: [0][150/391]\tTime  0.093 ( 0.099)\tLoss 4.1445e+00 (4.5420e+00)\tAcc@1   6.25 (  3.25)\tAcc@5  20.31 ( 12.93)\n",
            "Epoch: [0][180/391]\tTime  0.091 ( 0.098)\tLoss 4.0896e+00 (4.4700e+00)\tAcc@1   3.91 (  3.54)\tAcc@5  17.97 ( 14.31)\n",
            "Epoch: [0][210/391]\tTime  0.089 ( 0.097)\tLoss 4.0430e+00 (4.4078e+00)\tAcc@1   7.03 (  3.84)\tAcc@5  25.78 ( 15.67)\n",
            "Epoch: [0][240/391]\tTime  0.092 ( 0.096)\tLoss 4.0628e+00 (4.3581e+00)\tAcc@1   7.81 (  4.31)\tAcc@5  25.00 ( 16.92)\n",
            "Epoch: [0][270/391]\tTime  0.079 ( 0.096)\tLoss 4.0325e+00 (4.3161e+00)\tAcc@1   5.47 (  4.70)\tAcc@5  20.31 ( 17.93)\n",
            "Epoch: [0][300/391]\tTime  0.091 ( 0.096)\tLoss 3.8249e+00 (4.2775e+00)\tAcc@1  10.94 (  5.12)\tAcc@5  39.06 ( 18.95)\n",
            "Epoch: [0][330/391]\tTime  0.091 ( 0.095)\tLoss 4.1477e+00 (4.2455e+00)\tAcc@1   5.47 (  5.43)\tAcc@5  20.31 ( 19.77)\n",
            "Epoch: [0][360/391]\tTime  0.088 ( 0.095)\tLoss 3.8765e+00 (4.2155e+00)\tAcc@1   7.03 (  5.70)\tAcc@5  23.44 ( 20.64)\n",
            "Epoch: [0][390/391]\tTime  0.495 ( 0.096)\tLoss 3.8870e+00 (4.1887e+00)\tAcc@1  13.75 (  5.96)\tAcc@5  30.00 ( 21.40)\n",
            "==> Train Accuracy: Acc@1 5.964 || Acc@5 21.404\n",
            "==> Test Accuracy:  Acc@1 10.730 || Acc@5 33.660\n",
            "==> 40.11 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 1, lr: 0.1 -----\n",
            "Epoch: [1][  0/391]\tTime  0.266 ( 0.266)\tLoss 3.8649e+00 (3.8649e+00)\tAcc@1   7.81 (  7.81)\tAcc@5  24.22 ( 24.22)\n",
            "Epoch: [1][ 30/391]\tTime  0.102 ( 0.101)\tLoss 3.6262e+00 (3.7608e+00)\tAcc@1  14.84 ( 11.09)\tAcc@5  34.38 ( 34.30)\n",
            "Epoch: [1][ 60/391]\tTime  0.093 ( 0.098)\tLoss 3.7028e+00 (3.7478e+00)\tAcc@1   9.38 ( 11.13)\tAcc@5  34.38 ( 34.35)\n",
            "Epoch: [1][ 90/391]\tTime  0.093 ( 0.096)\tLoss 3.6300e+00 (3.7364e+00)\tAcc@1  14.06 ( 11.18)\tAcc@5  39.84 ( 34.48)\n",
            "Epoch: [1][120/391]\tTime  0.091 ( 0.095)\tLoss 3.7967e+00 (3.7274e+00)\tAcc@1  12.50 ( 11.20)\tAcc@5  32.81 ( 34.67)\n",
            "Epoch: [1][150/391]\tTime  0.093 ( 0.095)\tLoss 3.4757e+00 (3.7173e+00)\tAcc@1  12.50 ( 11.26)\tAcc@5  43.75 ( 35.13)\n",
            "Epoch: [1][180/391]\tTime  0.088 ( 0.094)\tLoss 3.6239e+00 (3.7081e+00)\tAcc@1  14.84 ( 11.40)\tAcc@5  34.38 ( 35.36)\n",
            "Epoch: [1][210/391]\tTime  0.092 ( 0.094)\tLoss 3.4408e+00 (3.6909e+00)\tAcc@1  14.84 ( 11.70)\tAcc@5  41.41 ( 35.78)\n",
            "Epoch: [1][240/391]\tTime  0.091 ( 0.094)\tLoss 3.4074e+00 (3.6753e+00)\tAcc@1  14.06 ( 12.06)\tAcc@5  44.53 ( 36.25)\n",
            "Epoch: [1][270/391]\tTime  0.102 ( 0.094)\tLoss 3.5234e+00 (3.6546e+00)\tAcc@1  12.50 ( 12.40)\tAcc@5  41.41 ( 36.91)\n",
            "Epoch: [1][300/391]\tTime  0.091 ( 0.094)\tLoss 3.4271e+00 (3.6382e+00)\tAcc@1  13.28 ( 12.72)\tAcc@5  41.41 ( 37.34)\n",
            "Epoch: [1][330/391]\tTime  0.094 ( 0.094)\tLoss 3.4046e+00 (3.6250e+00)\tAcc@1  17.97 ( 12.97)\tAcc@5  44.53 ( 37.80)\n",
            "Epoch: [1][360/391]\tTime  0.089 ( 0.093)\tLoss 3.5649e+00 (3.6104e+00)\tAcc@1  16.41 ( 13.28)\tAcc@5  37.50 ( 38.27)\n",
            "Epoch: [1][390/391]\tTime  0.079 ( 0.093)\tLoss 3.4429e+00 (3.5933e+00)\tAcc@1  18.75 ( 13.61)\tAcc@5  42.50 ( 38.81)\n",
            "==> Train Accuracy: Acc@1 13.612 || Acc@5 38.806\n",
            "==> Test Accuracy:  Acc@1 18.180 || Acc@5 45.310\n",
            "==> 38.99 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 2, lr: 0.1 -----\n",
            "Epoch: [2][  0/391]\tTime  0.285 ( 0.285)\tLoss 3.2882e+00 (3.2882e+00)\tAcc@1  21.09 ( 21.09)\tAcc@5  47.66 ( 47.66)\n",
            "Epoch: [2][ 30/391]\tTime  0.094 ( 0.101)\tLoss 3.3752e+00 (3.3347e+00)\tAcc@1  18.75 ( 17.79)\tAcc@5  45.31 ( 46.37)\n",
            "Epoch: [2][ 60/391]\tTime  0.094 ( 0.097)\tLoss 3.0014e+00 (3.3246e+00)\tAcc@1  28.91 ( 18.14)\tAcc@5  54.69 ( 46.66)\n",
            "Epoch: [2][ 90/391]\tTime  0.085 ( 0.095)\tLoss 3.4622e+00 (3.3131e+00)\tAcc@1  17.19 ( 18.52)\tAcc@5  39.84 ( 46.66)\n",
            "Epoch: [2][120/391]\tTime  0.098 ( 0.095)\tLoss 3.3883e+00 (3.2987e+00)\tAcc@1  21.09 ( 18.98)\tAcc@5  44.53 ( 47.09)\n",
            "Epoch: [2][150/391]\tTime  0.092 ( 0.094)\tLoss 3.1978e+00 (3.2874e+00)\tAcc@1  24.22 ( 19.14)\tAcc@5  55.47 ( 47.68)\n",
            "Epoch: [2][180/391]\tTime  0.097 ( 0.094)\tLoss 3.2311e+00 (3.2732e+00)\tAcc@1  25.78 ( 19.43)\tAcc@5  51.56 ( 48.10)\n",
            "Epoch: [2][210/391]\tTime  0.091 ( 0.094)\tLoss 3.2671e+00 (3.2639e+00)\tAcc@1  28.91 ( 19.71)\tAcc@5  45.31 ( 48.40)\n",
            "Epoch: [2][240/391]\tTime  0.091 ( 0.094)\tLoss 3.1365e+00 (3.2488e+00)\tAcc@1  22.66 ( 20.06)\tAcc@5  49.22 ( 48.82)\n",
            "Epoch: [2][270/391]\tTime  0.092 ( 0.094)\tLoss 2.8749e+00 (3.2319e+00)\tAcc@1  25.00 ( 20.40)\tAcc@5  54.69 ( 49.24)\n",
            "Epoch: [2][300/391]\tTime  0.102 ( 0.094)\tLoss 3.0811e+00 (3.2166e+00)\tAcc@1  23.44 ( 20.67)\tAcc@5  49.22 ( 49.61)\n",
            "Epoch: [2][330/391]\tTime  0.090 ( 0.094)\tLoss 2.9976e+00 (3.2068e+00)\tAcc@1  25.00 ( 20.83)\tAcc@5  55.47 ( 49.92)\n",
            "Epoch: [2][360/391]\tTime  0.091 ( 0.094)\tLoss 2.8735e+00 (3.1947e+00)\tAcc@1  26.56 ( 21.05)\tAcc@5  60.94 ( 50.28)\n",
            "Epoch: [2][390/391]\tTime  0.082 ( 0.094)\tLoss 2.9002e+00 (3.1819e+00)\tAcc@1  28.75 ( 21.28)\tAcc@5  55.00 ( 50.63)\n",
            "==> Train Accuracy: Acc@1 21.276 || Acc@5 50.628\n",
            "==> Test Accuracy:  Acc@1 25.370 || Acc@5 56.630\n",
            "==> 39.13 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 3, lr: 0.1 -----\n",
            "Epoch: [3][  0/391]\tTime  0.287 ( 0.287)\tLoss 2.8244e+00 (2.8244e+00)\tAcc@1  28.91 ( 28.91)\tAcc@5  55.47 ( 55.47)\n",
            "Epoch: [3][ 30/391]\tTime  0.089 ( 0.101)\tLoss 2.7737e+00 (2.9467e+00)\tAcc@1  24.22 ( 25.45)\tAcc@5  59.38 ( 57.41)\n",
            "Epoch: [3][ 60/391]\tTime  0.099 ( 0.097)\tLoss 2.8308e+00 (2.9454e+00)\tAcc@1  25.00 ( 25.93)\tAcc@5  61.72 ( 57.16)\n",
            "Epoch: [3][ 90/391]\tTime  0.092 ( 0.095)\tLoss 2.9941e+00 (2.9373e+00)\tAcc@1  23.44 ( 26.35)\tAcc@5  54.69 ( 56.99)\n",
            "Epoch: [3][120/391]\tTime  0.091 ( 0.095)\tLoss 3.1639e+00 (2.9393e+00)\tAcc@1  17.97 ( 26.01)\tAcc@5  46.09 ( 56.95)\n",
            "Epoch: [3][150/391]\tTime  0.095 ( 0.094)\tLoss 2.7817e+00 (2.9332e+00)\tAcc@1  27.34 ( 26.00)\tAcc@5  60.94 ( 57.10)\n",
            "Epoch: [3][180/391]\tTime  0.091 ( 0.094)\tLoss 3.0250e+00 (2.9231e+00)\tAcc@1  25.78 ( 26.33)\tAcc@5  52.34 ( 57.35)\n",
            "Epoch: [3][210/391]\tTime  0.091 ( 0.094)\tLoss 2.9320e+00 (2.9148e+00)\tAcc@1  26.56 ( 26.48)\tAcc@5  58.59 ( 57.72)\n",
            "Epoch: [3][240/391]\tTime  0.091 ( 0.094)\tLoss 3.0753e+00 (2.9039e+00)\tAcc@1  25.78 ( 26.71)\tAcc@5  54.69 ( 58.04)\n",
            "Epoch: [3][270/391]\tTime  0.089 ( 0.094)\tLoss 3.0096e+00 (2.8927e+00)\tAcc@1  20.31 ( 26.92)\tAcc@5  53.12 ( 58.21)\n",
            "Epoch: [3][300/391]\tTime  0.095 ( 0.094)\tLoss 2.7063e+00 (2.8826e+00)\tAcc@1  29.69 ( 27.04)\tAcc@5  61.72 ( 58.43)\n",
            "Epoch: [3][330/391]\tTime  0.092 ( 0.094)\tLoss 2.6728e+00 (2.8692e+00)\tAcc@1  32.03 ( 27.29)\tAcc@5  63.28 ( 58.73)\n",
            "Epoch: [3][360/391]\tTime  0.091 ( 0.093)\tLoss 2.6138e+00 (2.8598e+00)\tAcc@1  32.81 ( 27.42)\tAcc@5  66.41 ( 58.97)\n",
            "Epoch: [3][390/391]\tTime  0.084 ( 0.093)\tLoss 2.6618e+00 (2.8482e+00)\tAcc@1  33.75 ( 27.68)\tAcc@5  66.25 ( 59.26)\n",
            "==> Train Accuracy: Acc@1 27.682 || Acc@5 59.256\n",
            "==> Test Accuracy:  Acc@1 29.380 || Acc@5 61.580\n",
            "==> 39.11 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 4, lr: 0.1 -----\n",
            "Epoch: [4][  0/391]\tTime  0.315 ( 0.315)\tLoss 2.6157e+00 (2.6157e+00)\tAcc@1  35.16 ( 35.16)\tAcc@5  64.84 ( 64.84)\n",
            "Epoch: [4][ 30/391]\tTime  0.094 ( 0.106)\tLoss 2.8595e+00 (2.6440e+00)\tAcc@1  31.25 ( 32.23)\tAcc@5  60.94 ( 64.89)\n",
            "Epoch: [4][ 60/391]\tTime  0.114 ( 0.101)\tLoss 2.5448e+00 (2.6496e+00)\tAcc@1  35.94 ( 32.25)\tAcc@5  64.06 ( 64.25)\n",
            "Epoch: [4][ 90/391]\tTime  0.097 ( 0.100)\tLoss 2.5445e+00 (2.6354e+00)\tAcc@1  34.38 ( 32.46)\tAcc@5  65.62 ( 64.32)\n",
            "Epoch: [4][120/391]\tTime  0.105 ( 0.099)\tLoss 2.5604e+00 (2.6220e+00)\tAcc@1  30.47 ( 32.59)\tAcc@5  63.28 ( 64.46)\n",
            "Epoch: [4][150/391]\tTime  0.088 ( 0.099)\tLoss 2.5283e+00 (2.6141e+00)\tAcc@1  29.69 ( 32.62)\tAcc@5  65.62 ( 64.72)\n",
            "Epoch: [4][180/391]\tTime  0.099 ( 0.098)\tLoss 2.8720e+00 (2.6071e+00)\tAcc@1  33.59 ( 32.73)\tAcc@5  56.25 ( 64.72)\n",
            "Epoch: [4][210/391]\tTime  0.098 ( 0.098)\tLoss 2.5873e+00 (2.5991e+00)\tAcc@1  35.94 ( 32.88)\tAcc@5  63.28 ( 65.01)\n",
            "Epoch: [4][240/391]\tTime  0.093 ( 0.097)\tLoss 2.4565e+00 (2.5896e+00)\tAcc@1  35.94 ( 33.10)\tAcc@5  68.75 ( 65.13)\n",
            "Epoch: [4][270/391]\tTime  0.095 ( 0.097)\tLoss 2.6266e+00 (2.5833e+00)\tAcc@1  33.59 ( 33.18)\tAcc@5  67.19 ( 65.35)\n",
            "Epoch: [4][300/391]\tTime  0.094 ( 0.097)\tLoss 2.7185e+00 (2.5765e+00)\tAcc@1  27.34 ( 33.30)\tAcc@5  64.06 ( 65.50)\n",
            "Epoch: [4][330/391]\tTime  0.102 ( 0.097)\tLoss 2.1401e+00 (2.5675e+00)\tAcc@1  43.75 ( 33.56)\tAcc@5  73.44 ( 65.78)\n",
            "Epoch: [4][360/391]\tTime  0.087 ( 0.096)\tLoss 2.6200e+00 (2.5657e+00)\tAcc@1  30.47 ( 33.58)\tAcc@5  63.28 ( 65.79)\n",
            "Epoch: [4][390/391]\tTime  0.082 ( 0.096)\tLoss 2.3596e+00 (2.5580e+00)\tAcc@1  38.75 ( 33.73)\tAcc@5  66.25 ( 65.97)\n",
            "==> Train Accuracy: Acc@1 33.728 || Acc@5 65.974\n",
            "==> Test Accuracy:  Acc@1 34.270 || Acc@5 67.100\n",
            "==> 40.00 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 5, lr: 0.1 -----\n",
            "Epoch: [5][  0/391]\tTime  0.275 ( 0.275)\tLoss 2.3736e+00 (2.3736e+00)\tAcc@1  33.59 ( 33.59)\tAcc@5  65.62 ( 65.62)\n",
            "Epoch: [5][ 30/391]\tTime  0.092 ( 0.101)\tLoss 2.0908e+00 (2.3382e+00)\tAcc@1  44.53 ( 37.88)\tAcc@5  78.12 ( 70.64)\n",
            "Epoch: [5][ 60/391]\tTime  0.088 ( 0.097)\tLoss 2.2120e+00 (2.3549e+00)\tAcc@1  34.38 ( 37.88)\tAcc@5  78.12 ( 70.34)\n",
            "Epoch: [5][ 90/391]\tTime  0.097 ( 0.095)\tLoss 2.3688e+00 (2.3652e+00)\tAcc@1  33.59 ( 37.59)\tAcc@5  73.44 ( 70.05)\n",
            "Epoch: [5][120/391]\tTime  0.092 ( 0.095)\tLoss 2.5324e+00 (2.3703e+00)\tAcc@1  33.59 ( 37.58)\tAcc@5  64.06 ( 69.91)\n",
            "Epoch: [5][150/391]\tTime  0.090 ( 0.094)\tLoss 2.0936e+00 (2.3597e+00)\tAcc@1  46.09 ( 37.81)\tAcc@5  78.91 ( 70.16)\n",
            "Epoch: [5][180/391]\tTime  0.088 ( 0.094)\tLoss 2.2329e+00 (2.3502e+00)\tAcc@1  40.62 ( 38.02)\tAcc@5  74.22 ( 70.42)\n",
            "Epoch: [5][210/391]\tTime  0.093 ( 0.094)\tLoss 2.3604e+00 (2.3438e+00)\tAcc@1  40.62 ( 38.06)\tAcc@5  68.75 ( 70.53)\n",
            "Epoch: [5][240/391]\tTime  0.093 ( 0.094)\tLoss 2.3237e+00 (2.3414e+00)\tAcc@1  34.38 ( 38.02)\tAcc@5  73.44 ( 70.68)\n",
            "Epoch: [5][270/391]\tTime  0.091 ( 0.093)\tLoss 2.3172e+00 (2.3409e+00)\tAcc@1  37.50 ( 37.97)\tAcc@5  73.44 ( 70.79)\n",
            "Epoch: [5][300/391]\tTime  0.091 ( 0.093)\tLoss 2.2799e+00 (2.3298e+00)\tAcc@1  36.72 ( 38.22)\tAcc@5  72.66 ( 71.08)\n",
            "Epoch: [5][330/391]\tTime  0.095 ( 0.093)\tLoss 2.3262e+00 (2.3227e+00)\tAcc@1  36.72 ( 38.37)\tAcc@5  70.31 ( 71.27)\n",
            "Epoch: [5][360/391]\tTime  0.092 ( 0.093)\tLoss 2.1330e+00 (2.3165e+00)\tAcc@1  46.09 ( 38.57)\tAcc@5  72.66 ( 71.36)\n",
            "Epoch: [5][390/391]\tTime  0.082 ( 0.094)\tLoss 2.4822e+00 (2.3087e+00)\tAcc@1  33.75 ( 38.70)\tAcc@5  65.00 ( 71.54)\n",
            "==> Train Accuracy: Acc@1 38.702 || Acc@5 71.538\n",
            "==> Test Accuracy:  Acc@1 40.340 || Acc@5 73.730\n",
            "==> 39.10 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 6, lr: 0.1 -----\n",
            "Epoch: [6][  0/391]\tTime  0.272 ( 0.272)\tLoss 2.2959e+00 (2.2959e+00)\tAcc@1  39.06 ( 39.06)\tAcc@5  72.66 ( 72.66)\n",
            "Epoch: [6][ 30/391]\tTime  0.089 ( 0.101)\tLoss 1.9994e+00 (2.1398e+00)\tAcc@1  46.88 ( 42.64)\tAcc@5  76.56 ( 75.48)\n",
            "Epoch: [6][ 60/391]\tTime  0.092 ( 0.097)\tLoss 2.1567e+00 (2.1462e+00)\tAcc@1  38.28 ( 42.37)\tAcc@5  72.66 ( 75.47)\n",
            "Epoch: [6][ 90/391]\tTime  0.095 ( 0.096)\tLoss 2.2639e+00 (2.1518e+00)\tAcc@1  38.28 ( 42.20)\tAcc@5  72.66 ( 75.21)\n",
            "Epoch: [6][120/391]\tTime  0.101 ( 0.095)\tLoss 2.1166e+00 (2.1427e+00)\tAcc@1  42.97 ( 42.34)\tAcc@5  73.44 ( 75.10)\n",
            "Epoch: [6][150/391]\tTime  0.089 ( 0.094)\tLoss 2.0487e+00 (2.1278e+00)\tAcc@1  46.88 ( 42.66)\tAcc@5  75.00 ( 75.48)\n",
            "Epoch: [6][180/391]\tTime  0.096 ( 0.094)\tLoss 2.0980e+00 (2.1209e+00)\tAcc@1  42.19 ( 42.69)\tAcc@5  75.78 ( 75.63)\n",
            "Epoch: [6][210/391]\tTime  0.095 ( 0.094)\tLoss 2.2674e+00 (2.1213e+00)\tAcc@1  39.06 ( 42.79)\tAcc@5  75.78 ( 75.70)\n",
            "Epoch: [6][240/391]\tTime  0.091 ( 0.094)\tLoss 1.8606e+00 (2.1244e+00)\tAcc@1  46.88 ( 42.68)\tAcc@5  80.47 ( 75.67)\n",
            "Epoch: [6][270/391]\tTime  0.090 ( 0.094)\tLoss 2.0570e+00 (2.1204e+00)\tAcc@1  45.31 ( 42.79)\tAcc@5  76.56 ( 75.67)\n",
            "Epoch: [6][300/391]\tTime  0.091 ( 0.094)\tLoss 2.0293e+00 (2.1139e+00)\tAcc@1  43.75 ( 42.94)\tAcc@5  78.12 ( 75.80)\n",
            "Epoch: [6][330/391]\tTime  0.090 ( 0.094)\tLoss 2.4453e+00 (2.1113e+00)\tAcc@1  35.16 ( 42.97)\tAcc@5  65.62 ( 75.85)\n",
            "Epoch: [6][360/391]\tTime  0.091 ( 0.093)\tLoss 2.1426e+00 (2.1075e+00)\tAcc@1  42.97 ( 43.06)\tAcc@5  73.44 ( 75.89)\n",
            "Epoch: [6][390/391]\tTime  0.081 ( 0.093)\tLoss 2.2572e+00 (2.1007e+00)\tAcc@1  38.75 ( 43.24)\tAcc@5  67.50 ( 75.92)\n",
            "==> Train Accuracy: Acc@1 43.244 || Acc@5 75.922\n",
            "==> Test Accuracy:  Acc@1 43.030 || Acc@5 75.450\n",
            "==> 39.00 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 7, lr: 0.1 -----\n",
            "Epoch: [7][  0/391]\tTime  0.277 ( 0.277)\tLoss 1.7425e+00 (1.7425e+00)\tAcc@1  50.78 ( 50.78)\tAcc@5  82.81 ( 82.81)\n",
            "Epoch: [7][ 30/391]\tTime  0.088 ( 0.101)\tLoss 2.3187e+00 (1.8887e+00)\tAcc@1  34.38 ( 46.93)\tAcc@5  75.78 ( 80.44)\n",
            "Epoch: [7][ 60/391]\tTime  0.095 ( 0.097)\tLoss 2.2955e+00 (1.9014e+00)\tAcc@1  35.16 ( 46.68)\tAcc@5  73.44 ( 79.78)\n",
            "Epoch: [7][ 90/391]\tTime  0.096 ( 0.096)\tLoss 1.9047e+00 (1.9257e+00)\tAcc@1  46.09 ( 46.73)\tAcc@5  83.59 ( 79.12)\n",
            "Epoch: [7][120/391]\tTime  0.093 ( 0.095)\tLoss 1.9182e+00 (1.9288e+00)\tAcc@1  46.88 ( 46.60)\tAcc@5  79.69 ( 79.08)\n",
            "Epoch: [7][150/391]\tTime  0.091 ( 0.094)\tLoss 2.1947e+00 (1.9349e+00)\tAcc@1  35.16 ( 46.46)\tAcc@5  70.31 ( 79.01)\n",
            "Epoch: [7][180/391]\tTime  0.089 ( 0.094)\tLoss 1.9380e+00 (1.9315e+00)\tAcc@1  44.53 ( 46.60)\tAcc@5  81.25 ( 79.08)\n",
            "Epoch: [7][210/391]\tTime  0.091 ( 0.094)\tLoss 1.9151e+00 (1.9370e+00)\tAcc@1  49.22 ( 46.57)\tAcc@5  80.47 ( 78.99)\n",
            "Epoch: [7][240/391]\tTime  0.093 ( 0.094)\tLoss 2.1324e+00 (1.9356e+00)\tAcc@1  42.97 ( 46.62)\tAcc@5  75.00 ( 79.03)\n",
            "Epoch: [7][270/391]\tTime  0.099 ( 0.094)\tLoss 1.8596e+00 (1.9395e+00)\tAcc@1  48.44 ( 46.58)\tAcc@5  78.91 ( 78.95)\n",
            "Epoch: [7][300/391]\tTime  0.089 ( 0.094)\tLoss 1.9854e+00 (1.9445e+00)\tAcc@1  46.09 ( 46.52)\tAcc@5  75.00 ( 78.75)\n",
            "Epoch: [7][330/391]\tTime  0.081 ( 0.093)\tLoss 1.8598e+00 (1.9483e+00)\tAcc@1  52.34 ( 46.49)\tAcc@5  81.25 ( 78.69)\n",
            "Epoch: [7][360/391]\tTime  0.089 ( 0.093)\tLoss 1.9880e+00 (1.9492e+00)\tAcc@1  52.34 ( 46.48)\tAcc@5  79.69 ( 78.68)\n",
            "Epoch: [7][390/391]\tTime  0.083 ( 0.093)\tLoss 1.5559e+00 (1.9449e+00)\tAcc@1  58.75 ( 46.67)\tAcc@5  86.25 ( 78.80)\n",
            "==> Train Accuracy: Acc@1 46.668 || Acc@5 78.802\n",
            "==> Test Accuracy:  Acc@1 46.260 || Acc@5 78.330\n",
            "==> 38.90 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 8, lr: 0.1 -----\n",
            "Epoch: [8][  0/391]\tTime  0.257 ( 0.257)\tLoss 1.8047e+00 (1.8047e+00)\tAcc@1  47.66 ( 47.66)\tAcc@5  80.47 ( 80.47)\n",
            "Epoch: [8][ 30/391]\tTime  0.092 ( 0.101)\tLoss 2.1139e+00 (1.8477e+00)\tAcc@1  39.84 ( 48.11)\tAcc@5  73.44 ( 80.19)\n",
            "Epoch: [8][ 60/391]\tTime  0.093 ( 0.097)\tLoss 1.9006e+00 (1.8120e+00)\tAcc@1  47.66 ( 49.53)\tAcc@5  80.47 ( 81.16)\n",
            "Epoch: [8][ 90/391]\tTime  0.098 ( 0.095)\tLoss 1.5810e+00 (1.7968e+00)\tAcc@1  56.25 ( 49.84)\tAcc@5  85.16 ( 81.65)\n",
            "Epoch: [8][120/391]\tTime  0.092 ( 0.095)\tLoss 1.8202e+00 (1.8103e+00)\tAcc@1  46.09 ( 49.71)\tAcc@5  82.03 ( 81.31)\n",
            "Epoch: [8][150/391]\tTime  0.092 ( 0.095)\tLoss 1.8108e+00 (1.8113e+00)\tAcc@1  47.66 ( 49.80)\tAcc@5  80.47 ( 81.27)\n",
            "Epoch: [8][180/391]\tTime  0.096 ( 0.095)\tLoss 1.7467e+00 (1.8032e+00)\tAcc@1  50.78 ( 50.07)\tAcc@5  79.69 ( 81.35)\n",
            "Epoch: [8][210/391]\tTime  0.102 ( 0.094)\tLoss 1.7301e+00 (1.8109e+00)\tAcc@1  48.44 ( 49.90)\tAcc@5  83.59 ( 81.23)\n",
            "Epoch: [8][240/391]\tTime  0.089 ( 0.094)\tLoss 1.8015e+00 (1.8129e+00)\tAcc@1  47.66 ( 49.80)\tAcc@5  85.16 ( 81.26)\n",
            "Epoch: [8][270/391]\tTime  0.091 ( 0.094)\tLoss 1.9510e+00 (1.8183e+00)\tAcc@1  45.31 ( 49.65)\tAcc@5  78.12 ( 81.10)\n",
            "Epoch: [8][300/391]\tTime  0.090 ( 0.094)\tLoss 1.7720e+00 (1.8148e+00)\tAcc@1  47.66 ( 49.75)\tAcc@5  84.38 ( 81.17)\n",
            "Epoch: [8][330/391]\tTime  0.090 ( 0.094)\tLoss 2.0690e+00 (1.8210e+00)\tAcc@1  47.66 ( 49.62)\tAcc@5  77.34 ( 81.10)\n",
            "Epoch: [8][360/391]\tTime  0.091 ( 0.094)\tLoss 2.1940e+00 (1.8250e+00)\tAcc@1  40.62 ( 49.53)\tAcc@5  74.22 ( 81.02)\n",
            "Epoch: [8][390/391]\tTime  0.082 ( 0.094)\tLoss 1.5505e+00 (1.8238e+00)\tAcc@1  61.25 ( 49.56)\tAcc@5  86.25 ( 81.06)\n",
            "==> Train Accuracy: Acc@1 49.564 || Acc@5 81.060\n",
            "==> Test Accuracy:  Acc@1 46.540 || Acc@5 77.540\n",
            "==> 39.06 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 9, lr: 0.1 -----\n",
            "Epoch: [9][  0/391]\tTime  0.291 ( 0.291)\tLoss 1.7325e+00 (1.7325e+00)\tAcc@1  53.91 ( 53.91)\tAcc@5  82.81 ( 82.81)\n",
            "Epoch: [9][ 30/391]\tTime  0.095 ( 0.101)\tLoss 1.5652e+00 (1.7196e+00)\tAcc@1  53.91 ( 51.94)\tAcc@5  85.16 ( 82.59)\n",
            "Epoch: [9][ 60/391]\tTime  0.087 ( 0.097)\tLoss 1.8236e+00 (1.7477e+00)\tAcc@1  51.56 ( 50.92)\tAcc@5  82.81 ( 82.33)\n",
            "Epoch: [9][ 90/391]\tTime  0.082 ( 0.097)\tLoss 1.7405e+00 (1.7527e+00)\tAcc@1  49.22 ( 50.83)\tAcc@5  82.03 ( 82.20)\n",
            "Epoch: [9][120/391]\tTime  0.091 ( 0.096)\tLoss 1.5895e+00 (1.7529e+00)\tAcc@1  57.03 ( 50.70)\tAcc@5  85.16 ( 82.17)\n",
            "Epoch: [9][150/391]\tTime  0.089 ( 0.095)\tLoss 1.6211e+00 (1.7464e+00)\tAcc@1  52.34 ( 51.14)\tAcc@5  84.38 ( 82.35)\n",
            "Epoch: [9][180/391]\tTime  0.097 ( 0.095)\tLoss 1.8139e+00 (1.7453e+00)\tAcc@1  46.88 ( 51.28)\tAcc@5  82.03 ( 82.37)\n",
            "Epoch: [9][210/391]\tTime  0.090 ( 0.095)\tLoss 1.8932e+00 (1.7414e+00)\tAcc@1  49.22 ( 51.41)\tAcc@5  80.47 ( 82.40)\n",
            "Epoch: [9][240/391]\tTime  0.098 ( 0.095)\tLoss 1.7303e+00 (1.7474e+00)\tAcc@1  57.03 ( 51.19)\tAcc@5  80.47 ( 82.39)\n",
            "Epoch: [9][270/391]\tTime  0.094 ( 0.095)\tLoss 1.6225e+00 (1.7493e+00)\tAcc@1  57.03 ( 51.15)\tAcc@5  82.81 ( 82.42)\n",
            "Epoch: [9][300/391]\tTime  0.097 ( 0.095)\tLoss 1.6103e+00 (1.7436e+00)\tAcc@1  60.16 ( 51.21)\tAcc@5  82.81 ( 82.53)\n",
            "Epoch: [9][330/391]\tTime  0.095 ( 0.094)\tLoss 1.7511e+00 (1.7417e+00)\tAcc@1  52.34 ( 51.24)\tAcc@5  80.47 ( 82.57)\n",
            "Epoch: [9][360/391]\tTime  0.107 ( 0.094)\tLoss 1.8192e+00 (1.7400e+00)\tAcc@1  52.34 ( 51.41)\tAcc@5  80.47 ( 82.59)\n",
            "Epoch: [9][390/391]\tTime  0.082 ( 0.094)\tLoss 2.0279e+00 (1.7367e+00)\tAcc@1  42.50 ( 51.44)\tAcc@5  73.75 ( 82.63)\n",
            "==> Train Accuracy: Acc@1 51.436 || Acc@5 82.632\n",
            "==> Test Accuracy:  Acc@1 46.100 || Acc@5 76.610\n",
            "==> 39.27 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 10, lr: 0.1 -----\n",
            "Epoch: [10][  0/391]\tTime  0.285 ( 0.285)\tLoss 1.5322e+00 (1.5322e+00)\tAcc@1  53.91 ( 53.91)\tAcc@5  85.16 ( 85.16)\n",
            "Epoch: [10][ 30/391]\tTime  0.092 ( 0.100)\tLoss 1.8681e+00 (1.6317e+00)\tAcc@1  46.88 ( 53.78)\tAcc@5  78.91 ( 84.25)\n",
            "Epoch: [10][ 60/391]\tTime  0.097 ( 0.097)\tLoss 1.5435e+00 (1.6189e+00)\tAcc@1  51.56 ( 54.14)\tAcc@5  88.28 ( 84.63)\n",
            "Epoch: [10][ 90/391]\tTime  0.083 ( 0.095)\tLoss 1.4756e+00 (1.6389e+00)\tAcc@1  60.16 ( 54.10)\tAcc@5  87.50 ( 84.43)\n",
            "Epoch: [10][120/391]\tTime  0.094 ( 0.095)\tLoss 1.5430e+00 (1.6375e+00)\tAcc@1  55.47 ( 54.20)\tAcc@5  87.50 ( 84.36)\n",
            "Epoch: [10][150/391]\tTime  0.100 ( 0.094)\tLoss 1.9458e+00 (1.6365e+00)\tAcc@1  50.00 ( 54.15)\tAcc@5  79.69 ( 84.36)\n",
            "Epoch: [10][180/391]\tTime  0.081 ( 0.094)\tLoss 1.6395e+00 (1.6318e+00)\tAcc@1  52.34 ( 54.34)\tAcc@5  82.03 ( 84.40)\n",
            "Epoch: [10][210/391]\tTime  0.089 ( 0.094)\tLoss 1.5749e+00 (1.6373e+00)\tAcc@1  56.25 ( 54.29)\tAcc@5  85.94 ( 84.17)\n",
            "Epoch: [10][240/391]\tTime  0.107 ( 0.094)\tLoss 1.6668e+00 (1.6374e+00)\tAcc@1  51.56 ( 54.31)\tAcc@5  85.94 ( 84.18)\n",
            "Epoch: [10][270/391]\tTime  0.090 ( 0.094)\tLoss 1.4458e+00 (1.6403e+00)\tAcc@1  60.16 ( 54.23)\tAcc@5  85.16 ( 84.14)\n",
            "Epoch: [10][300/391]\tTime  0.100 ( 0.094)\tLoss 1.5845e+00 (1.6442e+00)\tAcc@1  54.69 ( 54.09)\tAcc@5  82.03 ( 84.08)\n",
            "Epoch: [10][330/391]\tTime  0.106 ( 0.094)\tLoss 1.6564e+00 (1.6455e+00)\tAcc@1  51.56 ( 54.10)\tAcc@5  85.94 ( 84.02)\n",
            "Epoch: [10][360/391]\tTime  0.091 ( 0.094)\tLoss 1.6157e+00 (1.6476e+00)\tAcc@1  53.12 ( 54.02)\tAcc@5  82.81 ( 84.04)\n",
            "Epoch: [10][390/391]\tTime  0.081 ( 0.094)\tLoss 1.7707e+00 (1.6490e+00)\tAcc@1  48.75 ( 53.98)\tAcc@5  83.75 ( 83.99)\n",
            "==> Train Accuracy: Acc@1 53.984 || Acc@5 83.990\n",
            "==> Test Accuracy:  Acc@1 51.320 || Acc@5 81.190\n",
            "==> 39.17 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 11, lr: 0.1 -----\n",
            "Epoch: [11][  0/391]\tTime  0.287 ( 0.287)\tLoss 1.7685e+00 (1.7685e+00)\tAcc@1  48.44 ( 48.44)\tAcc@5  84.38 ( 84.38)\n",
            "Epoch: [11][ 30/391]\tTime  0.091 ( 0.102)\tLoss 1.6925e+00 (1.5269e+00)\tAcc@1  46.88 ( 56.88)\tAcc@5  84.38 ( 85.99)\n",
            "Epoch: [11][ 60/391]\tTime  0.104 ( 0.098)\tLoss 1.3790e+00 (1.5143e+00)\tAcc@1  60.16 ( 57.29)\tAcc@5  88.28 ( 86.39)\n",
            "Epoch: [11][ 90/391]\tTime  0.089 ( 0.096)\tLoss 1.5970e+00 (1.5297e+00)\tAcc@1  57.81 ( 57.04)\tAcc@5  85.94 ( 86.13)\n",
            "Epoch: [11][120/391]\tTime  0.093 ( 0.096)\tLoss 1.8266e+00 (1.5472e+00)\tAcc@1  47.66 ( 56.53)\tAcc@5  85.16 ( 86.03)\n",
            "Epoch: [11][150/391]\tTime  0.097 ( 0.095)\tLoss 1.5555e+00 (1.5455e+00)\tAcc@1  58.59 ( 56.43)\tAcc@5  82.81 ( 85.92)\n",
            "Epoch: [11][180/391]\tTime  0.093 ( 0.095)\tLoss 1.5897e+00 (1.5494e+00)\tAcc@1  53.12 ( 56.16)\tAcc@5  86.72 ( 85.90)\n",
            "Epoch: [11][210/391]\tTime  0.096 ( 0.094)\tLoss 1.4661e+00 (1.5525e+00)\tAcc@1  59.38 ( 56.12)\tAcc@5  87.50 ( 85.84)\n",
            "Epoch: [11][240/391]\tTime  0.095 ( 0.094)\tLoss 1.6023e+00 (1.5539e+00)\tAcc@1  57.03 ( 56.10)\tAcc@5  80.47 ( 85.81)\n",
            "Epoch: [11][270/391]\tTime  0.091 ( 0.094)\tLoss 1.7564e+00 (1.5582e+00)\tAcc@1  56.25 ( 56.05)\tAcc@5  78.91 ( 85.78)\n",
            "Epoch: [11][300/391]\tTime  0.091 ( 0.094)\tLoss 1.4523e+00 (1.5584e+00)\tAcc@1  59.38 ( 56.07)\tAcc@5  85.94 ( 85.75)\n",
            "Epoch: [11][330/391]\tTime  0.091 ( 0.094)\tLoss 1.6585e+00 (1.5604e+00)\tAcc@1  50.78 ( 55.98)\tAcc@5  81.25 ( 85.69)\n",
            "Epoch: [11][360/391]\tTime  0.090 ( 0.093)\tLoss 1.8763e+00 (1.5652e+00)\tAcc@1  49.22 ( 55.91)\tAcc@5  81.25 ( 85.65)\n",
            "Epoch: [11][390/391]\tTime  0.082 ( 0.093)\tLoss 1.6285e+00 (1.5640e+00)\tAcc@1  53.75 ( 56.03)\tAcc@5  87.50 ( 85.62)\n",
            "==> Train Accuracy: Acc@1 56.028 || Acc@5 85.620\n",
            "==> Test Accuracy:  Acc@1 47.650 || Acc@5 78.790\n",
            "==> 39.01 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 12, lr: 0.1 -----\n",
            "Epoch: [12][  0/391]\tTime  0.283 ( 0.283)\tLoss 1.2061e+00 (1.2061e+00)\tAcc@1  67.19 ( 67.19)\tAcc@5  95.31 ( 95.31)\n",
            "Epoch: [12][ 30/391]\tTime  0.101 ( 0.101)\tLoss 1.6967e+00 (1.5037e+00)\tAcc@1  58.59 ( 57.01)\tAcc@5  82.03 ( 86.21)\n",
            "Epoch: [12][ 60/391]\tTime  0.098 ( 0.098)\tLoss 1.5901e+00 (1.4874e+00)\tAcc@1  53.12 ( 57.48)\tAcc@5  83.59 ( 86.48)\n",
            "Epoch: [12][ 90/391]\tTime  0.096 ( 0.097)\tLoss 1.4198e+00 (1.4866e+00)\tAcc@1  61.72 ( 57.73)\tAcc@5  85.16 ( 86.33)\n",
            "Epoch: [12][120/391]\tTime  0.097 ( 0.096)\tLoss 1.5738e+00 (1.4911e+00)\tAcc@1  53.91 ( 57.77)\tAcc@5  85.16 ( 86.36)\n",
            "Epoch: [12][150/391]\tTime  0.101 ( 0.096)\tLoss 1.6191e+00 (1.4947e+00)\tAcc@1  53.91 ( 57.76)\tAcc@5  85.16 ( 86.19)\n",
            "Epoch: [12][180/391]\tTime  0.101 ( 0.096)\tLoss 1.3400e+00 (1.4966e+00)\tAcc@1  61.72 ( 57.78)\tAcc@5  86.72 ( 86.12)\n",
            "Epoch: [12][210/391]\tTime  0.096 ( 0.095)\tLoss 1.4003e+00 (1.4975e+00)\tAcc@1  60.16 ( 57.73)\tAcc@5  86.72 ( 86.20)\n",
            "Epoch: [12][240/391]\tTime  0.092 ( 0.095)\tLoss 1.5722e+00 (1.5005e+00)\tAcc@1  56.25 ( 57.63)\tAcc@5  80.47 ( 86.19)\n",
            "Epoch: [12][270/391]\tTime  0.095 ( 0.095)\tLoss 1.4321e+00 (1.5094e+00)\tAcc@1  57.81 ( 57.35)\tAcc@5  84.38 ( 86.08)\n",
            "Epoch: [12][300/391]\tTime  0.090 ( 0.095)\tLoss 1.6206e+00 (1.5112e+00)\tAcc@1  54.69 ( 57.32)\tAcc@5  83.59 ( 86.12)\n",
            "Epoch: [12][330/391]\tTime  0.086 ( 0.094)\tLoss 1.3557e+00 (1.5150e+00)\tAcc@1  62.50 ( 57.22)\tAcc@5  89.84 ( 86.08)\n",
            "Epoch: [12][360/391]\tTime  0.096 ( 0.094)\tLoss 1.6795e+00 (1.5224e+00)\tAcc@1  53.91 ( 56.99)\tAcc@5  85.16 ( 85.97)\n",
            "Epoch: [12][390/391]\tTime  0.082 ( 0.094)\tLoss 1.7430e+00 (1.5207e+00)\tAcc@1  52.50 ( 57.01)\tAcc@5  81.25 ( 86.05)\n",
            "==> Train Accuracy: Acc@1 57.012 || Acc@5 86.050\n",
            "==> Test Accuracy:  Acc@1 54.130 || Acc@5 83.330\n",
            "==> 39.29 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 13, lr: 0.1 -----\n",
            "Epoch: [13][  0/391]\tTime  0.276 ( 0.276)\tLoss 1.4844e+00 (1.4844e+00)\tAcc@1  59.38 ( 59.38)\tAcc@5  83.59 ( 83.59)\n",
            "Epoch: [13][ 30/391]\tTime  0.093 ( 0.101)\tLoss 1.6089e+00 (1.4373e+00)\tAcc@1  54.69 ( 59.38)\tAcc@5  86.72 ( 87.22)\n",
            "Epoch: [13][ 60/391]\tTime  0.100 ( 0.097)\tLoss 1.3704e+00 (1.4227e+00)\tAcc@1  64.06 ( 59.67)\tAcc@5  90.62 ( 87.69)\n",
            "Epoch: [13][ 90/391]\tTime  0.091 ( 0.095)\tLoss 1.4833e+00 (1.4276e+00)\tAcc@1  61.72 ( 59.62)\tAcc@5  85.16 ( 87.65)\n",
            "Epoch: [13][120/391]\tTime  0.092 ( 0.095)\tLoss 1.5205e+00 (1.4344e+00)\tAcc@1  55.47 ( 59.16)\tAcc@5  86.72 ( 87.44)\n",
            "Epoch: [13][150/391]\tTime  0.090 ( 0.094)\tLoss 1.2802e+00 (1.4316e+00)\tAcc@1  62.50 ( 59.08)\tAcc@5  92.19 ( 87.54)\n",
            "Epoch: [13][180/391]\tTime  0.092 ( 0.094)\tLoss 1.6038e+00 (1.4399e+00)\tAcc@1  54.69 ( 58.95)\tAcc@5  84.38 ( 87.37)\n",
            "Epoch: [13][210/391]\tTime  0.094 ( 0.094)\tLoss 1.2734e+00 (1.4483e+00)\tAcc@1  64.06 ( 58.61)\tAcc@5  89.84 ( 87.23)\n",
            "Epoch: [13][240/391]\tTime  0.090 ( 0.094)\tLoss 1.2171e+00 (1.4559e+00)\tAcc@1  67.97 ( 58.33)\tAcc@5  90.62 ( 87.23)\n",
            "Epoch: [13][270/391]\tTime  0.097 ( 0.094)\tLoss 1.7521e+00 (1.4559e+00)\tAcc@1  53.12 ( 58.42)\tAcc@5  83.59 ( 87.23)\n",
            "Epoch: [13][300/391]\tTime  0.086 ( 0.094)\tLoss 1.4670e+00 (1.4578e+00)\tAcc@1  58.59 ( 58.34)\tAcc@5  87.50 ( 87.20)\n",
            "Epoch: [13][330/391]\tTime  0.094 ( 0.094)\tLoss 1.5292e+00 (1.4607e+00)\tAcc@1  53.12 ( 58.31)\tAcc@5  85.16 ( 87.18)\n",
            "Epoch: [13][360/391]\tTime  0.102 ( 0.094)\tLoss 1.4961e+00 (1.4625e+00)\tAcc@1  56.25 ( 58.36)\tAcc@5  84.38 ( 87.11)\n",
            "Epoch: [13][390/391]\tTime  0.082 ( 0.094)\tLoss 1.3563e+00 (1.4656e+00)\tAcc@1  55.00 ( 58.31)\tAcc@5  90.00 ( 87.10)\n",
            "==> Train Accuracy: Acc@1 58.310 || Acc@5 87.100\n",
            "==> Test Accuracy:  Acc@1 53.900 || Acc@5 83.580\n",
            "==> 39.15 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 14, lr: 0.1 -----\n",
            "Epoch: [14][  0/391]\tTime  0.286 ( 0.286)\tLoss 1.4281e+00 (1.4281e+00)\tAcc@1  60.16 ( 60.16)\tAcc@5  90.62 ( 90.62)\n",
            "Epoch: [14][ 30/391]\tTime  0.090 ( 0.100)\tLoss 1.3222e+00 (1.3771e+00)\tAcc@1  60.16 ( 60.69)\tAcc@5  86.72 ( 88.63)\n",
            "Epoch: [14][ 60/391]\tTime  0.090 ( 0.097)\tLoss 1.3510e+00 (1.3946e+00)\tAcc@1  64.06 ( 60.14)\tAcc@5  92.97 ( 88.20)\n",
            "Epoch: [14][ 90/391]\tTime  0.090 ( 0.096)\tLoss 1.5591e+00 (1.3863e+00)\tAcc@1  50.78 ( 60.41)\tAcc@5  86.72 ( 88.40)\n",
            "Epoch: [14][120/391]\tTime  0.095 ( 0.095)\tLoss 1.3106e+00 (1.3974e+00)\tAcc@1  64.84 ( 60.14)\tAcc@5  86.72 ( 88.15)\n",
            "Epoch: [14][150/391]\tTime  0.091 ( 0.094)\tLoss 1.3823e+00 (1.4002e+00)\tAcc@1  60.94 ( 59.95)\tAcc@5  89.06 ( 88.04)\n",
            "Epoch: [14][180/391]\tTime  0.095 ( 0.094)\tLoss 1.3344e+00 (1.4120e+00)\tAcc@1  61.72 ( 59.65)\tAcc@5  88.28 ( 87.90)\n",
            "Epoch: [14][210/391]\tTime  0.090 ( 0.094)\tLoss 1.4656e+00 (1.4108e+00)\tAcc@1  56.25 ( 59.73)\tAcc@5  85.94 ( 87.85)\n",
            "Epoch: [14][240/391]\tTime  0.091 ( 0.094)\tLoss 1.6967e+00 (1.4157e+00)\tAcc@1  54.69 ( 59.61)\tAcc@5  80.47 ( 87.73)\n",
            "Epoch: [14][270/391]\tTime  0.094 ( 0.094)\tLoss 1.4430e+00 (1.4203e+00)\tAcc@1  60.94 ( 59.41)\tAcc@5  89.84 ( 87.75)\n",
            "Epoch: [14][300/391]\tTime  0.094 ( 0.094)\tLoss 1.6180e+00 (1.4242e+00)\tAcc@1  50.00 ( 59.28)\tAcc@5  85.94 ( 87.63)\n",
            "Epoch: [14][330/391]\tTime  0.094 ( 0.094)\tLoss 1.5468e+00 (1.4268e+00)\tAcc@1  52.34 ( 59.26)\tAcc@5  88.28 ( 87.58)\n",
            "Epoch: [14][360/391]\tTime  0.085 ( 0.094)\tLoss 1.5545e+00 (1.4265e+00)\tAcc@1  56.25 ( 59.27)\tAcc@5  85.16 ( 87.57)\n",
            "Epoch: [14][390/391]\tTime  0.082 ( 0.093)\tLoss 1.5486e+00 (1.4289e+00)\tAcc@1  56.25 ( 59.16)\tAcc@5  82.50 ( 87.56)\n",
            "==> Train Accuracy: Acc@1 59.164 || Acc@5 87.560\n",
            "==> Test Accuracy:  Acc@1 54.330 || Acc@5 82.950\n",
            "==> 39.02 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 15, lr: 0.1 -----\n",
            "Epoch: [15][  0/391]\tTime  0.274 ( 0.274)\tLoss 1.2918e+00 (1.2918e+00)\tAcc@1  67.97 ( 67.97)\tAcc@5  88.28 ( 88.28)\n",
            "Epoch: [15][ 30/391]\tTime  0.091 ( 0.100)\tLoss 1.4451e+00 (1.3216e+00)\tAcc@1  57.03 ( 62.60)\tAcc@5  87.50 ( 88.91)\n",
            "Epoch: [15][ 60/391]\tTime  0.091 ( 0.097)\tLoss 1.1115e+00 (1.3235e+00)\tAcc@1  70.31 ( 62.31)\tAcc@5  89.06 ( 88.92)\n",
            "Epoch: [15][ 90/391]\tTime  0.101 ( 0.095)\tLoss 1.3363e+00 (1.3511e+00)\tAcc@1  57.03 ( 61.38)\tAcc@5  92.97 ( 88.68)\n",
            "Epoch: [15][120/391]\tTime  0.102 ( 0.095)\tLoss 1.3498e+00 (1.3752e+00)\tAcc@1  57.03 ( 60.71)\tAcc@5  90.62 ( 88.36)\n",
            "Epoch: [15][150/391]\tTime  0.094 ( 0.095)\tLoss 1.6172e+00 (1.3776e+00)\tAcc@1  52.34 ( 60.83)\tAcc@5  88.28 ( 88.30)\n",
            "Epoch: [15][180/391]\tTime  0.093 ( 0.095)\tLoss 1.4132e+00 (1.3785e+00)\tAcc@1  60.16 ( 60.76)\tAcc@5  89.84 ( 88.35)\n",
            "Epoch: [15][210/391]\tTime  0.089 ( 0.094)\tLoss 1.4778e+00 (1.3807e+00)\tAcc@1  59.38 ( 60.63)\tAcc@5  86.72 ( 88.33)\n",
            "Epoch: [15][240/391]\tTime  0.091 ( 0.094)\tLoss 1.3950e+00 (1.3837e+00)\tAcc@1  60.16 ( 60.59)\tAcc@5  89.84 ( 88.38)\n",
            "Epoch: [15][270/391]\tTime  0.094 ( 0.094)\tLoss 1.4206e+00 (1.3827e+00)\tAcc@1  65.62 ( 60.69)\tAcc@5  84.38 ( 88.38)\n",
            "Epoch: [15][300/391]\tTime  0.082 ( 0.094)\tLoss 1.3050e+00 (1.3861e+00)\tAcc@1  60.16 ( 60.53)\tAcc@5  92.97 ( 88.24)\n",
            "Epoch: [15][330/391]\tTime  0.088 ( 0.094)\tLoss 1.4185e+00 (1.3892e+00)\tAcc@1  61.72 ( 60.46)\tAcc@5  88.28 ( 88.19)\n",
            "Epoch: [15][360/391]\tTime  0.090 ( 0.094)\tLoss 1.3396e+00 (1.3903e+00)\tAcc@1  65.62 ( 60.46)\tAcc@5  86.72 ( 88.17)\n",
            "Epoch: [15][390/391]\tTime  0.082 ( 0.094)\tLoss 1.3320e+00 (1.3916e+00)\tAcc@1  62.50 ( 60.43)\tAcc@5  87.50 ( 88.07)\n",
            "==> Train Accuracy: Acc@1 60.430 || Acc@5 88.068\n",
            "==> Test Accuracy:  Acc@1 52.870 || Acc@5 83.210\n",
            "==> 39.10 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 16, lr: 0.1 -----\n",
            "Epoch: [16][  0/391]\tTime  0.286 ( 0.286)\tLoss 1.3784e+00 (1.3784e+00)\tAcc@1  56.25 ( 56.25)\tAcc@5  90.62 ( 90.62)\n",
            "Epoch: [16][ 30/391]\tTime  0.092 ( 0.100)\tLoss 1.1348e+00 (1.3053e+00)\tAcc@1  71.88 ( 62.63)\tAcc@5  92.19 ( 89.97)\n",
            "Epoch: [16][ 60/391]\tTime  0.112 ( 0.097)\tLoss 1.4259e+00 (1.3081e+00)\tAcc@1  57.81 ( 62.59)\tAcc@5  88.28 ( 89.72)\n",
            "Epoch: [16][ 90/391]\tTime  0.094 ( 0.095)\tLoss 1.4284e+00 (1.3089e+00)\tAcc@1  61.72 ( 62.50)\tAcc@5  88.28 ( 89.49)\n",
            "Epoch: [16][120/391]\tTime  0.093 ( 0.095)\tLoss 1.3740e+00 (1.3265e+00)\tAcc@1  59.38 ( 62.03)\tAcc@5  93.75 ( 89.11)\n",
            "Epoch: [16][150/391]\tTime  0.094 ( 0.094)\tLoss 1.3895e+00 (1.3339e+00)\tAcc@1  59.38 ( 61.72)\tAcc@5  89.84 ( 89.01)\n",
            "Epoch: [16][180/391]\tTime  0.089 ( 0.094)\tLoss 1.1078e+00 (1.3360e+00)\tAcc@1  68.75 ( 61.76)\tAcc@5  93.75 ( 88.95)\n",
            "Epoch: [16][210/391]\tTime  0.105 ( 0.094)\tLoss 1.3764e+00 (1.3417e+00)\tAcc@1  58.59 ( 61.53)\tAcc@5  90.62 ( 88.83)\n",
            "Epoch: [16][240/391]\tTime  0.090 ( 0.094)\tLoss 1.3370e+00 (1.3426e+00)\tAcc@1  57.81 ( 61.59)\tAcc@5  88.28 ( 88.78)\n",
            "Epoch: [16][270/391]\tTime  0.091 ( 0.094)\tLoss 1.3978e+00 (1.3460e+00)\tAcc@1  65.62 ( 61.56)\tAcc@5  84.38 ( 88.71)\n",
            "Epoch: [16][300/391]\tTime  0.092 ( 0.094)\tLoss 1.3221e+00 (1.3510e+00)\tAcc@1  67.97 ( 61.41)\tAcc@5  86.72 ( 88.63)\n",
            "Epoch: [16][330/391]\tTime  0.092 ( 0.094)\tLoss 1.5012e+00 (1.3577e+00)\tAcc@1  51.56 ( 61.14)\tAcc@5  89.84 ( 88.57)\n",
            "Epoch: [16][360/391]\tTime  0.097 ( 0.094)\tLoss 1.3051e+00 (1.3603e+00)\tAcc@1  60.94 ( 61.07)\tAcc@5  87.50 ( 88.58)\n",
            "Epoch: [16][390/391]\tTime  0.082 ( 0.094)\tLoss 1.3615e+00 (1.3647e+00)\tAcc@1  62.50 ( 60.89)\tAcc@5  93.75 ( 88.51)\n",
            "==> Train Accuracy: Acc@1 60.890 || Acc@5 88.512\n",
            "==> Test Accuracy:  Acc@1 51.990 || Acc@5 80.340\n",
            "==> 39.12 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 17, lr: 0.1 -----\n",
            "Epoch: [17][  0/391]\tTime  0.291 ( 0.291)\tLoss 1.0275e+00 (1.0275e+00)\tAcc@1  70.31 ( 70.31)\tAcc@5  94.53 ( 94.53)\n",
            "Epoch: [17][ 30/391]\tTime  0.092 ( 0.102)\tLoss 1.3779e+00 (1.2298e+00)\tAcc@1  62.50 ( 64.62)\tAcc@5  87.50 ( 90.78)\n",
            "Epoch: [17][ 60/391]\tTime  0.091 ( 0.099)\tLoss 1.5437e+00 (1.2666e+00)\tAcc@1  57.03 ( 63.31)\tAcc@5  86.72 ( 90.06)\n",
            "Epoch: [17][ 90/391]\tTime  0.104 ( 0.097)\tLoss 1.1084e+00 (1.2851e+00)\tAcc@1  68.75 ( 63.02)\tAcc@5  92.19 ( 89.68)\n",
            "Epoch: [17][120/391]\tTime  0.091 ( 0.096)\tLoss 1.2587e+00 (1.2915e+00)\tAcc@1  64.06 ( 62.95)\tAcc@5  90.62 ( 89.55)\n",
            "Epoch: [17][150/391]\tTime  0.093 ( 0.095)\tLoss 1.2118e+00 (1.2995e+00)\tAcc@1  64.84 ( 62.76)\tAcc@5  90.62 ( 89.47)\n",
            "Epoch: [17][180/391]\tTime  0.091 ( 0.095)\tLoss 1.7537e+00 (1.3200e+00)\tAcc@1  53.91 ( 62.26)\tAcc@5  82.81 ( 89.27)\n",
            "Epoch: [17][210/391]\tTime  0.091 ( 0.095)\tLoss 1.2138e+00 (1.3205e+00)\tAcc@1  64.06 ( 62.26)\tAcc@5  95.31 ( 89.35)\n",
            "Epoch: [17][240/391]\tTime  0.091 ( 0.094)\tLoss 1.4234e+00 (1.3205e+00)\tAcc@1  62.50 ( 62.19)\tAcc@5  85.94 ( 89.34)\n",
            "Epoch: [17][270/391]\tTime  0.091 ( 0.094)\tLoss 1.1200e+00 (1.3212e+00)\tAcc@1  71.09 ( 62.21)\tAcc@5  88.28 ( 89.26)\n",
            "Epoch: [17][300/391]\tTime  0.096 ( 0.094)\tLoss 1.5450e+00 (1.3235e+00)\tAcc@1  60.94 ( 62.17)\tAcc@5  85.94 ( 89.25)\n",
            "Epoch: [17][330/391]\tTime  0.094 ( 0.094)\tLoss 1.5641e+00 (1.3275e+00)\tAcc@1  55.47 ( 62.10)\tAcc@5  84.38 ( 89.16)\n",
            "Epoch: [17][360/391]\tTime  0.091 ( 0.094)\tLoss 1.4441e+00 (1.3281e+00)\tAcc@1  58.59 ( 62.09)\tAcc@5  85.94 ( 89.14)\n",
            "Epoch: [17][390/391]\tTime  0.082 ( 0.094)\tLoss 1.3333e+00 (1.3324e+00)\tAcc@1  52.50 ( 61.98)\tAcc@5  93.75 ( 89.12)\n",
            "==> Train Accuracy: Acc@1 61.978 || Acc@5 89.120\n",
            "==> Test Accuracy:  Acc@1 57.220 || Acc@5 84.590\n",
            "==> 39.20 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 18, lr: 0.1 -----\n",
            "Epoch: [18][  0/391]\tTime  0.281 ( 0.281)\tLoss 1.2672e+00 (1.2672e+00)\tAcc@1  65.62 ( 65.62)\tAcc@5  89.06 ( 89.06)\n",
            "Epoch: [18][ 30/391]\tTime  0.093 ( 0.100)\tLoss 1.1219e+00 (1.2580e+00)\tAcc@1  64.06 ( 63.99)\tAcc@5  91.41 ( 90.10)\n",
            "Epoch: [18][ 60/391]\tTime  0.091 ( 0.097)\tLoss 1.4838e+00 (1.2515e+00)\tAcc@1  58.59 ( 63.97)\tAcc@5  83.59 ( 90.22)\n",
            "Epoch: [18][ 90/391]\tTime  0.086 ( 0.096)\tLoss 1.1963e+00 (1.2447e+00)\tAcc@1  62.50 ( 63.80)\tAcc@5  92.97 ( 90.34)\n",
            "Epoch: [18][120/391]\tTime  0.083 ( 0.095)\tLoss 1.0944e+00 (1.2607e+00)\tAcc@1  69.53 ( 63.48)\tAcc@5  88.28 ( 90.13)\n",
            "Epoch: [18][150/391]\tTime  0.096 ( 0.095)\tLoss 1.2212e+00 (1.2744e+00)\tAcc@1  66.41 ( 63.36)\tAcc@5  89.06 ( 89.87)\n",
            "Epoch: [18][180/391]\tTime  0.091 ( 0.094)\tLoss 1.3285e+00 (1.2812e+00)\tAcc@1  62.50 ( 63.19)\tAcc@5  89.84 ( 89.73)\n",
            "Epoch: [18][210/391]\tTime  0.095 ( 0.094)\tLoss 1.6863e+00 (1.2892e+00)\tAcc@1  53.12 ( 62.96)\tAcc@5  85.94 ( 89.60)\n",
            "Epoch: [18][240/391]\tTime  0.091 ( 0.094)\tLoss 1.4926e+00 (1.2931e+00)\tAcc@1  54.69 ( 62.73)\tAcc@5  85.94 ( 89.62)\n",
            "Epoch: [18][270/391]\tTime  0.090 ( 0.094)\tLoss 1.0602e+00 (1.2995e+00)\tAcc@1  70.31 ( 62.58)\tAcc@5  91.41 ( 89.52)\n",
            "Epoch: [18][300/391]\tTime  0.089 ( 0.094)\tLoss 1.3579e+00 (1.3025e+00)\tAcc@1  66.41 ( 62.51)\tAcc@5  88.28 ( 89.44)\n",
            "Epoch: [18][330/391]\tTime  0.091 ( 0.094)\tLoss 1.5212e+00 (1.3032e+00)\tAcc@1  57.81 ( 62.48)\tAcc@5  83.59 ( 89.44)\n",
            "Epoch: [18][360/391]\tTime  0.089 ( 0.094)\tLoss 1.3517e+00 (1.3097e+00)\tAcc@1  60.16 ( 62.39)\tAcc@5  89.84 ( 89.32)\n",
            "Epoch: [18][390/391]\tTime  0.081 ( 0.094)\tLoss 1.5038e+00 (1.3098e+00)\tAcc@1  58.75 ( 62.39)\tAcc@5  85.00 ( 89.36)\n",
            "==> Train Accuracy: Acc@1 62.390 || Acc@5 89.360\n",
            "==> Test Accuracy:  Acc@1 56.260 || Acc@5 83.750\n",
            "==> 39.11 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 19, lr: 0.1 -----\n",
            "Epoch: [19][  0/391]\tTime  0.286 ( 0.286)\tLoss 1.1781e+00 (1.1781e+00)\tAcc@1  67.97 ( 67.97)\tAcc@5  92.97 ( 92.97)\n",
            "Epoch: [19][ 30/391]\tTime  0.091 ( 0.100)\tLoss 1.2364e+00 (1.1960e+00)\tAcc@1  68.75 ( 64.79)\tAcc@5  89.06 ( 90.95)\n",
            "Epoch: [19][ 60/391]\tTime  0.092 ( 0.097)\tLoss 1.1735e+00 (1.2077e+00)\tAcc@1  68.75 ( 64.63)\tAcc@5  91.41 ( 90.80)\n",
            "Epoch: [19][ 90/391]\tTime  0.091 ( 0.096)\tLoss 1.0436e+00 (1.2223e+00)\tAcc@1  67.97 ( 64.48)\tAcc@5  92.97 ( 90.47)\n",
            "Epoch: [19][120/391]\tTime  0.090 ( 0.095)\tLoss 1.4364e+00 (1.2400e+00)\tAcc@1  57.03 ( 63.97)\tAcc@5  87.50 ( 90.32)\n",
            "Epoch: [19][150/391]\tTime  0.094 ( 0.094)\tLoss 1.2745e+00 (1.2450e+00)\tAcc@1  64.84 ( 63.90)\tAcc@5  87.50 ( 90.32)\n",
            "Epoch: [19][180/391]\tTime  0.087 ( 0.094)\tLoss 1.5188e+00 (1.2599e+00)\tAcc@1  56.25 ( 63.47)\tAcc@5  87.50 ( 90.14)\n",
            "Epoch: [19][210/391]\tTime  0.085 ( 0.094)\tLoss 1.2566e+00 (1.2659e+00)\tAcc@1  60.16 ( 63.34)\tAcc@5  89.06 ( 90.04)\n",
            "Epoch: [19][240/391]\tTime  0.092 ( 0.094)\tLoss 1.4255e+00 (1.2679e+00)\tAcc@1  57.81 ( 63.39)\tAcc@5  88.28 ( 89.96)\n",
            "Epoch: [19][270/391]\tTime  0.092 ( 0.094)\tLoss 1.3415e+00 (1.2712e+00)\tAcc@1  64.06 ( 63.29)\tAcc@5  87.50 ( 89.87)\n",
            "Epoch: [19][300/391]\tTime  0.081 ( 0.094)\tLoss 1.5515e+00 (1.2750e+00)\tAcc@1  58.59 ( 63.23)\tAcc@5  83.59 ( 89.80)\n",
            "Epoch: [19][330/391]\tTime  0.092 ( 0.094)\tLoss 1.2571e+00 (1.2789e+00)\tAcc@1  67.19 ( 63.08)\tAcc@5  89.84 ( 89.76)\n",
            "Epoch: [19][360/391]\tTime  0.100 ( 0.094)\tLoss 1.1397e+00 (1.2825e+00)\tAcc@1  64.84 ( 62.95)\tAcc@5  93.75 ( 89.73)\n",
            "Epoch: [19][390/391]\tTime  0.081 ( 0.094)\tLoss 1.6108e+00 (1.2876e+00)\tAcc@1  56.25 ( 62.92)\tAcc@5  83.75 ( 89.65)\n",
            "==> Train Accuracy: Acc@1 62.916 || Acc@5 89.652\n",
            "==> Test Accuracy:  Acc@1 48.820 || Acc@5 78.440\n",
            "==> 39.08 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 20, lr: 0.1 -----\n",
            "Epoch: [20][  0/391]\tTime  0.294 ( 0.294)\tLoss 1.1244e+00 (1.1244e+00)\tAcc@1  63.28 ( 63.28)\tAcc@5  93.75 ( 93.75)\n",
            "Epoch: [20][ 30/391]\tTime  0.107 ( 0.101)\tLoss 1.3284e+00 (1.2503e+00)\tAcc@1  63.28 ( 63.96)\tAcc@5  90.62 ( 89.94)\n",
            "Epoch: [20][ 60/391]\tTime  0.092 ( 0.098)\tLoss 1.1274e+00 (1.2230e+00)\tAcc@1  67.19 ( 64.52)\tAcc@5  89.84 ( 90.24)\n",
            "Epoch: [20][ 90/391]\tTime  0.102 ( 0.097)\tLoss 1.2591e+00 (1.2277e+00)\tAcc@1  60.94 ( 64.52)\tAcc@5  89.84 ( 90.10)\n",
            "Epoch: [20][120/391]\tTime  0.102 ( 0.096)\tLoss 1.1604e+00 (1.2393e+00)\tAcc@1  64.06 ( 64.17)\tAcc@5  89.84 ( 90.10)\n",
            "Epoch: [20][150/391]\tTime  0.092 ( 0.095)\tLoss 1.1349e+00 (1.2333e+00)\tAcc@1  65.62 ( 64.40)\tAcc@5  95.31 ( 90.36)\n",
            "Epoch: [20][180/391]\tTime  0.098 ( 0.095)\tLoss 1.1212e+00 (1.2385e+00)\tAcc@1  63.28 ( 64.28)\tAcc@5  91.41 ( 90.32)\n",
            "Epoch: [20][210/391]\tTime  0.095 ( 0.095)\tLoss 1.2521e+00 (1.2413e+00)\tAcc@1  61.72 ( 64.30)\tAcc@5  91.41 ( 90.27)\n",
            "Epoch: [20][240/391]\tTime  0.096 ( 0.095)\tLoss 1.3847e+00 (1.2481e+00)\tAcc@1  60.16 ( 64.08)\tAcc@5  87.50 ( 90.12)\n",
            "Epoch: [20][270/391]\tTime  0.090 ( 0.094)\tLoss 1.2754e+00 (1.2512e+00)\tAcc@1  58.59 ( 64.00)\tAcc@5  93.75 ( 90.11)\n",
            "Epoch: [20][300/391]\tTime  0.095 ( 0.094)\tLoss 1.0824e+00 (1.2565e+00)\tAcc@1  68.75 ( 63.79)\tAcc@5  92.19 ( 90.06)\n",
            "Epoch: [20][330/391]\tTime  0.098 ( 0.094)\tLoss 9.6970e-01 (1.2612e+00)\tAcc@1  71.09 ( 63.73)\tAcc@5  91.41 ( 89.96)\n",
            "Epoch: [20][360/391]\tTime  0.106 ( 0.094)\tLoss 1.3519e+00 (1.2663e+00)\tAcc@1  61.72 ( 63.60)\tAcc@5  89.06 ( 89.91)\n",
            "Epoch: [20][390/391]\tTime  0.082 ( 0.094)\tLoss 1.4023e+00 (1.2709e+00)\tAcc@1  66.25 ( 63.46)\tAcc@5  85.00 ( 89.84)\n",
            "==> Train Accuracy: Acc@1 63.462 || Acc@5 89.842\n",
            "==> Test Accuracy:  Acc@1 58.630 || Acc@5 85.250\n",
            "==> 39.24 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 21, lr: 0.1 -----\n",
            "Epoch: [21][  0/391]\tTime  0.294 ( 0.294)\tLoss 1.3143e+00 (1.3143e+00)\tAcc@1  63.28 ( 63.28)\tAcc@5  92.19 ( 92.19)\n",
            "Epoch: [21][ 30/391]\tTime  0.082 ( 0.101)\tLoss 1.1690e+00 (1.1847e+00)\tAcc@1  70.31 ( 66.23)\tAcc@5  92.19 ( 91.31)\n",
            "Epoch: [21][ 60/391]\tTime  0.091 ( 0.097)\tLoss 1.4285e+00 (1.1663e+00)\tAcc@1  59.38 ( 66.87)\tAcc@5  87.50 ( 91.55)\n",
            "Epoch: [21][ 90/391]\tTime  0.092 ( 0.096)\tLoss 1.6263e+00 (1.1836e+00)\tAcc@1  56.25 ( 66.45)\tAcc@5  85.16 ( 90.93)\n",
            "Epoch: [21][120/391]\tTime  0.093 ( 0.095)\tLoss 1.2758e+00 (1.1928e+00)\tAcc@1  67.19 ( 65.97)\tAcc@5  87.50 ( 90.76)\n",
            "Epoch: [21][150/391]\tTime  0.089 ( 0.095)\tLoss 9.9835e-01 (1.2006e+00)\tAcc@1  71.88 ( 65.57)\tAcc@5  92.97 ( 90.78)\n",
            "Epoch: [21][180/391]\tTime  0.091 ( 0.094)\tLoss 1.1751e+00 (1.2140e+00)\tAcc@1  66.41 ( 65.11)\tAcc@5  90.62 ( 90.67)\n",
            "Epoch: [21][210/391]\tTime  0.097 ( 0.094)\tLoss 1.2639e+00 (1.2256e+00)\tAcc@1  61.72 ( 64.84)\tAcc@5  92.19 ( 90.51)\n",
            "Epoch: [21][240/391]\tTime  0.088 ( 0.094)\tLoss 1.4625e+00 (1.2309e+00)\tAcc@1  60.94 ( 64.66)\tAcc@5  82.03 ( 90.42)\n",
            "Epoch: [21][270/391]\tTime  0.097 ( 0.094)\tLoss 1.3014e+00 (1.2329e+00)\tAcc@1  61.72 ( 64.57)\tAcc@5  89.06 ( 90.40)\n",
            "Epoch: [21][300/391]\tTime  0.092 ( 0.094)\tLoss 1.3867e+00 (1.2368e+00)\tAcc@1  57.81 ( 64.40)\tAcc@5  88.28 ( 90.35)\n",
            "Epoch: [21][330/391]\tTime  0.091 ( 0.094)\tLoss 1.2332e+00 (1.2427e+00)\tAcc@1  64.84 ( 64.30)\tAcc@5  94.53 ( 90.26)\n",
            "Epoch: [21][360/391]\tTime  0.090 ( 0.094)\tLoss 1.4013e+00 (1.2455e+00)\tAcc@1  60.94 ( 64.22)\tAcc@5  86.72 ( 90.25)\n",
            "Epoch: [21][390/391]\tTime  0.081 ( 0.094)\tLoss 1.4070e+00 (1.2506e+00)\tAcc@1  57.50 ( 64.04)\tAcc@5  88.75 ( 90.18)\n",
            "==> Train Accuracy: Acc@1 64.044 || Acc@5 90.176\n",
            "==> Test Accuracy:  Acc@1 55.330 || Acc@5 84.120\n",
            "==> 39.19 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 22, lr: 0.1 -----\n",
            "Epoch: [22][  0/391]\tTime  0.293 ( 0.293)\tLoss 1.1927e+00 (1.1927e+00)\tAcc@1  64.84 ( 64.84)\tAcc@5  91.41 ( 91.41)\n",
            "Epoch: [22][ 30/391]\tTime  0.092 ( 0.101)\tLoss 1.2479e+00 (1.1406e+00)\tAcc@1  57.03 ( 67.11)\tAcc@5  92.97 ( 91.73)\n",
            "Epoch: [22][ 60/391]\tTime  0.092 ( 0.097)\tLoss 1.1680e+00 (1.1600e+00)\tAcc@1  65.62 ( 66.44)\tAcc@5  92.97 ( 91.29)\n",
            "Epoch: [22][ 90/391]\tTime  0.103 ( 0.096)\tLoss 1.2229e+00 (1.1707e+00)\tAcc@1  64.84 ( 65.99)\tAcc@5  89.84 ( 91.21)\n",
            "Epoch: [22][120/391]\tTime  0.092 ( 0.095)\tLoss 1.0166e+00 (1.1812e+00)\tAcc@1  69.53 ( 65.55)\tAcc@5  91.41 ( 91.03)\n",
            "Epoch: [22][150/391]\tTime  0.100 ( 0.095)\tLoss 1.2682e+00 (1.1857e+00)\tAcc@1  63.28 ( 65.43)\tAcc@5  92.19 ( 90.94)\n",
            "Epoch: [22][180/391]\tTime  0.099 ( 0.095)\tLoss 1.3723e+00 (1.1970e+00)\tAcc@1  57.81 ( 65.19)\tAcc@5  88.28 ( 90.78)\n",
            "Epoch: [22][210/391]\tTime  0.089 ( 0.094)\tLoss 1.1271e+00 (1.2039e+00)\tAcc@1  69.53 ( 65.04)\tAcc@5  91.41 ( 90.65)\n",
            "Epoch: [22][240/391]\tTime  0.086 ( 0.094)\tLoss 1.3077e+00 (1.2141e+00)\tAcc@1  58.59 ( 64.68)\tAcc@5  89.06 ( 90.49)\n",
            "Epoch: [22][270/391]\tTime  0.096 ( 0.094)\tLoss 1.5457e+00 (1.2220e+00)\tAcc@1  60.16 ( 64.60)\tAcc@5  89.06 ( 90.37)\n",
            "Epoch: [22][300/391]\tTime  0.100 ( 0.094)\tLoss 1.1938e+00 (1.2271e+00)\tAcc@1  65.62 ( 64.51)\tAcc@5  89.06 ( 90.30)\n",
            "Epoch: [22][330/391]\tTime  0.095 ( 0.094)\tLoss 1.2889e+00 (1.2263e+00)\tAcc@1  59.38 ( 64.56)\tAcc@5  92.19 ( 90.31)\n",
            "Epoch: [22][360/391]\tTime  0.090 ( 0.094)\tLoss 1.2396e+00 (1.2316e+00)\tAcc@1  69.53 ( 64.45)\tAcc@5  87.50 ( 90.19)\n",
            "Epoch: [22][390/391]\tTime  0.081 ( 0.094)\tLoss 1.0764e+00 (1.2313e+00)\tAcc@1  65.00 ( 64.36)\tAcc@5  91.25 ( 90.26)\n",
            "==> Train Accuracy: Acc@1 64.358 || Acc@5 90.262\n",
            "==> Test Accuracy:  Acc@1 58.140 || Acc@5 86.780\n",
            "==> 39.12 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 23, lr: 0.1 -----\n",
            "Epoch: [23][  0/391]\tTime  0.286 ( 0.286)\tLoss 1.1564e+00 (1.1564e+00)\tAcc@1  67.97 ( 67.97)\tAcc@5  90.62 ( 90.62)\n",
            "Epoch: [23][ 30/391]\tTime  0.096 ( 0.100)\tLoss 1.0933e+00 (1.1326e+00)\tAcc@1  65.62 ( 66.63)\tAcc@5  92.97 ( 92.57)\n",
            "Epoch: [23][ 60/391]\tTime  0.092 ( 0.096)\tLoss 1.0838e+00 (1.1521e+00)\tAcc@1  63.28 ( 66.18)\tAcc@5  93.75 ( 92.15)\n",
            "Epoch: [23][ 90/391]\tTime  0.095 ( 0.095)\tLoss 1.1345e+00 (1.1617e+00)\tAcc@1  67.97 ( 66.00)\tAcc@5  91.41 ( 91.71)\n",
            "Epoch: [23][120/391]\tTime  0.079 ( 0.095)\tLoss 1.1763e+00 (1.1672e+00)\tAcc@1  64.84 ( 65.62)\tAcc@5  93.75 ( 91.52)\n",
            "Epoch: [23][150/391]\tTime  0.094 ( 0.094)\tLoss 9.5689e-01 (1.1772e+00)\tAcc@1  71.88 ( 65.36)\tAcc@5  89.84 ( 91.26)\n",
            "Epoch: [23][180/391]\tTime  0.101 ( 0.095)\tLoss 9.5229e-01 (1.1848e+00)\tAcc@1  69.53 ( 65.27)\tAcc@5  93.75 ( 91.05)\n",
            "Epoch: [23][210/391]\tTime  0.105 ( 0.094)\tLoss 1.2270e+00 (1.1934e+00)\tAcc@1  64.06 ( 65.13)\tAcc@5  90.62 ( 90.96)\n",
            "Epoch: [23][240/391]\tTime  0.087 ( 0.094)\tLoss 1.1420e+00 (1.1961e+00)\tAcc@1  64.84 ( 65.12)\tAcc@5  95.31 ( 90.95)\n",
            "Epoch: [23][270/391]\tTime  0.092 ( 0.094)\tLoss 1.3523e+00 (1.2040e+00)\tAcc@1  52.34 ( 64.97)\tAcc@5  92.97 ( 90.83)\n",
            "Epoch: [23][300/391]\tTime  0.096 ( 0.094)\tLoss 1.2284e+00 (1.2092e+00)\tAcc@1  64.84 ( 64.88)\tAcc@5  90.62 ( 90.78)\n",
            "Epoch: [23][330/391]\tTime  0.096 ( 0.094)\tLoss 1.1722e+00 (1.2125e+00)\tAcc@1  65.62 ( 64.79)\tAcc@5  89.84 ( 90.71)\n",
            "Epoch: [23][360/391]\tTime  0.090 ( 0.094)\tLoss 1.3524e+00 (1.2158e+00)\tAcc@1  59.38 ( 64.76)\tAcc@5  91.41 ( 90.66)\n",
            "Epoch: [23][390/391]\tTime  0.082 ( 0.094)\tLoss 1.2163e+00 (1.2181e+00)\tAcc@1  67.50 ( 64.73)\tAcc@5  85.00 ( 90.63)\n",
            "==> Train Accuracy: Acc@1 64.726 || Acc@5 90.632\n",
            "==> Test Accuracy:  Acc@1 54.170 || Acc@5 83.200\n",
            "==> 39.15 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 24, lr: 0.1 -----\n",
            "Epoch: [24][  0/391]\tTime  0.300 ( 0.300)\tLoss 1.2087e+00 (1.2087e+00)\tAcc@1  70.31 ( 70.31)\tAcc@5  89.84 ( 89.84)\n",
            "Epoch: [24][ 30/391]\tTime  0.089 ( 0.100)\tLoss 1.1863e+00 (1.1229e+00)\tAcc@1  68.75 ( 66.91)\tAcc@5  89.84 ( 91.89)\n",
            "Epoch: [24][ 60/391]\tTime  0.092 ( 0.096)\tLoss 1.1836e+00 (1.1224e+00)\tAcc@1  64.06 ( 66.44)\tAcc@5  90.62 ( 92.02)\n",
            "Epoch: [24][ 90/391]\tTime  0.091 ( 0.095)\tLoss 1.1269e+00 (1.1456e+00)\tAcc@1  71.09 ( 66.29)\tAcc@5  91.41 ( 91.60)\n",
            "Epoch: [24][120/391]\tTime  0.097 ( 0.095)\tLoss 9.9575e-01 (1.1623e+00)\tAcc@1  69.53 ( 65.89)\tAcc@5  93.75 ( 91.41)\n",
            "Epoch: [24][150/391]\tTime  0.099 ( 0.095)\tLoss 1.1199e+00 (1.1693e+00)\tAcc@1  64.84 ( 65.82)\tAcc@5  91.41 ( 91.30)\n",
            "Epoch: [24][180/391]\tTime  0.091 ( 0.094)\tLoss 1.3636e+00 (1.1794e+00)\tAcc@1  57.81 ( 65.56)\tAcc@5  89.84 ( 91.27)\n",
            "Epoch: [24][210/391]\tTime  0.093 ( 0.094)\tLoss 1.2975e+00 (1.1834e+00)\tAcc@1  59.38 ( 65.46)\tAcc@5  92.19 ( 91.24)\n",
            "Epoch: [24][240/391]\tTime  0.090 ( 0.094)\tLoss 1.3548e+00 (1.1892e+00)\tAcc@1  61.72 ( 65.35)\tAcc@5  87.50 ( 91.12)\n",
            "Epoch: [24][270/391]\tTime  0.093 ( 0.094)\tLoss 1.3360e+00 (1.1917e+00)\tAcc@1  64.84 ( 65.39)\tAcc@5  90.62 ( 91.06)\n",
            "Epoch: [24][300/391]\tTime  0.093 ( 0.094)\tLoss 9.1024e-01 (1.1965e+00)\tAcc@1  74.22 ( 65.26)\tAcc@5  96.09 ( 91.01)\n",
            "Epoch: [24][330/391]\tTime  0.094 ( 0.094)\tLoss 1.1300e+00 (1.1987e+00)\tAcc@1  67.97 ( 65.19)\tAcc@5  93.75 ( 90.96)\n",
            "Epoch: [24][360/391]\tTime  0.090 ( 0.094)\tLoss 1.3861e+00 (1.2014e+00)\tAcc@1  55.47 ( 65.19)\tAcc@5  90.62 ( 90.90)\n",
            "Epoch: [24][390/391]\tTime  0.082 ( 0.094)\tLoss 1.3350e+00 (1.2077e+00)\tAcc@1  65.00 ( 65.08)\tAcc@5  86.25 ( 90.78)\n",
            "==> Train Accuracy: Acc@1 65.078 || Acc@5 90.784\n",
            "==> Test Accuracy:  Acc@1 55.090 || Acc@5 83.920\n",
            "==> 39.34 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 25, lr: 0.1 -----\n",
            "Epoch: [25][  0/391]\tTime  0.280 ( 0.280)\tLoss 1.0752e+00 (1.0752e+00)\tAcc@1  71.88 ( 71.88)\tAcc@5  90.62 ( 90.62)\n",
            "Epoch: [25][ 30/391]\tTime  0.089 ( 0.102)\tLoss 1.0340e+00 (1.1341e+00)\tAcc@1  71.88 ( 67.16)\tAcc@5  95.31 ( 91.51)\n",
            "Epoch: [25][ 60/391]\tTime  0.097 ( 0.098)\tLoss 1.0671e+00 (1.1199e+00)\tAcc@1  71.88 ( 67.21)\tAcc@5  90.62 ( 91.82)\n",
            "Epoch: [25][ 90/391]\tTime  0.094 ( 0.096)\tLoss 1.0118e+00 (1.1283e+00)\tAcc@1  71.09 ( 67.05)\tAcc@5  90.62 ( 91.65)\n",
            "Epoch: [25][120/391]\tTime  0.090 ( 0.096)\tLoss 1.2884e+00 (1.1308e+00)\tAcc@1  60.94 ( 66.95)\tAcc@5  87.50 ( 91.59)\n",
            "Epoch: [25][150/391]\tTime  0.089 ( 0.095)\tLoss 1.2343e+00 (1.1473e+00)\tAcc@1  65.62 ( 66.46)\tAcc@5  88.28 ( 91.45)\n",
            "Epoch: [25][180/391]\tTime  0.090 ( 0.095)\tLoss 1.1389e+00 (1.1496e+00)\tAcc@1  68.75 ( 66.42)\tAcc@5  91.41 ( 91.47)\n",
            "Epoch: [25][210/391]\tTime  0.091 ( 0.095)\tLoss 1.1059e+00 (1.1578e+00)\tAcc@1  67.97 ( 66.17)\tAcc@5  92.19 ( 91.38)\n",
            "Epoch: [25][240/391]\tTime  0.094 ( 0.094)\tLoss 1.0987e+00 (1.1674e+00)\tAcc@1  71.09 ( 66.03)\tAcc@5  92.19 ( 91.21)\n",
            "Epoch: [25][270/391]\tTime  0.088 ( 0.094)\tLoss 1.3252e+00 (1.1725e+00)\tAcc@1  63.28 ( 65.88)\tAcc@5  89.84 ( 91.15)\n",
            "Epoch: [25][300/391]\tTime  0.091 ( 0.094)\tLoss 1.0981e+00 (1.1829e+00)\tAcc@1  66.41 ( 65.56)\tAcc@5  96.88 ( 91.04)\n",
            "Epoch: [25][330/391]\tTime  0.093 ( 0.094)\tLoss 1.1415e+00 (1.1912e+00)\tAcc@1  66.41 ( 65.41)\tAcc@5  93.75 ( 90.98)\n",
            "Epoch: [25][360/391]\tTime  0.106 ( 0.094)\tLoss 1.0208e+00 (1.1918e+00)\tAcc@1  67.97 ( 65.45)\tAcc@5  89.84 ( 90.95)\n",
            "Epoch: [25][390/391]\tTime  0.082 ( 0.094)\tLoss 1.0215e+00 (1.1940e+00)\tAcc@1  70.00 ( 65.48)\tAcc@5  91.25 ( 90.89)\n",
            "==> Train Accuracy: Acc@1 65.478 || Acc@5 90.892\n",
            "==> Test Accuracy:  Acc@1 57.640 || Acc@5 85.840\n",
            "==> 39.24 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 26, lr: 0.1 -----\n",
            "Epoch: [26][  0/391]\tTime  0.280 ( 0.280)\tLoss 1.1702e+00 (1.1702e+00)\tAcc@1  60.16 ( 60.16)\tAcc@5  94.53 ( 94.53)\n",
            "Epoch: [26][ 30/391]\tTime  0.099 ( 0.101)\tLoss 1.1046e+00 (1.0711e+00)\tAcc@1  66.41 ( 68.37)\tAcc@5  92.97 ( 92.44)\n",
            "Epoch: [26][ 60/391]\tTime  0.091 ( 0.097)\tLoss 1.2219e+00 (1.0858e+00)\tAcc@1  64.06 ( 68.25)\tAcc@5  93.75 ( 92.44)\n",
            "Epoch: [26][ 90/391]\tTime  0.092 ( 0.096)\tLoss 1.1179e+00 (1.1031e+00)\tAcc@1  67.19 ( 68.11)\tAcc@5  92.97 ( 92.24)\n",
            "Epoch: [26][120/391]\tTime  0.101 ( 0.095)\tLoss 1.2478e+00 (1.1192e+00)\tAcc@1  60.94 ( 67.49)\tAcc@5  89.06 ( 92.02)\n",
            "Epoch: [26][150/391]\tTime  0.092 ( 0.095)\tLoss 1.0673e+00 (1.1247e+00)\tAcc@1  69.53 ( 67.46)\tAcc@5  91.41 ( 91.89)\n",
            "Epoch: [26][180/391]\tTime  0.104 ( 0.095)\tLoss 1.1921e+00 (1.1362e+00)\tAcc@1  67.19 ( 67.09)\tAcc@5  89.06 ( 91.66)\n",
            "Epoch: [26][210/391]\tTime  0.095 ( 0.095)\tLoss 1.1453e+00 (1.1403e+00)\tAcc@1  68.75 ( 67.03)\tAcc@5  89.84 ( 91.63)\n",
            "Epoch: [26][240/391]\tTime  0.103 ( 0.095)\tLoss 1.2210e+00 (1.1483e+00)\tAcc@1  63.28 ( 66.71)\tAcc@5  89.84 ( 91.50)\n",
            "Epoch: [26][270/391]\tTime  0.105 ( 0.095)\tLoss 9.9058e-01 (1.1536e+00)\tAcc@1  74.22 ( 66.58)\tAcc@5  91.41 ( 91.46)\n",
            "Epoch: [26][300/391]\tTime  0.092 ( 0.095)\tLoss 1.5163e+00 (1.1611e+00)\tAcc@1  59.38 ( 66.41)\tAcc@5  88.28 ( 91.36)\n",
            "Epoch: [26][330/391]\tTime  0.091 ( 0.094)\tLoss 1.2990e+00 (1.1667e+00)\tAcc@1  64.84 ( 66.28)\tAcc@5  91.41 ( 91.33)\n",
            "Epoch: [26][360/391]\tTime  0.086 ( 0.094)\tLoss 9.2778e-01 (1.1690e+00)\tAcc@1  75.78 ( 66.19)\tAcc@5  94.53 ( 91.30)\n",
            "Epoch: [26][390/391]\tTime  0.082 ( 0.094)\tLoss 1.2165e+00 (1.1719e+00)\tAcc@1  63.75 ( 66.05)\tAcc@5  93.75 ( 91.30)\n",
            "==> Train Accuracy: Acc@1 66.048 || Acc@5 91.296\n",
            "==> Test Accuracy:  Acc@1 59.080 || Acc@5 86.600\n",
            "==> 39.29 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 27, lr: 0.1 -----\n",
            "Epoch: [27][  0/391]\tTime  0.292 ( 0.292)\tLoss 1.0879e+00 (1.0879e+00)\tAcc@1  66.41 ( 66.41)\tAcc@5  89.84 ( 89.84)\n",
            "Epoch: [27][ 30/391]\tTime  0.095 ( 0.102)\tLoss 1.1950e+00 (1.1292e+00)\tAcc@1  63.28 ( 66.81)\tAcc@5  92.19 ( 91.58)\n",
            "Epoch: [27][ 60/391]\tTime  0.081 ( 0.098)\tLoss 1.0207e+00 (1.1304e+00)\tAcc@1  74.22 ( 66.74)\tAcc@5  93.75 ( 91.76)\n",
            "Epoch: [27][ 90/391]\tTime  0.084 ( 0.096)\tLoss 1.0452e+00 (1.1378e+00)\tAcc@1  66.41 ( 66.73)\tAcc@5  93.75 ( 91.68)\n",
            "Epoch: [27][120/391]\tTime  0.095 ( 0.095)\tLoss 1.1652e+00 (1.1355e+00)\tAcc@1  71.88 ( 66.85)\tAcc@5  89.84 ( 91.76)\n",
            "Epoch: [27][150/391]\tTime  0.096 ( 0.095)\tLoss 1.1858e+00 (1.1414e+00)\tAcc@1  58.59 ( 66.68)\tAcc@5  92.19 ( 91.69)\n",
            "Epoch: [27][180/391]\tTime  0.094 ( 0.095)\tLoss 1.2611e+00 (1.1376e+00)\tAcc@1  60.16 ( 66.79)\tAcc@5  92.97 ( 91.73)\n",
            "Epoch: [27][210/391]\tTime  0.096 ( 0.095)\tLoss 1.1536e+00 (1.1445e+00)\tAcc@1  67.97 ( 66.64)\tAcc@5  90.62 ( 91.63)\n",
            "Epoch: [27][240/391]\tTime  0.091 ( 0.094)\tLoss 1.1333e+00 (1.1523e+00)\tAcc@1  66.41 ( 66.41)\tAcc@5  93.75 ( 91.57)\n",
            "Epoch: [27][270/391]\tTime  0.113 ( 0.094)\tLoss 1.1782e+00 (1.1600e+00)\tAcc@1  62.50 ( 66.24)\tAcc@5  92.19 ( 91.44)\n",
            "Epoch: [27][300/391]\tTime  0.093 ( 0.094)\tLoss 1.2898e+00 (1.1630e+00)\tAcc@1  67.19 ( 66.09)\tAcc@5  88.28 ( 91.49)\n",
            "Epoch: [27][330/391]\tTime  0.092 ( 0.094)\tLoss 1.1458e+00 (1.1624e+00)\tAcc@1  67.97 ( 66.04)\tAcc@5  90.62 ( 91.46)\n",
            "Epoch: [27][360/391]\tTime  0.096 ( 0.094)\tLoss 1.2863e+00 (1.1653e+00)\tAcc@1  66.41 ( 65.96)\tAcc@5  89.84 ( 91.44)\n",
            "Epoch: [27][390/391]\tTime  0.082 ( 0.094)\tLoss 9.2868e-01 (1.1680e+00)\tAcc@1  75.00 ( 65.93)\tAcc@5  96.25 ( 91.36)\n",
            "==> Train Accuracy: Acc@1 65.926 || Acc@5 91.364\n",
            "==> Test Accuracy:  Acc@1 51.250 || Acc@5 80.630\n",
            "==> 39.31 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 28, lr: 0.1 -----\n",
            "Epoch: [28][  0/391]\tTime  0.280 ( 0.280)\tLoss 1.1023e+00 (1.1023e+00)\tAcc@1  68.75 ( 68.75)\tAcc@5  92.97 ( 92.97)\n",
            "Epoch: [28][ 30/391]\tTime  0.098 ( 0.101)\tLoss 1.0880e+00 (1.0891e+00)\tAcc@1  67.19 ( 68.52)\tAcc@5  91.41 ( 92.77)\n",
            "Epoch: [28][ 60/391]\tTime  0.095 ( 0.098)\tLoss 1.3434e+00 (1.1091e+00)\tAcc@1  66.41 ( 67.85)\tAcc@5  89.84 ( 92.57)\n",
            "Epoch: [28][ 90/391]\tTime  0.097 ( 0.096)\tLoss 1.0727e+00 (1.1119e+00)\tAcc@1  70.31 ( 67.72)\tAcc@5  93.75 ( 92.35)\n",
            "Epoch: [28][120/391]\tTime  0.091 ( 0.096)\tLoss 1.1504e+00 (1.1250e+00)\tAcc@1  67.97 ( 67.36)\tAcc@5  90.62 ( 92.02)\n",
            "Epoch: [28][150/391]\tTime  0.094 ( 0.095)\tLoss 1.1242e+00 (1.1350e+00)\tAcc@1  70.31 ( 67.16)\tAcc@5  88.28 ( 91.84)\n",
            "Epoch: [28][180/391]\tTime  0.098 ( 0.095)\tLoss 1.4148e+00 (1.1469e+00)\tAcc@1  63.28 ( 66.89)\tAcc@5  85.94 ( 91.62)\n",
            "Epoch: [28][210/391]\tTime  0.094 ( 0.095)\tLoss 9.3415e-01 (1.1499e+00)\tAcc@1  71.09 ( 66.72)\tAcc@5  93.75 ( 91.55)\n",
            "Epoch: [28][240/391]\tTime  0.093 ( 0.094)\tLoss 1.1932e+00 (1.1567e+00)\tAcc@1  69.53 ( 66.55)\tAcc@5  90.62 ( 91.50)\n",
            "Epoch: [28][270/391]\tTime  0.092 ( 0.094)\tLoss 1.1504e+00 (1.1522e+00)\tAcc@1  65.62 ( 66.71)\tAcc@5  93.75 ( 91.49)\n",
            "Epoch: [28][300/391]\tTime  0.095 ( 0.094)\tLoss 9.5800e-01 (1.1512e+00)\tAcc@1  71.88 ( 66.64)\tAcc@5  93.75 ( 91.56)\n",
            "Epoch: [28][330/391]\tTime  0.086 ( 0.094)\tLoss 1.4639e+00 (1.1519e+00)\tAcc@1  58.59 ( 66.58)\tAcc@5  83.59 ( 91.58)\n",
            "Epoch: [28][360/391]\tTime  0.094 ( 0.094)\tLoss 1.3533e+00 (1.1564e+00)\tAcc@1  65.62 ( 66.43)\tAcc@5  90.62 ( 91.53)\n",
            "Epoch: [28][390/391]\tTime  0.082 ( 0.094)\tLoss 1.3207e+00 (1.1627e+00)\tAcc@1  56.25 ( 66.31)\tAcc@5  90.00 ( 91.43)\n",
            "==> Train Accuracy: Acc@1 66.312 || Acc@5 91.434\n",
            "==> Test Accuracy:  Acc@1 56.980 || Acc@5 85.040\n",
            "==> 39.15 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 29, lr: 0.1 -----\n",
            "Epoch: [29][  0/391]\tTime  0.290 ( 0.290)\tLoss 1.0643e+00 (1.0643e+00)\tAcc@1  69.53 ( 69.53)\tAcc@5  91.41 ( 91.41)\n",
            "Epoch: [29][ 30/391]\tTime  0.091 ( 0.100)\tLoss 1.2149e+00 (1.0904e+00)\tAcc@1  64.84 ( 68.22)\tAcc@5  89.84 ( 92.54)\n",
            "Epoch: [29][ 60/391]\tTime  0.092 ( 0.097)\tLoss 1.2018e+00 (1.0880e+00)\tAcc@1  63.28 ( 68.28)\tAcc@5  89.84 ( 92.70)\n",
            "Epoch: [29][ 90/391]\tTime  0.090 ( 0.095)\tLoss 1.2897e+00 (1.1050e+00)\tAcc@1  67.19 ( 67.81)\tAcc@5  88.28 ( 92.48)\n",
            "Epoch: [29][120/391]\tTime  0.091 ( 0.095)\tLoss 1.0695e+00 (1.1121e+00)\tAcc@1  65.62 ( 67.56)\tAcc@5  93.75 ( 92.40)\n",
            "Epoch: [29][150/391]\tTime  0.092 ( 0.095)\tLoss 1.0568e+00 (1.1116e+00)\tAcc@1  70.31 ( 67.70)\tAcc@5  92.97 ( 92.34)\n",
            "Epoch: [29][180/391]\tTime  0.098 ( 0.095)\tLoss 1.0844e+00 (1.1095e+00)\tAcc@1  67.19 ( 67.71)\tAcc@5  92.19 ( 92.38)\n",
            "Epoch: [29][210/391]\tTime  0.092 ( 0.095)\tLoss 1.0053e+00 (1.1188e+00)\tAcc@1  68.75 ( 67.49)\tAcc@5  94.53 ( 92.23)\n",
            "Epoch: [29][240/391]\tTime  0.101 ( 0.095)\tLoss 1.2119e+00 (1.1244e+00)\tAcc@1  63.28 ( 67.31)\tAcc@5  92.19 ( 92.05)\n",
            "Epoch: [29][270/391]\tTime  0.083 ( 0.095)\tLoss 1.3899e+00 (1.1305e+00)\tAcc@1  61.72 ( 67.11)\tAcc@5  87.50 ( 91.94)\n",
            "Epoch: [29][300/391]\tTime  0.092 ( 0.095)\tLoss 1.2994e+00 (1.1361e+00)\tAcc@1  65.62 ( 67.01)\tAcc@5  90.62 ( 91.86)\n",
            "Epoch: [29][330/391]\tTime  0.083 ( 0.095)\tLoss 1.2271e+00 (1.1450e+00)\tAcc@1  65.62 ( 66.81)\tAcc@5  91.41 ( 91.72)\n",
            "Epoch: [29][360/391]\tTime  0.096 ( 0.095)\tLoss 1.2269e+00 (1.1510e+00)\tAcc@1  62.50 ( 66.70)\tAcc@5  90.62 ( 91.60)\n",
            "Epoch: [29][390/391]\tTime  0.081 ( 0.094)\tLoss 1.0071e+00 (1.1538e+00)\tAcc@1  71.25 ( 66.62)\tAcc@5  96.25 ( 91.53)\n",
            "==> Train Accuracy: Acc@1 66.622 || Acc@5 91.526\n",
            "==> Test Accuracy:  Acc@1 58.730 || Acc@5 87.200\n",
            "==> 39.38 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 30, lr: 0.1 -----\n",
            "Epoch: [30][  0/391]\tTime  0.284 ( 0.284)\tLoss 1.0926e+00 (1.0926e+00)\tAcc@1  67.97 ( 67.97)\tAcc@5  91.41 ( 91.41)\n",
            "Epoch: [30][ 30/391]\tTime  0.097 ( 0.101)\tLoss 9.9901e-01 (1.0561e+00)\tAcc@1  71.88 ( 69.68)\tAcc@5  92.19 ( 92.62)\n",
            "Epoch: [30][ 60/391]\tTime  0.093 ( 0.097)\tLoss 1.3092e+00 (1.0624e+00)\tAcc@1  64.06 ( 69.20)\tAcc@5  89.06 ( 92.42)\n",
            "Epoch: [30][ 90/391]\tTime  0.092 ( 0.096)\tLoss 9.9005e-01 (1.0811e+00)\tAcc@1  67.97 ( 68.52)\tAcc@5  94.53 ( 92.48)\n",
            "Epoch: [30][120/391]\tTime  0.105 ( 0.095)\tLoss 8.8427e-01 (1.0947e+00)\tAcc@1  75.78 ( 68.32)\tAcc@5  93.75 ( 92.16)\n",
            "Epoch: [30][150/391]\tTime  0.092 ( 0.095)\tLoss 1.0674e+00 (1.1069e+00)\tAcc@1  70.31 ( 67.88)\tAcc@5  92.97 ( 91.92)\n",
            "Epoch: [30][180/391]\tTime  0.097 ( 0.095)\tLoss 1.2186e+00 (1.1116e+00)\tAcc@1  67.19 ( 67.67)\tAcc@5  89.06 ( 91.86)\n",
            "Epoch: [30][210/391]\tTime  0.098 ( 0.094)\tLoss 1.2730e+00 (1.1178e+00)\tAcc@1  64.84 ( 67.50)\tAcc@5  87.50 ( 91.85)\n",
            "Epoch: [30][240/391]\tTime  0.080 ( 0.094)\tLoss 1.2970e+00 (1.1248e+00)\tAcc@1  65.62 ( 67.37)\tAcc@5  91.41 ( 91.80)\n",
            "Epoch: [30][270/391]\tTime  0.095 ( 0.094)\tLoss 1.2002e+00 (1.1304e+00)\tAcc@1  67.97 ( 67.22)\tAcc@5  91.41 ( 91.72)\n",
            "Epoch: [30][300/391]\tTime  0.095 ( 0.094)\tLoss 1.0271e+00 (1.1347e+00)\tAcc@1  66.41 ( 67.06)\tAcc@5  92.97 ( 91.66)\n",
            "Epoch: [30][330/391]\tTime  0.093 ( 0.094)\tLoss 1.2336e+00 (1.1374e+00)\tAcc@1  67.97 ( 66.99)\tAcc@5  89.84 ( 91.61)\n",
            "Epoch: [30][360/391]\tTime  0.091 ( 0.094)\tLoss 1.2395e+00 (1.1382e+00)\tAcc@1  67.19 ( 66.97)\tAcc@5  89.06 ( 91.56)\n",
            "Epoch: [30][390/391]\tTime  0.082 ( 0.094)\tLoss 1.1190e+00 (1.1407e+00)\tAcc@1  67.50 ( 66.92)\tAcc@5  93.75 ( 91.55)\n",
            "==> Train Accuracy: Acc@1 66.916 || Acc@5 91.552\n",
            "==> Test Accuracy:  Acc@1 56.520 || Acc@5 84.730\n",
            "==> 39.24 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 31, lr: 0.1 -----\n",
            "Epoch: [31][  0/391]\tTime  0.301 ( 0.301)\tLoss 1.2576e+00 (1.2576e+00)\tAcc@1  64.84 ( 64.84)\tAcc@5  91.41 ( 91.41)\n",
            "Epoch: [31][ 30/391]\tTime  0.103 ( 0.103)\tLoss 1.0524e+00 (1.0234e+00)\tAcc@1  71.88 ( 69.76)\tAcc@5  89.84 ( 93.52)\n",
            "Epoch: [31][ 60/391]\tTime  0.081 ( 0.099)\tLoss 9.0880e-01 (1.0267e+00)\tAcc@1  71.09 ( 69.80)\tAcc@5  98.44 ( 93.44)\n",
            "Epoch: [31][ 90/391]\tTime  0.098 ( 0.098)\tLoss 1.0037e+00 (1.0496e+00)\tAcc@1  70.31 ( 69.19)\tAcc@5  94.53 ( 93.18)\n",
            "Epoch: [31][120/391]\tTime  0.091 ( 0.097)\tLoss 1.0645e+00 (1.0609e+00)\tAcc@1  63.28 ( 68.80)\tAcc@5  93.75 ( 92.92)\n",
            "Epoch: [31][150/391]\tTime  0.096 ( 0.097)\tLoss 9.6850e-01 (1.0739e+00)\tAcc@1  74.22 ( 68.51)\tAcc@5  93.75 ( 92.69)\n",
            "Epoch: [31][180/391]\tTime  0.097 ( 0.096)\tLoss 1.1973e+00 (1.0855e+00)\tAcc@1  62.50 ( 68.28)\tAcc@5  89.84 ( 92.46)\n",
            "Epoch: [31][210/391]\tTime  0.096 ( 0.096)\tLoss 9.0876e-01 (1.0973e+00)\tAcc@1  71.88 ( 67.98)\tAcc@5  94.53 ( 92.35)\n",
            "Epoch: [31][240/391]\tTime  0.091 ( 0.095)\tLoss 1.1217e+00 (1.1021e+00)\tAcc@1  67.97 ( 67.92)\tAcc@5  92.19 ( 92.25)\n",
            "Epoch: [31][270/391]\tTime  0.094 ( 0.095)\tLoss 1.1789e+00 (1.1107e+00)\tAcc@1  65.62 ( 67.67)\tAcc@5  92.97 ( 92.15)\n",
            "Epoch: [31][300/391]\tTime  0.099 ( 0.095)\tLoss 1.3053e+00 (1.1211e+00)\tAcc@1  63.28 ( 67.38)\tAcc@5  88.28 ( 92.00)\n",
            "Epoch: [31][330/391]\tTime  0.088 ( 0.095)\tLoss 1.3508e+00 (1.1259e+00)\tAcc@1  62.50 ( 67.22)\tAcc@5  89.84 ( 91.92)\n",
            "Epoch: [31][360/391]\tTime  0.089 ( 0.095)\tLoss 1.5752e+00 (1.1324e+00)\tAcc@1  57.03 ( 67.06)\tAcc@5  85.16 ( 91.80)\n",
            "Epoch: [31][390/391]\tTime  0.082 ( 0.094)\tLoss 1.2744e+00 (1.1388e+00)\tAcc@1  63.75 ( 66.87)\tAcc@5  91.25 ( 91.70)\n",
            "==> Train Accuracy: Acc@1 66.872 || Acc@5 91.696\n",
            "==> Test Accuracy:  Acc@1 57.040 || Acc@5 84.390\n",
            "==> 39.52 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 32, lr: 0.1 -----\n",
            "Epoch: [32][  0/391]\tTime  0.288 ( 0.288)\tLoss 9.6873e-01 (9.6873e-01)\tAcc@1  74.22 ( 74.22)\tAcc@5  93.75 ( 93.75)\n",
            "Epoch: [32][ 30/391]\tTime  0.096 ( 0.101)\tLoss 1.1114e+00 (1.0046e+00)\tAcc@1  67.19 ( 70.51)\tAcc@5  93.75 ( 93.50)\n",
            "Epoch: [32][ 60/391]\tTime  0.092 ( 0.098)\tLoss 1.1479e+00 (1.0286e+00)\tAcc@1  65.62 ( 70.04)\tAcc@5  91.41 ( 92.87)\n",
            "Epoch: [32][ 90/391]\tTime  0.106 ( 0.097)\tLoss 1.1467e+00 (1.0368e+00)\tAcc@1  62.50 ( 69.73)\tAcc@5  94.53 ( 92.99)\n",
            "Epoch: [32][120/391]\tTime  0.088 ( 0.096)\tLoss 1.1705e+00 (1.0452e+00)\tAcc@1  65.62 ( 69.49)\tAcc@5  92.19 ( 92.90)\n",
            "Epoch: [32][150/391]\tTime  0.093 ( 0.096)\tLoss 1.3796e+00 (1.0731e+00)\tAcc@1  60.94 ( 68.64)\tAcc@5  89.84 ( 92.62)\n",
            "Epoch: [32][180/391]\tTime  0.092 ( 0.095)\tLoss 1.1880e+00 (1.0840e+00)\tAcc@1  67.97 ( 68.48)\tAcc@5  95.31 ( 92.53)\n",
            "Epoch: [32][210/391]\tTime  0.095 ( 0.095)\tLoss 1.0377e+00 (1.0939e+00)\tAcc@1  71.88 ( 68.21)\tAcc@5  92.19 ( 92.42)\n",
            "Epoch: [32][240/391]\tTime  0.084 ( 0.095)\tLoss 1.1857e+00 (1.1056e+00)\tAcc@1  70.31 ( 67.89)\tAcc@5  90.62 ( 92.20)\n",
            "Epoch: [32][270/391]\tTime  0.096 ( 0.095)\tLoss 1.0471e+00 (1.1124e+00)\tAcc@1  70.31 ( 67.66)\tAcc@5  92.19 ( 92.14)\n",
            "Epoch: [32][300/391]\tTime  0.090 ( 0.095)\tLoss 1.0430e+00 (1.1170e+00)\tAcc@1  69.53 ( 67.55)\tAcc@5  91.41 ( 92.08)\n",
            "Epoch: [32][330/391]\tTime  0.095 ( 0.095)\tLoss 1.1110e+00 (1.1178e+00)\tAcc@1  65.62 ( 67.57)\tAcc@5  92.19 ( 92.01)\n",
            "Epoch: [32][360/391]\tTime  0.096 ( 0.095)\tLoss 1.1747e+00 (1.1232e+00)\tAcc@1  65.62 ( 67.46)\tAcc@5  92.19 ( 91.94)\n",
            "Epoch: [32][390/391]\tTime  0.081 ( 0.095)\tLoss 1.1502e+00 (1.1270e+00)\tAcc@1  66.25 ( 67.34)\tAcc@5  93.75 ( 91.88)\n",
            "==> Train Accuracy: Acc@1 67.340 || Acc@5 91.884\n",
            "==> Test Accuracy:  Acc@1 57.070 || Acc@5 83.940\n",
            "==> 39.48 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 33, lr: 0.1 -----\n",
            "Epoch: [33][  0/391]\tTime  0.294 ( 0.294)\tLoss 8.8642e-01 (8.8642e-01)\tAcc@1  71.09 ( 71.09)\tAcc@5  93.75 ( 93.75)\n",
            "Epoch: [33][ 30/391]\tTime  0.095 ( 0.101)\tLoss 9.6650e-01 (1.0511e+00)\tAcc@1  73.44 ( 69.71)\tAcc@5  94.53 ( 92.44)\n",
            "Epoch: [33][ 60/391]\tTime  0.091 ( 0.097)\tLoss 1.1376e+00 (1.0570e+00)\tAcc@1  67.19 ( 68.92)\tAcc@5  92.19 ( 92.56)\n",
            "Epoch: [33][ 90/391]\tTime  0.088 ( 0.096)\tLoss 9.3716e-01 (1.0478e+00)\tAcc@1  70.31 ( 69.32)\tAcc@5  94.53 ( 92.67)\n",
            "Epoch: [33][120/391]\tTime  0.093 ( 0.095)\tLoss 8.6542e-01 (1.0512e+00)\tAcc@1  74.22 ( 69.23)\tAcc@5  95.31 ( 92.67)\n",
            "Epoch: [33][150/391]\tTime  0.095 ( 0.095)\tLoss 1.1578e+00 (1.0736e+00)\tAcc@1  70.31 ( 68.74)\tAcc@5  91.41 ( 92.42)\n",
            "Epoch: [33][180/391]\tTime  0.086 ( 0.094)\tLoss 9.3560e-01 (1.0841e+00)\tAcc@1  73.44 ( 68.43)\tAcc@5  95.31 ( 92.32)\n",
            "Epoch: [33][210/391]\tTime  0.094 ( 0.094)\tLoss 1.1275e+00 (1.0872e+00)\tAcc@1  67.97 ( 68.33)\tAcc@5  90.62 ( 92.27)\n",
            "Epoch: [33][240/391]\tTime  0.097 ( 0.094)\tLoss 1.1634e+00 (1.0967e+00)\tAcc@1  61.72 ( 68.03)\tAcc@5  92.97 ( 92.14)\n",
            "Epoch: [33][270/391]\tTime  0.091 ( 0.094)\tLoss 1.1718e+00 (1.1024e+00)\tAcc@1  67.97 ( 67.82)\tAcc@5  91.41 ( 92.05)\n",
            "Epoch: [33][300/391]\tTime  0.090 ( 0.094)\tLoss 1.0992e+00 (1.1057e+00)\tAcc@1  68.75 ( 67.76)\tAcc@5  90.62 ( 92.00)\n",
            "Epoch: [33][330/391]\tTime  0.094 ( 0.094)\tLoss 1.2918e+00 (1.1129e+00)\tAcc@1  65.62 ( 67.54)\tAcc@5  89.06 ( 91.95)\n",
            "Epoch: [33][360/391]\tTime  0.093 ( 0.094)\tLoss 1.1081e+00 (1.1172e+00)\tAcc@1  71.09 ( 67.46)\tAcc@5  89.06 ( 91.90)\n",
            "Epoch: [33][390/391]\tTime  0.082 ( 0.094)\tLoss 1.4367e+00 (1.1230e+00)\tAcc@1  60.00 ( 67.32)\tAcc@5  87.50 ( 91.82)\n",
            "==> Train Accuracy: Acc@1 67.320 || Acc@5 91.816\n",
            "==> Test Accuracy:  Acc@1 58.510 || Acc@5 85.240\n",
            "==> 39.17 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 34, lr: 0.1 -----\n",
            "Epoch: [34][  0/391]\tTime  0.286 ( 0.286)\tLoss 1.0637e+00 (1.0637e+00)\tAcc@1  67.19 ( 67.19)\tAcc@5  92.97 ( 92.97)\n",
            "Epoch: [34][ 30/391]\tTime  0.086 ( 0.101)\tLoss 1.0000e+00 (9.6757e-01)\tAcc@1  70.31 ( 71.22)\tAcc@5  96.09 ( 94.33)\n",
            "Epoch: [34][ 60/391]\tTime  0.085 ( 0.097)\tLoss 1.0407e+00 (9.9070e-01)\tAcc@1  71.09 ( 70.86)\tAcc@5  94.53 ( 93.70)\n",
            "Epoch: [34][ 90/391]\tTime  0.092 ( 0.096)\tLoss 9.3497e-01 (1.0102e+00)\tAcc@1  68.75 ( 70.23)\tAcc@5  92.19 ( 93.28)\n",
            "Epoch: [34][120/391]\tTime  0.101 ( 0.096)\tLoss 1.1407e+00 (1.0352e+00)\tAcc@1  67.19 ( 69.64)\tAcc@5  91.41 ( 93.01)\n",
            "Epoch: [34][150/391]\tTime  0.104 ( 0.095)\tLoss 1.2089e+00 (1.0553e+00)\tAcc@1  65.62 ( 69.13)\tAcc@5  92.19 ( 92.70)\n",
            "Epoch: [34][180/391]\tTime  0.092 ( 0.095)\tLoss 1.0935e+00 (1.0614e+00)\tAcc@1  68.75 ( 68.97)\tAcc@5  91.41 ( 92.64)\n",
            "Epoch: [34][210/391]\tTime  0.090 ( 0.095)\tLoss 9.5689e-01 (1.0705e+00)\tAcc@1  69.53 ( 68.79)\tAcc@5  93.75 ( 92.51)\n",
            "Epoch: [34][240/391]\tTime  0.093 ( 0.095)\tLoss 1.0917e+00 (1.0775e+00)\tAcc@1  68.75 ( 68.66)\tAcc@5  89.84 ( 92.46)\n",
            "Epoch: [34][270/391]\tTime  0.098 ( 0.095)\tLoss 1.2280e+00 (1.0810e+00)\tAcc@1  65.62 ( 68.56)\tAcc@5  89.06 ( 92.40)\n",
            "Epoch: [34][300/391]\tTime  0.096 ( 0.095)\tLoss 1.2626e+00 (1.0922e+00)\tAcc@1  61.72 ( 68.28)\tAcc@5  89.06 ( 92.22)\n",
            "Epoch: [34][330/391]\tTime  0.097 ( 0.095)\tLoss 1.1851e+00 (1.1000e+00)\tAcc@1  70.31 ( 68.06)\tAcc@5  90.62 ( 92.14)\n",
            "Epoch: [34][360/391]\tTime  0.095 ( 0.095)\tLoss 1.1400e+00 (1.1039e+00)\tAcc@1  69.53 ( 67.99)\tAcc@5  88.28 ( 92.09)\n",
            "Epoch: [34][390/391]\tTime  0.078 ( 0.094)\tLoss 9.9070e-01 (1.1069e+00)\tAcc@1  77.50 ( 67.90)\tAcc@5  91.25 ( 92.07)\n",
            "==> Train Accuracy: Acc@1 67.896 || Acc@5 92.074\n",
            "==> Test Accuracy:  Acc@1 55.640 || Acc@5 84.110\n",
            "==> 39.37 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 35, lr: 0.1 -----\n",
            "Epoch: [35][  0/391]\tTime  0.295 ( 0.295)\tLoss 9.7316e-01 (9.7316e-01)\tAcc@1  71.09 ( 71.09)\tAcc@5  95.31 ( 95.31)\n",
            "Epoch: [35][ 30/391]\tTime  0.099 ( 0.102)\tLoss 1.0545e+00 (1.0580e+00)\tAcc@1  74.22 ( 69.13)\tAcc@5  92.19 ( 92.99)\n",
            "Epoch: [35][ 60/391]\tTime  0.092 ( 0.098)\tLoss 1.0264e+00 (1.0632e+00)\tAcc@1  70.31 ( 69.03)\tAcc@5  92.19 ( 92.89)\n",
            "Epoch: [35][ 90/391]\tTime  0.101 ( 0.097)\tLoss 1.0620e+00 (1.0640e+00)\tAcc@1  67.19 ( 68.90)\tAcc@5  93.75 ( 92.82)\n",
            "Epoch: [35][120/391]\tTime  0.091 ( 0.096)\tLoss 1.0946e+00 (1.0714e+00)\tAcc@1  68.75 ( 68.65)\tAcc@5  92.19 ( 92.78)\n",
            "Epoch: [35][150/391]\tTime  0.095 ( 0.095)\tLoss 1.1792e+00 (1.0807e+00)\tAcc@1  60.94 ( 68.30)\tAcc@5  93.75 ( 92.61)\n",
            "Epoch: [35][180/391]\tTime  0.095 ( 0.095)\tLoss 1.0764e+00 (1.0805e+00)\tAcc@1  63.28 ( 68.31)\tAcc@5  94.53 ( 92.54)\n",
            "Epoch: [35][210/391]\tTime  0.094 ( 0.095)\tLoss 1.3604e+00 (1.0875e+00)\tAcc@1  64.06 ( 68.09)\tAcc@5  88.28 ( 92.45)\n",
            "Epoch: [35][240/391]\tTime  0.098 ( 0.095)\tLoss 1.2052e+00 (1.0908e+00)\tAcc@1  64.84 ( 68.07)\tAcc@5  90.62 ( 92.32)\n",
            "Epoch: [35][270/391]\tTime  0.091 ( 0.095)\tLoss 1.1210e+00 (1.1011e+00)\tAcc@1  69.53 ( 67.82)\tAcc@5  89.84 ( 92.18)\n",
            "Epoch: [35][300/391]\tTime  0.096 ( 0.094)\tLoss 9.4384e-01 (1.1016e+00)\tAcc@1  74.22 ( 67.84)\tAcc@5  92.97 ( 92.18)\n",
            "Epoch: [35][330/391]\tTime  0.098 ( 0.094)\tLoss 1.0906e+00 (1.1052e+00)\tAcc@1  74.22 ( 67.77)\tAcc@5  91.41 ( 92.13)\n",
            "Epoch: [35][360/391]\tTime  0.100 ( 0.094)\tLoss 1.2103e+00 (1.1093e+00)\tAcc@1  64.84 ( 67.70)\tAcc@5  91.41 ( 92.07)\n",
            "Epoch: [35][390/391]\tTime  0.082 ( 0.094)\tLoss 1.3288e+00 (1.1105e+00)\tAcc@1  66.25 ( 67.67)\tAcc@5  91.25 ( 92.06)\n",
            "==> Train Accuracy: Acc@1 67.672 || Acc@5 92.060\n",
            "==> Test Accuracy:  Acc@1 60.000 || Acc@5 87.470\n",
            "==> 39.35 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 36, lr: 0.1 -----\n",
            "Epoch: [36][  0/391]\tTime  0.287 ( 0.287)\tLoss 1.0178e+00 (1.0178e+00)\tAcc@1  65.62 ( 65.62)\tAcc@5  91.41 ( 91.41)\n",
            "Epoch: [36][ 30/391]\tTime  0.087 ( 0.103)\tLoss 1.0091e+00 (1.0139e+00)\tAcc@1  69.53 ( 70.51)\tAcc@5  92.97 ( 93.32)\n",
            "Epoch: [36][ 60/391]\tTime  0.096 ( 0.098)\tLoss 1.0142e+00 (1.0250e+00)\tAcc@1  69.53 ( 70.13)\tAcc@5  93.75 ( 93.19)\n",
            "Epoch: [36][ 90/391]\tTime  0.092 ( 0.096)\tLoss 1.1061e+00 (1.0288e+00)\tAcc@1  67.97 ( 69.87)\tAcc@5  89.06 ( 93.16)\n",
            "Epoch: [36][120/391]\tTime  0.093 ( 0.095)\tLoss 8.4156e-01 (1.0405e+00)\tAcc@1  73.44 ( 69.42)\tAcc@5  97.66 ( 93.00)\n",
            "Epoch: [36][150/391]\tTime  0.104 ( 0.095)\tLoss 1.2733e+00 (1.0465e+00)\tAcc@1  59.38 ( 69.10)\tAcc@5  90.62 ( 92.89)\n",
            "Epoch: [36][180/391]\tTime  0.100 ( 0.095)\tLoss 1.1036e+00 (1.0619e+00)\tAcc@1  69.53 ( 68.76)\tAcc@5  94.53 ( 92.71)\n",
            "Epoch: [36][210/391]\tTime  0.093 ( 0.095)\tLoss 1.3204e+00 (1.0712e+00)\tAcc@1  66.41 ( 68.53)\tAcc@5  88.28 ( 92.57)\n",
            "Epoch: [36][240/391]\tTime  0.092 ( 0.095)\tLoss 9.8608e-01 (1.0757e+00)\tAcc@1  69.53 ( 68.59)\tAcc@5  92.97 ( 92.55)\n",
            "Epoch: [36][270/391]\tTime  0.086 ( 0.094)\tLoss 1.1845e+00 (1.0831e+00)\tAcc@1  71.88 ( 68.44)\tAcc@5  89.84 ( 92.41)\n",
            "Epoch: [36][300/391]\tTime  0.092 ( 0.094)\tLoss 1.1642e+00 (1.0892e+00)\tAcc@1  67.97 ( 68.28)\tAcc@5  93.75 ( 92.34)\n",
            "Epoch: [36][330/391]\tTime  0.095 ( 0.094)\tLoss 1.0350e+00 (1.0948e+00)\tAcc@1  69.53 ( 68.14)\tAcc@5  92.19 ( 92.29)\n",
            "Epoch: [36][360/391]\tTime  0.095 ( 0.094)\tLoss 1.0839e+00 (1.0959e+00)\tAcc@1  68.75 ( 68.08)\tAcc@5  89.84 ( 92.28)\n",
            "Epoch: [36][390/391]\tTime  0.082 ( 0.094)\tLoss 1.1104e+00 (1.1013e+00)\tAcc@1  67.50 ( 67.93)\tAcc@5  90.00 ( 92.20)\n",
            "==> Train Accuracy: Acc@1 67.930 || Acc@5 92.200\n",
            "==> Test Accuracy:  Acc@1 59.000 || Acc@5 86.260\n",
            "==> 39.24 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 37, lr: 0.1 -----\n",
            "Epoch: [37][  0/391]\tTime  0.278 ( 0.278)\tLoss 1.0613e+00 (1.0613e+00)\tAcc@1  71.09 ( 71.09)\tAcc@5  91.41 ( 91.41)\n",
            "Epoch: [37][ 30/391]\tTime  0.093 ( 0.099)\tLoss 7.4598e-01 (9.2627e-01)\tAcc@1  73.44 ( 72.18)\tAcc@5  97.66 ( 94.46)\n",
            "Epoch: [37][ 60/391]\tTime  0.089 ( 0.096)\tLoss 1.1371e+00 (9.7041e-01)\tAcc@1  69.53 ( 70.74)\tAcc@5  88.28 ( 93.83)\n",
            "Epoch: [37][ 90/391]\tTime  0.088 ( 0.096)\tLoss 8.6557e-01 (9.9964e-01)\tAcc@1  79.69 ( 70.26)\tAcc@5  91.41 ( 93.43)\n",
            "Epoch: [37][120/391]\tTime  0.096 ( 0.095)\tLoss 9.9501e-01 (1.0304e+00)\tAcc@1  72.66 ( 69.74)\tAcc@5  92.97 ( 93.04)\n",
            "Epoch: [37][150/391]\tTime  0.091 ( 0.095)\tLoss 1.2034e+00 (1.0394e+00)\tAcc@1  67.97 ( 69.55)\tAcc@5  85.94 ( 92.94)\n",
            "Epoch: [37][180/391]\tTime  0.092 ( 0.095)\tLoss 1.2410e+00 (1.0499e+00)\tAcc@1  63.28 ( 69.22)\tAcc@5  89.06 ( 92.87)\n",
            "Epoch: [37][210/391]\tTime  0.091 ( 0.095)\tLoss 9.6628e-01 (1.0622e+00)\tAcc@1  72.66 ( 68.81)\tAcc@5  92.97 ( 92.72)\n",
            "Epoch: [37][240/391]\tTime  0.085 ( 0.095)\tLoss 1.1355e+00 (1.0700e+00)\tAcc@1  69.53 ( 68.65)\tAcc@5  89.06 ( 92.63)\n",
            "Epoch: [37][270/391]\tTime  0.094 ( 0.095)\tLoss 1.1640e+00 (1.0790e+00)\tAcc@1  65.62 ( 68.40)\tAcc@5  90.62 ( 92.55)\n",
            "Epoch: [37][300/391]\tTime  0.096 ( 0.095)\tLoss 1.0822e+00 (1.0793e+00)\tAcc@1  70.31 ( 68.45)\tAcc@5  90.62 ( 92.54)\n",
            "Epoch: [37][330/391]\tTime  0.091 ( 0.095)\tLoss 1.0881e+00 (1.0817e+00)\tAcc@1  69.53 ( 68.46)\tAcc@5  90.62 ( 92.46)\n",
            "Epoch: [37][360/391]\tTime  0.091 ( 0.095)\tLoss 1.3765e+00 (1.0884e+00)\tAcc@1  58.59 ( 68.32)\tAcc@5  89.84 ( 92.39)\n",
            "Epoch: [37][390/391]\tTime  0.081 ( 0.094)\tLoss 1.5626e+00 (1.0925e+00)\tAcc@1  56.25 ( 68.22)\tAcc@5  85.00 ( 92.35)\n",
            "==> Train Accuracy: Acc@1 68.224 || Acc@5 92.346\n",
            "==> Test Accuracy:  Acc@1 56.800 || Acc@5 85.020\n",
            "==> 39.46 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 38, lr: 0.1 -----\n",
            "Epoch: [38][  0/391]\tTime  0.287 ( 0.287)\tLoss 9.9521e-01 (9.9521e-01)\tAcc@1  72.66 ( 72.66)\tAcc@5  89.84 ( 89.84)\n",
            "Epoch: [38][ 30/391]\tTime  0.104 ( 0.103)\tLoss 9.2091e-01 (9.9068e-01)\tAcc@1  73.44 ( 70.19)\tAcc@5  95.31 ( 93.60)\n",
            "Epoch: [38][ 60/391]\tTime  0.110 ( 0.100)\tLoss 1.0321e+00 (1.0059e+00)\tAcc@1  67.19 ( 69.71)\tAcc@5  95.31 ( 93.34)\n",
            "Epoch: [38][ 90/391]\tTime  0.089 ( 0.099)\tLoss 1.2868e+00 (1.0191e+00)\tAcc@1  60.16 ( 69.53)\tAcc@5  90.62 ( 93.11)\n",
            "Epoch: [38][120/391]\tTime  0.081 ( 0.098)\tLoss 1.1361e+00 (1.0363e+00)\tAcc@1  67.19 ( 69.20)\tAcc@5  91.41 ( 92.95)\n",
            "Epoch: [38][150/391]\tTime  0.103 ( 0.098)\tLoss 1.0043e+00 (1.0462e+00)\tAcc@1  66.41 ( 69.03)\tAcc@5  96.88 ( 92.83)\n",
            "Epoch: [38][180/391]\tTime  0.101 ( 0.097)\tLoss 1.1219e+00 (1.0587e+00)\tAcc@1  67.19 ( 68.66)\tAcc@5  91.41 ( 92.61)\n",
            "Epoch: [38][210/391]\tTime  0.113 ( 0.097)\tLoss 1.2568e+00 (1.0697e+00)\tAcc@1  62.50 ( 68.48)\tAcc@5  92.97 ( 92.53)\n",
            "Epoch: [38][240/391]\tTime  0.090 ( 0.097)\tLoss 1.0418e+00 (1.0764e+00)\tAcc@1  67.19 ( 68.43)\tAcc@5  95.31 ( 92.41)\n",
            "Epoch: [38][270/391]\tTime  0.103 ( 0.097)\tLoss 1.0563e+00 (1.0776e+00)\tAcc@1  70.31 ( 68.38)\tAcc@5  95.31 ( 92.46)\n",
            "Epoch: [38][300/391]\tTime  0.108 ( 0.097)\tLoss 1.1570e+00 (1.0843e+00)\tAcc@1  67.19 ( 68.19)\tAcc@5  90.62 ( 92.36)\n",
            "Epoch: [38][330/391]\tTime  0.080 ( 0.097)\tLoss 1.2026e+00 (1.0864e+00)\tAcc@1  67.97 ( 68.19)\tAcc@5  90.62 ( 92.31)\n",
            "Epoch: [38][360/391]\tTime  0.094 ( 0.096)\tLoss 1.0884e+00 (1.0911e+00)\tAcc@1  68.75 ( 68.01)\tAcc@5  94.53 ( 92.33)\n",
            "Epoch: [38][390/391]\tTime  0.082 ( 0.096)\tLoss 1.0151e+00 (1.0944e+00)\tAcc@1  72.50 ( 67.97)\tAcc@5  96.25 ( 92.30)\n",
            "==> Train Accuracy: Acc@1 67.974 || Acc@5 92.304\n",
            "==> Test Accuracy:  Acc@1 60.460 || Acc@5 86.830\n",
            "==> 40.37 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 39, lr: 0.1 -----\n",
            "Epoch: [39][  0/391]\tTime  0.315 ( 0.315)\tLoss 1.1955e+00 (1.1955e+00)\tAcc@1  64.84 ( 64.84)\tAcc@5  92.19 ( 92.19)\n",
            "Epoch: [39][ 30/391]\tTime  0.092 ( 0.104)\tLoss 1.0303e+00 (1.0184e+00)\tAcc@1  71.09 ( 70.34)\tAcc@5  92.19 ( 93.67)\n",
            "Epoch: [39][ 60/391]\tTime  0.110 ( 0.100)\tLoss 1.0194e+00 (1.0248e+00)\tAcc@1  67.97 ( 69.71)\tAcc@5  92.97 ( 93.49)\n",
            "Epoch: [39][ 90/391]\tTime  0.088 ( 0.098)\tLoss 1.3384e+00 (1.0364e+00)\tAcc@1  58.59 ( 69.45)\tAcc@5  89.06 ( 93.11)\n",
            "Epoch: [39][120/391]\tTime  0.087 ( 0.097)\tLoss 9.4220e-01 (1.0452e+00)\tAcc@1  71.88 ( 69.31)\tAcc@5  92.97 ( 93.07)\n",
            "Epoch: [39][150/391]\tTime  0.097 ( 0.097)\tLoss 1.0728e+00 (1.0498e+00)\tAcc@1  70.31 ( 69.14)\tAcc@5  92.19 ( 92.96)\n",
            "Epoch: [39][180/391]\tTime  0.100 ( 0.096)\tLoss 1.1611e+00 (1.0600e+00)\tAcc@1  64.06 ( 68.75)\tAcc@5  92.97 ( 92.84)\n",
            "Epoch: [39][210/391]\tTime  0.087 ( 0.096)\tLoss 8.0258e-01 (1.0658e+00)\tAcc@1  78.91 ( 68.67)\tAcc@5  94.53 ( 92.73)\n",
            "Epoch: [39][240/391]\tTime  0.091 ( 0.096)\tLoss 1.0784e+00 (1.0722e+00)\tAcc@1  68.75 ( 68.52)\tAcc@5  92.19 ( 92.62)\n",
            "Epoch: [39][270/391]\tTime  0.097 ( 0.095)\tLoss 1.0045e+00 (1.0759e+00)\tAcc@1  69.53 ( 68.44)\tAcc@5  93.75 ( 92.60)\n",
            "Epoch: [39][300/391]\tTime  0.091 ( 0.095)\tLoss 1.1277e+00 (1.0784e+00)\tAcc@1  67.97 ( 68.32)\tAcc@5  91.41 ( 92.57)\n",
            "Epoch: [39][330/391]\tTime  0.098 ( 0.095)\tLoss 1.0792e+00 (1.0822e+00)\tAcc@1  66.41 ( 68.17)\tAcc@5  93.75 ( 92.52)\n",
            "Epoch: [39][360/391]\tTime  0.080 ( 0.095)\tLoss 1.1223e+00 (1.0869e+00)\tAcc@1  66.41 ( 68.06)\tAcc@5  93.75 ( 92.46)\n",
            "Epoch: [39][390/391]\tTime  0.081 ( 0.095)\tLoss 1.2984e+00 (1.0903e+00)\tAcc@1  62.50 ( 67.98)\tAcc@5  90.00 ( 92.42)\n",
            "==> Train Accuracy: Acc@1 67.984 || Acc@5 92.418\n",
            "==> Test Accuracy:  Acc@1 52.720 || Acc@5 81.070\n",
            "==> 39.59 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 40, lr: 0.1 -----\n",
            "Epoch: [40][  0/391]\tTime  0.292 ( 0.292)\tLoss 1.0335e+00 (1.0335e+00)\tAcc@1  71.88 ( 71.88)\tAcc@5  92.19 ( 92.19)\n",
            "Epoch: [40][ 30/391]\tTime  0.100 ( 0.102)\tLoss 1.0648e+00 (9.7705e-01)\tAcc@1  68.75 ( 70.99)\tAcc@5  90.62 ( 93.60)\n",
            "Epoch: [40][ 60/391]\tTime  0.093 ( 0.098)\tLoss 1.0219e+00 (1.0094e+00)\tAcc@1  71.09 ( 70.20)\tAcc@5  92.97 ( 92.89)\n",
            "Epoch: [40][ 90/391]\tTime  0.110 ( 0.097)\tLoss 9.5441e-01 (1.0191e+00)\tAcc@1  74.22 ( 70.00)\tAcc@5  95.31 ( 92.89)\n",
            "Epoch: [40][120/391]\tTime  0.092 ( 0.096)\tLoss 9.5064e-01 (1.0190e+00)\tAcc@1  67.97 ( 70.00)\tAcc@5  93.75 ( 93.06)\n",
            "Epoch: [40][150/391]\tTime  0.093 ( 0.095)\tLoss 9.4052e-01 (1.0260e+00)\tAcc@1  70.31 ( 69.82)\tAcc@5  94.53 ( 93.13)\n",
            "Epoch: [40][180/391]\tTime  0.086 ( 0.095)\tLoss 1.1342e+00 (1.0299e+00)\tAcc@1  70.31 ( 69.67)\tAcc@5  90.62 ( 93.04)\n",
            "Epoch: [40][210/391]\tTime  0.084 ( 0.095)\tLoss 1.0614e+00 (1.0330e+00)\tAcc@1  71.88 ( 69.55)\tAcc@5  92.97 ( 92.99)\n",
            "Epoch: [40][240/391]\tTime  0.091 ( 0.095)\tLoss 1.1716e+00 (1.0379e+00)\tAcc@1  62.50 ( 69.45)\tAcc@5  93.75 ( 93.01)\n",
            "Epoch: [40][270/391]\tTime  0.096 ( 0.095)\tLoss 1.0229e+00 (1.0540e+00)\tAcc@1  67.97 ( 69.04)\tAcc@5  94.53 ( 92.84)\n",
            "Epoch: [40][300/391]\tTime  0.119 ( 0.095)\tLoss 1.2177e+00 (1.0613e+00)\tAcc@1  64.84 ( 68.87)\tAcc@5  88.28 ( 92.75)\n",
            "Epoch: [40][330/391]\tTime  0.089 ( 0.095)\tLoss 1.1673e+00 (1.0643e+00)\tAcc@1  64.84 ( 68.80)\tAcc@5  92.97 ( 92.73)\n",
            "Epoch: [40][360/391]\tTime  0.105 ( 0.095)\tLoss 1.0092e+00 (1.0719e+00)\tAcc@1  68.75 ( 68.65)\tAcc@5  94.53 ( 92.64)\n",
            "Epoch: [40][390/391]\tTime  0.081 ( 0.095)\tLoss 9.9112e-01 (1.0759e+00)\tAcc@1  68.75 ( 68.54)\tAcc@5  91.25 ( 92.56)\n",
            "==> Train Accuracy: Acc@1 68.538 || Acc@5 92.564\n",
            "==> Test Accuracy:  Acc@1 58.010 || Acc@5 85.100\n",
            "==> 39.59 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 41, lr: 0.1 -----\n",
            "Epoch: [41][  0/391]\tTime  0.277 ( 0.277)\tLoss 7.7677e-01 (7.7677e-01)\tAcc@1  76.56 ( 76.56)\tAcc@5  97.66 ( 97.66)\n",
            "Epoch: [41][ 30/391]\tTime  0.095 ( 0.101)\tLoss 1.2553e+00 (9.8493e-01)\tAcc@1  65.62 ( 71.12)\tAcc@5  89.84 ( 94.00)\n",
            "Epoch: [41][ 60/391]\tTime  0.086 ( 0.098)\tLoss 9.1702e-01 (9.9307e-01)\tAcc@1  71.88 ( 71.02)\tAcc@5  94.53 ( 93.57)\n",
            "Epoch: [41][ 90/391]\tTime  0.096 ( 0.096)\tLoss 9.4883e-01 (1.0029e+00)\tAcc@1  71.88 ( 70.72)\tAcc@5  93.75 ( 93.42)\n",
            "Epoch: [41][120/391]\tTime  0.092 ( 0.096)\tLoss 1.1296e+00 (1.0207e+00)\tAcc@1  69.53 ( 69.94)\tAcc@5  89.84 ( 93.33)\n",
            "Epoch: [41][150/391]\tTime  0.093 ( 0.095)\tLoss 1.0550e+00 (1.0351e+00)\tAcc@1  65.62 ( 69.61)\tAcc@5  92.19 ( 93.22)\n",
            "Epoch: [41][180/391]\tTime  0.102 ( 0.095)\tLoss 1.1075e+00 (1.0425e+00)\tAcc@1  66.41 ( 69.26)\tAcc@5  96.88 ( 93.18)\n",
            "Epoch: [41][210/391]\tTime  0.094 ( 0.095)\tLoss 9.3519e-01 (1.0442e+00)\tAcc@1  71.09 ( 69.18)\tAcc@5  92.97 ( 93.11)\n",
            "Epoch: [41][240/391]\tTime  0.091 ( 0.095)\tLoss 1.1853e+00 (1.0513e+00)\tAcc@1  66.41 ( 69.04)\tAcc@5  91.41 ( 92.99)\n",
            "Epoch: [41][270/391]\tTime  0.093 ( 0.095)\tLoss 1.1076e+00 (1.0556e+00)\tAcc@1  67.97 ( 68.96)\tAcc@5  92.97 ( 92.93)\n",
            "Epoch: [41][300/391]\tTime  0.102 ( 0.095)\tLoss 9.9328e-01 (1.0643e+00)\tAcc@1  71.88 ( 68.76)\tAcc@5  93.75 ( 92.76)\n",
            "Epoch: [41][330/391]\tTime  0.078 ( 0.095)\tLoss 9.3560e-01 (1.0667e+00)\tAcc@1  72.66 ( 68.70)\tAcc@5  92.97 ( 92.73)\n",
            "Epoch: [41][360/391]\tTime  0.100 ( 0.095)\tLoss 1.1567e+00 (1.0727e+00)\tAcc@1  67.97 ( 68.57)\tAcc@5  87.50 ( 92.65)\n",
            "Epoch: [41][390/391]\tTime  0.082 ( 0.094)\tLoss 1.2675e+00 (1.0780e+00)\tAcc@1  65.00 ( 68.43)\tAcc@5  90.00 ( 92.54)\n",
            "==> Train Accuracy: Acc@1 68.430 || Acc@5 92.544\n",
            "==> Test Accuracy:  Acc@1 60.420 || Acc@5 86.620\n",
            "==> 39.43 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 42, lr: 0.1 -----\n",
            "Epoch: [42][  0/391]\tTime  0.290 ( 0.290)\tLoss 1.0170e+00 (1.0170e+00)\tAcc@1  72.66 ( 72.66)\tAcc@5  92.97 ( 92.97)\n",
            "Epoch: [42][ 30/391]\tTime  0.087 ( 0.103)\tLoss 1.0248e+00 (9.9070e-01)\tAcc@1  72.66 ( 71.04)\tAcc@5  92.19 ( 93.62)\n",
            "Epoch: [42][ 60/391]\tTime  0.098 ( 0.099)\tLoss 8.7296e-01 (9.7021e-01)\tAcc@1  76.56 ( 71.13)\tAcc@5  96.88 ( 94.01)\n",
            "Epoch: [42][ 90/391]\tTime  0.098 ( 0.097)\tLoss 9.8276e-01 (1.0099e+00)\tAcc@1  72.66 ( 70.42)\tAcc@5  92.19 ( 93.42)\n",
            "Epoch: [42][120/391]\tTime  0.083 ( 0.097)\tLoss 7.4608e-01 (1.0077e+00)\tAcc@1  78.91 ( 70.54)\tAcc@5  96.88 ( 93.46)\n",
            "Epoch: [42][150/391]\tTime  0.087 ( 0.096)\tLoss 9.7305e-01 (1.0189e+00)\tAcc@1  75.78 ( 70.22)\tAcc@5  92.97 ( 93.28)\n",
            "Epoch: [42][180/391]\tTime  0.101 ( 0.096)\tLoss 1.2967e+00 (1.0330e+00)\tAcc@1  61.72 ( 70.00)\tAcc@5  89.84 ( 93.07)\n",
            "Epoch: [42][210/391]\tTime  0.091 ( 0.096)\tLoss 1.1298e+00 (1.0366e+00)\tAcc@1  69.53 ( 69.89)\tAcc@5  91.41 ( 93.05)\n",
            "Epoch: [42][240/391]\tTime  0.096 ( 0.095)\tLoss 9.8784e-01 (1.0383e+00)\tAcc@1  71.09 ( 69.74)\tAcc@5  94.53 ( 93.01)\n",
            "Epoch: [42][270/391]\tTime  0.094 ( 0.095)\tLoss 1.1148e+00 (1.0457e+00)\tAcc@1  71.88 ( 69.54)\tAcc@5  89.06 ( 92.87)\n",
            "Epoch: [42][300/391]\tTime  0.088 ( 0.095)\tLoss 1.0087e+00 (1.0545e+00)\tAcc@1  76.56 ( 69.32)\tAcc@5  90.62 ( 92.75)\n",
            "Epoch: [42][330/391]\tTime  0.085 ( 0.095)\tLoss 1.1545e+00 (1.0602e+00)\tAcc@1  69.53 ( 69.21)\tAcc@5  92.19 ( 92.71)\n",
            "Epoch: [42][360/391]\tTime  0.096 ( 0.095)\tLoss 9.3649e-01 (1.0664e+00)\tAcc@1  75.00 ( 69.04)\tAcc@5  92.97 ( 92.66)\n",
            "Epoch: [42][390/391]\tTime  0.082 ( 0.094)\tLoss 1.3213e+00 (1.0683e+00)\tAcc@1  60.00 ( 68.92)\tAcc@5  88.75 ( 92.64)\n",
            "==> Train Accuracy: Acc@1 68.918 || Acc@5 92.644\n",
            "==> Test Accuracy:  Acc@1 56.010 || Acc@5 84.660\n",
            "==> 39.46 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 43, lr: 0.1 -----\n",
            "Epoch: [43][  0/391]\tTime  0.284 ( 0.284)\tLoss 1.1546e+00 (1.1546e+00)\tAcc@1  67.97 ( 67.97)\tAcc@5  91.41 ( 91.41)\n",
            "Epoch: [43][ 30/391]\tTime  0.095 ( 0.101)\tLoss 1.0457e+00 (9.9299e-01)\tAcc@1  66.41 ( 70.72)\tAcc@5  96.09 ( 93.62)\n",
            "Epoch: [43][ 60/391]\tTime  0.094 ( 0.098)\tLoss 8.5136e-01 (9.8875e-01)\tAcc@1  71.88 ( 70.66)\tAcc@5  94.53 ( 93.88)\n",
            "Epoch: [43][ 90/391]\tTime  0.094 ( 0.096)\tLoss 1.1153e+00 (9.9306e-01)\tAcc@1  67.97 ( 70.64)\tAcc@5  95.31 ( 93.58)\n",
            "Epoch: [43][120/391]\tTime  0.093 ( 0.096)\tLoss 1.1174e+00 (1.0082e+00)\tAcc@1  68.75 ( 70.25)\tAcc@5  91.41 ( 93.21)\n",
            "Epoch: [43][150/391]\tTime  0.092 ( 0.095)\tLoss 9.3730e-01 (1.0104e+00)\tAcc@1  71.88 ( 70.28)\tAcc@5  96.88 ( 93.12)\n",
            "Epoch: [43][180/391]\tTime  0.099 ( 0.095)\tLoss 1.2381e+00 (1.0180e+00)\tAcc@1  69.53 ( 70.11)\tAcc@5  88.28 ( 93.09)\n",
            "Epoch: [43][210/391]\tTime  0.094 ( 0.095)\tLoss 1.0065e+00 (1.0301e+00)\tAcc@1  73.44 ( 69.79)\tAcc@5  92.97 ( 93.00)\n",
            "Epoch: [43][240/391]\tTime  0.096 ( 0.095)\tLoss 1.2470e+00 (1.0409e+00)\tAcc@1  61.72 ( 69.54)\tAcc@5  90.62 ( 92.89)\n",
            "Epoch: [43][270/391]\tTime  0.100 ( 0.095)\tLoss 1.0288e+00 (1.0446e+00)\tAcc@1  69.53 ( 69.46)\tAcc@5  93.75 ( 92.86)\n",
            "Epoch: [43][300/391]\tTime  0.087 ( 0.095)\tLoss 1.1120e+00 (1.0529e+00)\tAcc@1  71.09 ( 69.22)\tAcc@5  87.50 ( 92.74)\n",
            "Epoch: [43][330/391]\tTime  0.082 ( 0.095)\tLoss 9.5504e-01 (1.0565e+00)\tAcc@1  69.53 ( 69.13)\tAcc@5  96.09 ( 92.72)\n",
            "Epoch: [43][360/391]\tTime  0.089 ( 0.095)\tLoss 1.2517e+00 (1.0618e+00)\tAcc@1  61.72 ( 68.95)\tAcc@5  90.62 ( 92.63)\n",
            "Epoch: [43][390/391]\tTime  0.082 ( 0.095)\tLoss 1.0977e+00 (1.0622e+00)\tAcc@1  70.00 ( 68.98)\tAcc@5  90.00 ( 92.64)\n",
            "==> Train Accuracy: Acc@1 68.980 || Acc@5 92.636\n",
            "==> Test Accuracy:  Acc@1 60.560 || Acc@5 87.310\n",
            "==> 39.55 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 44, lr: 0.1 -----\n",
            "Epoch: [44][  0/391]\tTime  0.285 ( 0.285)\tLoss 1.0083e+00 (1.0083e+00)\tAcc@1  68.75 ( 68.75)\tAcc@5  92.19 ( 92.19)\n",
            "Epoch: [44][ 30/391]\tTime  0.106 ( 0.102)\tLoss 9.5088e-01 (1.0151e+00)\tAcc@1  72.66 ( 69.96)\tAcc@5  96.09 ( 93.07)\n",
            "Epoch: [44][ 60/391]\tTime  0.093 ( 0.098)\tLoss 1.1100e+00 (1.0070e+00)\tAcc@1  68.75 ( 70.03)\tAcc@5  93.75 ( 93.26)\n",
            "Epoch: [44][ 90/391]\tTime  0.089 ( 0.096)\tLoss 7.6832e-01 (1.0055e+00)\tAcc@1  77.34 ( 70.36)\tAcc@5  96.88 ( 93.41)\n",
            "Epoch: [44][120/391]\tTime  0.088 ( 0.095)\tLoss 1.1301e+00 (1.0082e+00)\tAcc@1  70.31 ( 70.53)\tAcc@5  92.19 ( 93.29)\n",
            "Epoch: [44][150/391]\tTime  0.094 ( 0.095)\tLoss 9.2258e-01 (1.0132e+00)\tAcc@1  71.09 ( 70.39)\tAcc@5  92.97 ( 93.17)\n",
            "Epoch: [44][180/391]\tTime  0.093 ( 0.095)\tLoss 9.8613e-01 (1.0137e+00)\tAcc@1  74.22 ( 70.37)\tAcc@5  94.53 ( 93.26)\n",
            "Epoch: [44][210/391]\tTime  0.097 ( 0.094)\tLoss 1.1465e+00 (1.0211e+00)\tAcc@1  68.75 ( 70.13)\tAcc@5  92.19 ( 93.13)\n",
            "Epoch: [44][240/391]\tTime  0.081 ( 0.094)\tLoss 1.0458e+00 (1.0348e+00)\tAcc@1  67.97 ( 69.76)\tAcc@5  92.97 ( 92.95)\n",
            "Epoch: [44][270/391]\tTime  0.091 ( 0.094)\tLoss 1.3876e+00 (1.0419e+00)\tAcc@1  56.25 ( 69.52)\tAcc@5  87.50 ( 92.91)\n",
            "Epoch: [44][300/391]\tTime  0.099 ( 0.094)\tLoss 1.1066e+00 (1.0495e+00)\tAcc@1  64.06 ( 69.34)\tAcc@5  90.62 ( 92.81)\n",
            "Epoch: [44][330/391]\tTime  0.092 ( 0.094)\tLoss 8.7353e-01 (1.0550e+00)\tAcc@1  72.66 ( 69.21)\tAcc@5  96.09 ( 92.69)\n",
            "Epoch: [44][360/391]\tTime  0.088 ( 0.094)\tLoss 9.8082e-01 (1.0593e+00)\tAcc@1  62.50 ( 69.05)\tAcc@5  96.09 ( 92.63)\n",
            "Epoch: [44][390/391]\tTime  0.082 ( 0.094)\tLoss 1.3497e+00 (1.0629e+00)\tAcc@1  62.50 ( 68.91)\tAcc@5  87.50 ( 92.62)\n",
            "==> Train Accuracy: Acc@1 68.910 || Acc@5 92.616\n",
            "==> Test Accuracy:  Acc@1 59.520 || Acc@5 86.010\n",
            "==> 39.33 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 45, lr: 0.1 -----\n",
            "Epoch: [45][  0/391]\tTime  0.286 ( 0.286)\tLoss 9.9127e-01 (9.9127e-01)\tAcc@1  69.53 ( 69.53)\tAcc@5  92.97 ( 92.97)\n",
            "Epoch: [45][ 30/391]\tTime  0.099 ( 0.102)\tLoss 8.2067e-01 (9.8198e-01)\tAcc@1  71.88 ( 70.99)\tAcc@5  96.88 ( 94.13)\n",
            "Epoch: [45][ 60/391]\tTime  0.091 ( 0.098)\tLoss 1.0467e+00 (9.7733e-01)\tAcc@1  67.97 ( 71.17)\tAcc@5  94.53 ( 94.13)\n",
            "Epoch: [45][ 90/391]\tTime  0.095 ( 0.097)\tLoss 1.0140e+00 (9.9646e-01)\tAcc@1  67.97 ( 70.69)\tAcc@5  95.31 ( 93.84)\n",
            "Epoch: [45][120/391]\tTime  0.084 ( 0.096)\tLoss 1.0715e+00 (1.0058e+00)\tAcc@1  69.53 ( 70.50)\tAcc@5  90.62 ( 93.61)\n",
            "Epoch: [45][150/391]\tTime  0.098 ( 0.096)\tLoss 1.0343e+00 (1.0166e+00)\tAcc@1  66.41 ( 70.28)\tAcc@5  92.97 ( 93.31)\n",
            "Epoch: [45][180/391]\tTime  0.098 ( 0.096)\tLoss 1.0310e+00 (1.0249e+00)\tAcc@1  71.88 ( 70.00)\tAcc@5  92.19 ( 93.11)\n",
            "Epoch: [45][210/391]\tTime  0.089 ( 0.095)\tLoss 1.0569e+00 (1.0267e+00)\tAcc@1  68.75 ( 69.90)\tAcc@5  96.88 ( 93.15)\n",
            "Epoch: [45][240/391]\tTime  0.098 ( 0.095)\tLoss 1.0723e+00 (1.0340e+00)\tAcc@1  67.19 ( 69.67)\tAcc@5  95.31 ( 93.02)\n",
            "Epoch: [45][270/391]\tTime  0.091 ( 0.095)\tLoss 1.3506e+00 (1.0413e+00)\tAcc@1  63.28 ( 69.56)\tAcc@5  86.72 ( 92.96)\n",
            "Epoch: [45][300/391]\tTime  0.092 ( 0.095)\tLoss 1.0040e+00 (1.0467e+00)\tAcc@1  71.09 ( 69.42)\tAcc@5  94.53 ( 92.91)\n",
            "Epoch: [45][330/391]\tTime  0.094 ( 0.095)\tLoss 1.1007e+00 (1.0512e+00)\tAcc@1  67.19 ( 69.36)\tAcc@5  90.62 ( 92.82)\n",
            "Epoch: [45][360/391]\tTime  0.089 ( 0.095)\tLoss 1.0682e+00 (1.0552e+00)\tAcc@1  67.19 ( 69.25)\tAcc@5  93.75 ( 92.82)\n",
            "Epoch: [45][390/391]\tTime  0.082 ( 0.095)\tLoss 1.0218e+00 (1.0601e+00)\tAcc@1  70.00 ( 69.12)\tAcc@5  91.25 ( 92.74)\n",
            "==> Train Accuracy: Acc@1 69.124 || Acc@5 92.736\n",
            "==> Test Accuracy:  Acc@1 59.830 || Acc@5 86.270\n",
            "==> 39.48 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 46, lr: 0.1 -----\n",
            "Epoch: [46][  0/391]\tTime  0.276 ( 0.276)\tLoss 1.0247e+00 (1.0247e+00)\tAcc@1  71.88 ( 71.88)\tAcc@5  92.19 ( 92.19)\n",
            "Epoch: [46][ 30/391]\tTime  0.091 ( 0.100)\tLoss 9.2617e-01 (9.7227e-01)\tAcc@1  70.31 ( 72.10)\tAcc@5  94.53 ( 93.62)\n",
            "Epoch: [46][ 60/391]\tTime  0.095 ( 0.097)\tLoss 9.9910e-01 (9.6633e-01)\tAcc@1  66.41 ( 71.64)\tAcc@5  93.75 ( 93.85)\n",
            "Epoch: [46][ 90/391]\tTime  0.087 ( 0.096)\tLoss 9.8151e-01 (9.8375e-01)\tAcc@1  69.53 ( 71.00)\tAcc@5  95.31 ( 93.69)\n",
            "Epoch: [46][120/391]\tTime  0.082 ( 0.095)\tLoss 9.9395e-01 (1.0065e+00)\tAcc@1  70.31 ( 70.44)\tAcc@5  92.19 ( 93.55)\n",
            "Epoch: [46][150/391]\tTime  0.093 ( 0.095)\tLoss 1.2479e+00 (1.0129e+00)\tAcc@1  61.72 ( 70.17)\tAcc@5  92.19 ( 93.49)\n",
            "Epoch: [46][180/391]\tTime  0.095 ( 0.095)\tLoss 8.6519e-01 (1.0246e+00)\tAcc@1  77.34 ( 69.82)\tAcc@5  93.75 ( 93.27)\n",
            "Epoch: [46][210/391]\tTime  0.096 ( 0.095)\tLoss 1.1776e+00 (1.0307e+00)\tAcc@1  60.94 ( 69.70)\tAcc@5  95.31 ( 93.15)\n",
            "Epoch: [46][240/391]\tTime  0.097 ( 0.095)\tLoss 8.0612e-01 (1.0322e+00)\tAcc@1  75.78 ( 69.75)\tAcc@5  96.09 ( 93.13)\n",
            "Epoch: [46][270/391]\tTime  0.089 ( 0.095)\tLoss 1.1309e+00 (1.0387e+00)\tAcc@1  70.31 ( 69.56)\tAcc@5  89.84 ( 93.07)\n",
            "Epoch: [46][300/391]\tTime  0.101 ( 0.095)\tLoss 9.1030e-01 (1.0446e+00)\tAcc@1  74.22 ( 69.40)\tAcc@5  93.75 ( 92.96)\n",
            "Epoch: [46][330/391]\tTime  0.085 ( 0.095)\tLoss 1.0380e+00 (1.0462e+00)\tAcc@1  65.62 ( 69.41)\tAcc@5  93.75 ( 92.88)\n",
            "Epoch: [46][360/391]\tTime  0.101 ( 0.095)\tLoss 9.4589e-01 (1.0550e+00)\tAcc@1  72.66 ( 69.16)\tAcc@5  95.31 ( 92.80)\n",
            "Epoch: [46][390/391]\tTime  0.082 ( 0.094)\tLoss 1.1130e+00 (1.0617e+00)\tAcc@1  63.75 ( 69.00)\tAcc@5  91.25 ( 92.71)\n",
            "==> Train Accuracy: Acc@1 69.004 || Acc@5 92.710\n",
            "==> Test Accuracy:  Acc@1 55.820 || Acc@5 83.670\n",
            "==> 39.49 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 47, lr: 0.1 -----\n",
            "Epoch: [47][  0/391]\tTime  0.283 ( 0.283)\tLoss 1.0138e+00 (1.0138e+00)\tAcc@1  69.53 ( 69.53)\tAcc@5  96.09 ( 96.09)\n",
            "Epoch: [47][ 30/391]\tTime  0.094 ( 0.101)\tLoss 1.0278e+00 (9.6928e-01)\tAcc@1  68.75 ( 71.50)\tAcc@5  94.53 ( 94.00)\n",
            "Epoch: [47][ 60/391]\tTime  0.094 ( 0.097)\tLoss 1.1061e+00 (9.7366e-01)\tAcc@1  69.53 ( 70.97)\tAcc@5  93.75 ( 94.11)\n",
            "Epoch: [47][ 90/391]\tTime  0.089 ( 0.096)\tLoss 1.0838e+00 (9.7506e-01)\tAcc@1  69.53 ( 71.09)\tAcc@5  92.19 ( 93.86)\n",
            "Epoch: [47][120/391]\tTime  0.093 ( 0.095)\tLoss 1.1418e+00 (9.9468e-01)\tAcc@1  64.84 ( 70.66)\tAcc@5  93.75 ( 93.65)\n",
            "Epoch: [47][150/391]\tTime  0.093 ( 0.095)\tLoss 1.1084e+00 (1.0050e+00)\tAcc@1  67.19 ( 70.38)\tAcc@5  92.19 ( 93.50)\n",
            "Epoch: [47][180/391]\tTime  0.088 ( 0.095)\tLoss 8.3250e-01 (1.0159e+00)\tAcc@1  75.00 ( 70.15)\tAcc@5  95.31 ( 93.36)\n",
            "Epoch: [47][210/391]\tTime  0.087 ( 0.094)\tLoss 1.0690e+00 (1.0233e+00)\tAcc@1  68.75 ( 70.07)\tAcc@5  92.19 ( 93.30)\n",
            "Epoch: [47][240/391]\tTime  0.099 ( 0.094)\tLoss 1.2538e+00 (1.0280e+00)\tAcc@1  65.62 ( 69.92)\tAcc@5  89.84 ( 93.28)\n",
            "Epoch: [47][270/391]\tTime  0.087 ( 0.094)\tLoss 1.0583e+00 (1.0324e+00)\tAcc@1  71.88 ( 69.82)\tAcc@5  92.19 ( 93.14)\n",
            "Epoch: [47][300/391]\tTime  0.093 ( 0.094)\tLoss 1.1435e+00 (1.0438e+00)\tAcc@1  66.41 ( 69.54)\tAcc@5  90.62 ( 92.90)\n",
            "Epoch: [47][330/391]\tTime  0.090 ( 0.094)\tLoss 1.0192e+00 (1.0481e+00)\tAcc@1  73.44 ( 69.38)\tAcc@5  96.88 ( 92.88)\n",
            "Epoch: [47][360/391]\tTime  0.090 ( 0.094)\tLoss 1.0204e+00 (1.0485e+00)\tAcc@1  65.62 ( 69.28)\tAcc@5  96.88 ( 92.91)\n",
            "Epoch: [47][390/391]\tTime  0.082 ( 0.094)\tLoss 1.0654e+00 (1.0532e+00)\tAcc@1  71.25 ( 69.19)\tAcc@5  91.25 ( 92.86)\n",
            "==> Train Accuracy: Acc@1 69.186 || Acc@5 92.856\n",
            "==> Test Accuracy:  Acc@1 56.480 || Acc@5 84.260\n",
            "==> 39.27 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 48, lr: 0.1 -----\n",
            "Epoch: [48][  0/391]\tTime  0.298 ( 0.298)\tLoss 8.3324e-01 (8.3324e-01)\tAcc@1  78.12 ( 78.12)\tAcc@5  95.31 ( 95.31)\n",
            "Epoch: [48][ 30/391]\tTime  0.096 ( 0.102)\tLoss 8.4944e-01 (9.3886e-01)\tAcc@1  75.00 ( 72.63)\tAcc@5  93.75 ( 94.13)\n",
            "Epoch: [48][ 60/391]\tTime  0.097 ( 0.098)\tLoss 1.1416e+00 (9.5797e-01)\tAcc@1  67.97 ( 71.88)\tAcc@5  93.75 ( 93.97)\n",
            "Epoch: [48][ 90/391]\tTime  0.100 ( 0.096)\tLoss 1.0402e+00 (9.6975e-01)\tAcc@1  68.75 ( 71.60)\tAcc@5  90.62 ( 93.78)\n",
            "Epoch: [48][120/391]\tTime  0.091 ( 0.095)\tLoss 1.1617e+00 (9.7342e-01)\tAcc@1  64.84 ( 71.29)\tAcc@5  91.41 ( 93.70)\n",
            "Epoch: [48][150/391]\tTime  0.101 ( 0.095)\tLoss 9.5073e-01 (9.9337e-01)\tAcc@1  70.31 ( 70.77)\tAcc@5  96.09 ( 93.50)\n",
            "Epoch: [48][180/391]\tTime  0.092 ( 0.095)\tLoss 9.6254e-01 (1.0055e+00)\tAcc@1  71.09 ( 70.46)\tAcc@5  95.31 ( 93.29)\n",
            "Epoch: [48][210/391]\tTime  0.099 ( 0.095)\tLoss 1.0794e+00 (1.0176e+00)\tAcc@1  65.62 ( 70.18)\tAcc@5  89.84 ( 93.10)\n",
            "Epoch: [48][240/391]\tTime  0.096 ( 0.095)\tLoss 1.1312e+00 (1.0242e+00)\tAcc@1  61.72 ( 69.80)\tAcc@5  92.19 ( 93.03)\n",
            "Epoch: [48][270/391]\tTime  0.095 ( 0.095)\tLoss 8.8321e-01 (1.0329e+00)\tAcc@1  71.88 ( 69.57)\tAcc@5  92.19 ( 92.93)\n",
            "Epoch: [48][300/391]\tTime  0.104 ( 0.095)\tLoss 1.0188e+00 (1.0367e+00)\tAcc@1  71.88 ( 69.54)\tAcc@5  90.62 ( 92.89)\n",
            "Epoch: [48][330/391]\tTime  0.093 ( 0.095)\tLoss 1.0886e+00 (1.0405e+00)\tAcc@1  67.97 ( 69.38)\tAcc@5  91.41 ( 92.88)\n",
            "Epoch: [48][360/391]\tTime  0.088 ( 0.095)\tLoss 1.0362e+00 (1.0433e+00)\tAcc@1  73.44 ( 69.29)\tAcc@5  92.97 ( 92.86)\n",
            "Epoch: [48][390/391]\tTime  0.082 ( 0.095)\tLoss 1.3504e+00 (1.0484e+00)\tAcc@1  57.50 ( 69.17)\tAcc@5  92.50 ( 92.79)\n",
            "==> Train Accuracy: Acc@1 69.168 || Acc@5 92.794\n",
            "==> Test Accuracy:  Acc@1 59.700 || Acc@5 86.690\n",
            "==> 39.49 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 49, lr: 0.1 -----\n",
            "Epoch: [49][  0/391]\tTime  0.280 ( 0.280)\tLoss 1.0874e+00 (1.0874e+00)\tAcc@1  67.97 ( 67.97)\tAcc@5  93.75 ( 93.75)\n",
            "Epoch: [49][ 30/391]\tTime  0.093 ( 0.101)\tLoss 9.9876e-01 (9.5725e-01)\tAcc@1  71.09 ( 71.67)\tAcc@5  94.53 ( 94.56)\n",
            "Epoch: [49][ 60/391]\tTime  0.096 ( 0.098)\tLoss 9.7342e-01 (9.6023e-01)\tAcc@1  70.31 ( 71.39)\tAcc@5  96.88 ( 94.22)\n",
            "Epoch: [49][ 90/391]\tTime  0.092 ( 0.096)\tLoss 1.0679e+00 (9.7169e-01)\tAcc@1  64.06 ( 71.15)\tAcc@5  92.19 ( 94.06)\n",
            "Epoch: [49][120/391]\tTime  0.098 ( 0.096)\tLoss 1.0379e+00 (9.8618e-01)\tAcc@1  67.97 ( 70.71)\tAcc@5  91.41 ( 93.96)\n",
            "Epoch: [49][150/391]\tTime  0.088 ( 0.096)\tLoss 1.0829e+00 (9.9437e-01)\tAcc@1  68.75 ( 70.60)\tAcc@5  92.97 ( 93.79)\n",
            "Epoch: [49][180/391]\tTime  0.091 ( 0.095)\tLoss 1.1270e+00 (9.9533e-01)\tAcc@1  67.19 ( 70.43)\tAcc@5  87.50 ( 93.66)\n",
            "Epoch: [49][210/391]\tTime  0.094 ( 0.095)\tLoss 8.6342e-01 (1.0025e+00)\tAcc@1  75.00 ( 70.40)\tAcc@5  94.53 ( 93.51)\n",
            "Epoch: [49][240/391]\tTime  0.094 ( 0.095)\tLoss 1.1328e+00 (1.0106e+00)\tAcc@1  68.75 ( 70.27)\tAcc@5  92.19 ( 93.43)\n",
            "Epoch: [49][270/391]\tTime  0.092 ( 0.095)\tLoss 9.2605e-01 (1.0162e+00)\tAcc@1  72.66 ( 70.09)\tAcc@5  96.09 ( 93.39)\n",
            "Epoch: [49][300/391]\tTime  0.091 ( 0.095)\tLoss 1.1328e+00 (1.0244e+00)\tAcc@1  70.31 ( 69.88)\tAcc@5  89.06 ( 93.28)\n",
            "Epoch: [49][330/391]\tTime  0.117 ( 0.095)\tLoss 1.0486e+00 (1.0311e+00)\tAcc@1  72.66 ( 69.73)\tAcc@5  91.41 ( 93.21)\n",
            "Epoch: [49][360/391]\tTime  0.094 ( 0.094)\tLoss 9.6270e-01 (1.0396e+00)\tAcc@1  68.75 ( 69.52)\tAcc@5  93.75 ( 93.12)\n",
            "Epoch: [49][390/391]\tTime  0.082 ( 0.094)\tLoss 9.3461e-01 (1.0447e+00)\tAcc@1  72.50 ( 69.40)\tAcc@5  95.00 ( 93.02)\n",
            "==> Train Accuracy: Acc@1 69.398 || Acc@5 93.020\n",
            "==> Test Accuracy:  Acc@1 60.210 || Acc@5 86.270\n",
            "==> 39.47 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 50, lr: 0.1 -----\n",
            "Epoch: [50][  0/391]\tTime  0.288 ( 0.288)\tLoss 8.7619e-01 (8.7619e-01)\tAcc@1  77.34 ( 77.34)\tAcc@5  93.75 ( 93.75)\n",
            "Epoch: [50][ 30/391]\tTime  0.083 ( 0.101)\tLoss 9.5155e-01 (9.5811e-01)\tAcc@1  71.88 ( 72.08)\tAcc@5  92.97 ( 93.67)\n",
            "Epoch: [50][ 60/391]\tTime  0.091 ( 0.098)\tLoss 1.0018e+00 (9.5921e-01)\tAcc@1  70.31 ( 71.59)\tAcc@5  92.97 ( 93.87)\n",
            "Epoch: [50][ 90/391]\tTime  0.101 ( 0.097)\tLoss 8.9569e-01 (9.6514e-01)\tAcc@1  75.78 ( 71.42)\tAcc@5  94.53 ( 93.90)\n",
            "Epoch: [50][120/391]\tTime  0.094 ( 0.096)\tLoss 1.0069e+00 (9.5948e-01)\tAcc@1  71.09 ( 71.66)\tAcc@5  96.09 ( 94.05)\n",
            "Epoch: [50][150/391]\tTime  0.093 ( 0.096)\tLoss 9.7952e-01 (9.7182e-01)\tAcc@1  75.00 ( 71.33)\tAcc@5  91.41 ( 93.91)\n",
            "Epoch: [50][180/391]\tTime  0.099 ( 0.096)\tLoss 1.2317e+00 (9.8224e-01)\tAcc@1  64.06 ( 70.96)\tAcc@5  92.19 ( 93.81)\n",
            "Epoch: [50][210/391]\tTime  0.082 ( 0.095)\tLoss 1.0967e+00 (9.9477e-01)\tAcc@1  70.31 ( 70.76)\tAcc@5  94.53 ( 93.56)\n",
            "Epoch: [50][240/391]\tTime  0.104 ( 0.095)\tLoss 1.2179e+00 (1.0041e+00)\tAcc@1  66.41 ( 70.46)\tAcc@5  89.84 ( 93.45)\n",
            "Epoch: [50][270/391]\tTime  0.098 ( 0.095)\tLoss 8.9955e-01 (1.0127e+00)\tAcc@1  74.22 ( 70.23)\tAcc@5  96.88 ( 93.35)\n",
            "Epoch: [50][300/391]\tTime  0.087 ( 0.095)\tLoss 1.0311e+00 (1.0196e+00)\tAcc@1  69.53 ( 70.03)\tAcc@5  92.19 ( 93.28)\n",
            "Epoch: [50][330/391]\tTime  0.097 ( 0.095)\tLoss 1.2637e+00 (1.0248e+00)\tAcc@1  64.06 ( 69.91)\tAcc@5  90.62 ( 93.20)\n",
            "Epoch: [50][360/391]\tTime  0.093 ( 0.094)\tLoss 1.2192e+00 (1.0339e+00)\tAcc@1  63.28 ( 69.63)\tAcc@5  92.97 ( 93.09)\n",
            "Epoch: [50][390/391]\tTime  0.082 ( 0.094)\tLoss 1.2311e+00 (1.0384e+00)\tAcc@1  61.25 ( 69.50)\tAcc@5  91.25 ( 93.03)\n",
            "==> Train Accuracy: Acc@1 69.504 || Acc@5 93.032\n",
            "==> Test Accuracy:  Acc@1 58.600 || Acc@5 86.350\n",
            "==> 39.38 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 51, lr: 0.1 -----\n",
            "Epoch: [51][  0/391]\tTime  0.292 ( 0.292)\tLoss 7.6223e-01 (7.6223e-01)\tAcc@1  77.34 ( 77.34)\tAcc@5  95.31 ( 95.31)\n",
            "Epoch: [51][ 30/391]\tTime  0.089 ( 0.101)\tLoss 7.8417e-01 (9.0937e-01)\tAcc@1  78.12 ( 72.63)\tAcc@5  96.88 ( 94.48)\n",
            "Epoch: [51][ 60/391]\tTime  0.091 ( 0.097)\tLoss 9.7361e-01 (9.2538e-01)\tAcc@1  68.75 ( 72.18)\tAcc@5  94.53 ( 94.43)\n",
            "Epoch: [51][ 90/391]\tTime  0.096 ( 0.096)\tLoss 1.3342e+00 (9.5161e-01)\tAcc@1  63.28 ( 71.60)\tAcc@5  89.84 ( 94.13)\n",
            "Epoch: [51][120/391]\tTime  0.091 ( 0.096)\tLoss 1.1319e+00 (9.5653e-01)\tAcc@1  65.62 ( 71.46)\tAcc@5  92.97 ( 94.11)\n",
            "Epoch: [51][150/391]\tTime  0.088 ( 0.095)\tLoss 1.1575e+00 (9.7710e-01)\tAcc@1  64.84 ( 71.07)\tAcc@5  92.19 ( 93.80)\n",
            "Epoch: [51][180/391]\tTime  0.092 ( 0.095)\tLoss 1.1261e+00 (9.9072e-01)\tAcc@1  66.41 ( 70.59)\tAcc@5  93.75 ( 93.74)\n",
            "Epoch: [51][210/391]\tTime  0.102 ( 0.095)\tLoss 1.1699e+00 (1.0037e+00)\tAcc@1  64.84 ( 70.21)\tAcc@5  94.53 ( 93.53)\n",
            "Epoch: [51][240/391]\tTime  0.102 ( 0.095)\tLoss 1.3260e+00 (1.0114e+00)\tAcc@1  63.28 ( 70.06)\tAcc@5  87.50 ( 93.40)\n",
            "Epoch: [51][270/391]\tTime  0.103 ( 0.095)\tLoss 1.0389e+00 (1.0174e+00)\tAcc@1  67.97 ( 69.98)\tAcc@5  95.31 ( 93.32)\n",
            "Epoch: [51][300/391]\tTime  0.093 ( 0.095)\tLoss 1.2288e+00 (1.0260e+00)\tAcc@1  63.28 ( 69.79)\tAcc@5  91.41 ( 93.23)\n",
            "Epoch: [51][330/391]\tTime  0.094 ( 0.095)\tLoss 1.0564e+00 (1.0319e+00)\tAcc@1  72.66 ( 69.68)\tAcc@5  91.41 ( 93.10)\n",
            "Epoch: [51][360/391]\tTime  0.102 ( 0.095)\tLoss 9.0258e-01 (1.0371e+00)\tAcc@1  77.34 ( 69.59)\tAcc@5  92.19 ( 93.02)\n",
            "Epoch: [51][390/391]\tTime  0.085 ( 0.095)\tLoss 1.6534e+00 (1.0401e+00)\tAcc@1  56.25 ( 69.52)\tAcc@5  82.50 ( 92.95)\n",
            "==> Train Accuracy: Acc@1 69.524 || Acc@5 92.950\n",
            "==> Test Accuracy:  Acc@1 57.800 || Acc@5 85.480\n",
            "==> 39.59 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 52, lr: 0.1 -----\n",
            "Epoch: [52][  0/391]\tTime  0.267 ( 0.267)\tLoss 7.7336e-01 (7.7336e-01)\tAcc@1  75.78 ( 75.78)\tAcc@5  96.88 ( 96.88)\n",
            "Epoch: [52][ 30/391]\tTime  0.088 ( 0.100)\tLoss 9.2067e-01 (9.6537e-01)\tAcc@1  68.75 ( 71.30)\tAcc@5  97.66 ( 93.70)\n",
            "Epoch: [52][ 60/391]\tTime  0.091 ( 0.097)\tLoss 8.4692e-01 (9.7387e-01)\tAcc@1  78.12 ( 71.34)\tAcc@5  94.53 ( 93.85)\n",
            "Epoch: [52][ 90/391]\tTime  0.085 ( 0.096)\tLoss 9.7485e-01 (9.6509e-01)\tAcc@1  71.88 ( 71.51)\tAcc@5  93.75 ( 93.92)\n",
            "Epoch: [52][120/391]\tTime  0.094 ( 0.095)\tLoss 9.5649e-01 (9.7059e-01)\tAcc@1  67.19 ( 71.29)\tAcc@5  94.53 ( 93.90)\n",
            "Epoch: [52][150/391]\tTime  0.092 ( 0.095)\tLoss 1.1851e+00 (9.7862e-01)\tAcc@1  66.41 ( 71.14)\tAcc@5  90.62 ( 93.77)\n",
            "Epoch: [52][180/391]\tTime  0.095 ( 0.094)\tLoss 1.0488e+00 (9.9504e-01)\tAcc@1  64.06 ( 70.66)\tAcc@5  95.31 ( 93.62)\n",
            "Epoch: [52][210/391]\tTime  0.096 ( 0.094)\tLoss 8.0652e-01 (9.9728e-01)\tAcc@1  74.22 ( 70.61)\tAcc@5  95.31 ( 93.65)\n",
            "Epoch: [52][240/391]\tTime  0.106 ( 0.094)\tLoss 1.2311e+00 (1.0111e+00)\tAcc@1  65.62 ( 70.32)\tAcc@5  87.50 ( 93.40)\n",
            "Epoch: [52][270/391]\tTime  0.100 ( 0.094)\tLoss 1.0322e+00 (1.0153e+00)\tAcc@1  70.31 ( 70.18)\tAcc@5  92.19 ( 93.36)\n",
            "Epoch: [52][300/391]\tTime  0.090 ( 0.094)\tLoss 1.0546e+00 (1.0181e+00)\tAcc@1  71.88 ( 70.12)\tAcc@5  92.19 ( 93.31)\n",
            "Epoch: [52][330/391]\tTime  0.096 ( 0.094)\tLoss 1.1431e+00 (1.0236e+00)\tAcc@1  70.31 ( 70.02)\tAcc@5  90.62 ( 93.25)\n",
            "Epoch: [52][360/391]\tTime  0.082 ( 0.094)\tLoss 1.0918e+00 (1.0303e+00)\tAcc@1  67.19 ( 69.82)\tAcc@5  91.41 ( 93.15)\n",
            "Epoch: [52][390/391]\tTime  0.082 ( 0.094)\tLoss 1.0043e+00 (1.0336e+00)\tAcc@1  72.50 ( 69.73)\tAcc@5  93.75 ( 93.09)\n",
            "==> Train Accuracy: Acc@1 69.730 || Acc@5 93.086\n",
            "==> Test Accuracy:  Acc@1 59.480 || Acc@5 86.310\n",
            "==> 39.12 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 53, lr: 0.1 -----\n",
            "Epoch: [53][  0/391]\tTime  0.288 ( 0.288)\tLoss 1.0790e+00 (1.0790e+00)\tAcc@1  68.75 ( 68.75)\tAcc@5  93.75 ( 93.75)\n",
            "Epoch: [53][ 30/391]\tTime  0.098 ( 0.101)\tLoss 1.0335e+00 (9.5262e-01)\tAcc@1  67.97 ( 72.35)\tAcc@5  94.53 ( 94.18)\n",
            "Epoch: [53][ 60/391]\tTime  0.109 ( 0.098)\tLoss 7.0153e-01 (9.4070e-01)\tAcc@1  79.69 ( 72.54)\tAcc@5  96.09 ( 94.35)\n",
            "Epoch: [53][ 90/391]\tTime  0.088 ( 0.096)\tLoss 7.5781e-01 (9.4251e-01)\tAcc@1  75.00 ( 72.12)\tAcc@5  99.22 ( 94.37)\n",
            "Epoch: [53][120/391]\tTime  0.100 ( 0.096)\tLoss 8.9545e-01 (9.6313e-01)\tAcc@1  75.78 ( 71.64)\tAcc@5  95.31 ( 94.11)\n",
            "Epoch: [53][150/391]\tTime  0.104 ( 0.096)\tLoss 9.7268e-01 (9.7355e-01)\tAcc@1  72.66 ( 71.39)\tAcc@5  96.88 ( 94.00)\n",
            "Epoch: [53][180/391]\tTime  0.082 ( 0.095)\tLoss 9.8040e-01 (9.9076e-01)\tAcc@1  70.31 ( 71.04)\tAcc@5  92.19 ( 93.71)\n",
            "Epoch: [53][210/391]\tTime  0.093 ( 0.095)\tLoss 8.6653e-01 (1.0016e+00)\tAcc@1  76.56 ( 70.68)\tAcc@5  96.88 ( 93.53)\n",
            "Epoch: [53][240/391]\tTime  0.090 ( 0.095)\tLoss 7.3982e-01 (1.0083e+00)\tAcc@1  78.12 ( 70.51)\tAcc@5  96.09 ( 93.54)\n",
            "Epoch: [53][270/391]\tTime  0.093 ( 0.095)\tLoss 1.4074e+00 (1.0164e+00)\tAcc@1  60.94 ( 70.34)\tAcc@5  90.62 ( 93.41)\n",
            "Epoch: [53][300/391]\tTime  0.091 ( 0.095)\tLoss 1.1928e+00 (1.0259e+00)\tAcc@1  64.06 ( 70.10)\tAcc@5  94.53 ( 93.31)\n",
            "Epoch: [53][330/391]\tTime  0.092 ( 0.095)\tLoss 1.0669e+00 (1.0344e+00)\tAcc@1  67.97 ( 69.87)\tAcc@5  92.19 ( 93.17)\n",
            "Epoch: [53][360/391]\tTime  0.084 ( 0.094)\tLoss 9.1361e-01 (1.0377e+00)\tAcc@1  73.44 ( 69.76)\tAcc@5  98.44 ( 93.19)\n",
            "Epoch: [53][390/391]\tTime  0.082 ( 0.094)\tLoss 1.1848e+00 (1.0367e+00)\tAcc@1  68.75 ( 69.77)\tAcc@5  88.75 ( 93.18)\n",
            "==> Train Accuracy: Acc@1 69.766 || Acc@5 93.182\n",
            "==> Test Accuracy:  Acc@1 58.770 || Acc@5 85.480\n",
            "==> 39.42 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 54, lr: 0.1 -----\n",
            "Epoch: [54][  0/391]\tTime  0.287 ( 0.287)\tLoss 9.5496e-01 (9.5496e-01)\tAcc@1  74.22 ( 74.22)\tAcc@5  93.75 ( 93.75)\n",
            "Epoch: [54][ 30/391]\tTime  0.090 ( 0.101)\tLoss 7.7769e-01 (8.7577e-01)\tAcc@1  75.00 ( 74.02)\tAcc@5  97.66 ( 94.88)\n",
            "Epoch: [54][ 60/391]\tTime  0.092 ( 0.097)\tLoss 9.2587e-01 (9.0966e-01)\tAcc@1  71.88 ( 73.01)\tAcc@5  96.09 ( 94.36)\n",
            "Epoch: [54][ 90/391]\tTime  0.091 ( 0.096)\tLoss 1.2176e+00 (9.3237e-01)\tAcc@1  66.41 ( 72.38)\tAcc@5  92.19 ( 94.37)\n",
            "Epoch: [54][120/391]\tTime  0.085 ( 0.095)\tLoss 7.6950e-01 (9.4582e-01)\tAcc@1  74.22 ( 71.87)\tAcc@5  94.53 ( 94.23)\n",
            "Epoch: [54][150/391]\tTime  0.093 ( 0.095)\tLoss 1.1737e+00 (9.5325e-01)\tAcc@1  66.41 ( 71.65)\tAcc@5  89.84 ( 94.11)\n",
            "Epoch: [54][180/391]\tTime  0.091 ( 0.095)\tLoss 1.2148e+00 (9.7382e-01)\tAcc@1  64.84 ( 70.95)\tAcc@5  89.84 ( 93.88)\n",
            "Epoch: [54][210/391]\tTime  0.094 ( 0.094)\tLoss 9.6098e-01 (9.8340e-01)\tAcc@1  69.53 ( 70.65)\tAcc@5  93.75 ( 93.75)\n",
            "Epoch: [54][240/391]\tTime  0.092 ( 0.094)\tLoss 1.1792e+00 (9.9072e-01)\tAcc@1  60.94 ( 70.49)\tAcc@5  89.84 ( 93.56)\n",
            "Epoch: [54][270/391]\tTime  0.101 ( 0.094)\tLoss 1.0085e+00 (1.0036e+00)\tAcc@1  71.88 ( 70.17)\tAcc@5  93.75 ( 93.48)\n",
            "Epoch: [54][300/391]\tTime  0.092 ( 0.094)\tLoss 1.3897e+00 (1.0183e+00)\tAcc@1  59.38 ( 69.82)\tAcc@5  87.50 ( 93.30)\n",
            "Epoch: [54][330/391]\tTime  0.096 ( 0.094)\tLoss 9.9276e-01 (1.0199e+00)\tAcc@1  71.88 ( 69.82)\tAcc@5  93.75 ( 93.32)\n",
            "Epoch: [54][360/391]\tTime  0.098 ( 0.094)\tLoss 1.0150e+00 (1.0251e+00)\tAcc@1  68.75 ( 69.68)\tAcc@5  90.62 ( 93.25)\n",
            "Epoch: [54][390/391]\tTime  0.082 ( 0.094)\tLoss 1.3261e+00 (1.0308e+00)\tAcc@1  63.75 ( 69.61)\tAcc@5  87.50 ( 93.16)\n",
            "==> Train Accuracy: Acc@1 69.614 || Acc@5 93.164\n",
            "==> Test Accuracy:  Acc@1 57.420 || Acc@5 84.580\n",
            "==> 39.32 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 55, lr: 0.1 -----\n",
            "Epoch: [55][  0/391]\tTime  0.283 ( 0.283)\tLoss 1.0935e+00 (1.0935e+00)\tAcc@1  65.62 ( 65.62)\tAcc@5  92.19 ( 92.19)\n",
            "Epoch: [55][ 30/391]\tTime  0.088 ( 0.101)\tLoss 9.8294e-01 (9.6736e-01)\tAcc@1  69.53 ( 71.27)\tAcc@5  97.66 ( 93.88)\n",
            "Epoch: [55][ 60/391]\tTime  0.098 ( 0.097)\tLoss 9.6936e-01 (9.5202e-01)\tAcc@1  69.53 ( 71.90)\tAcc@5  94.53 ( 93.95)\n",
            "Epoch: [55][ 90/391]\tTime  0.100 ( 0.096)\tLoss 9.9007e-01 (9.6481e-01)\tAcc@1  69.53 ( 71.44)\tAcc@5  89.06 ( 93.80)\n",
            "Epoch: [55][120/391]\tTime  0.093 ( 0.095)\tLoss 1.0658e+00 (9.7364e-01)\tAcc@1  70.31 ( 71.07)\tAcc@5  89.06 ( 93.76)\n",
            "Epoch: [55][150/391]\tTime  0.099 ( 0.095)\tLoss 1.1157e+00 (9.8282e-01)\tAcc@1  64.84 ( 70.92)\tAcc@5  91.41 ( 93.64)\n",
            "Epoch: [55][180/391]\tTime  0.088 ( 0.095)\tLoss 1.0210e+00 (9.9121e-01)\tAcc@1  75.00 ( 70.74)\tAcc@5  89.84 ( 93.59)\n",
            "Epoch: [55][210/391]\tTime  0.093 ( 0.095)\tLoss 1.0605e+00 (1.0005e+00)\tAcc@1  71.88 ( 70.41)\tAcc@5  93.75 ( 93.53)\n",
            "Epoch: [55][240/391]\tTime  0.090 ( 0.094)\tLoss 1.1345e+00 (1.0140e+00)\tAcc@1  71.09 ( 70.13)\tAcc@5  93.75 ( 93.35)\n",
            "Epoch: [55][270/391]\tTime  0.100 ( 0.094)\tLoss 1.0975e+00 (1.0164e+00)\tAcc@1  66.41 ( 70.14)\tAcc@5  91.41 ( 93.31)\n",
            "Epoch: [55][300/391]\tTime  0.105 ( 0.094)\tLoss 1.2157e+00 (1.0179e+00)\tAcc@1  62.50 ( 70.13)\tAcc@5  94.53 ( 93.33)\n",
            "Epoch: [55][330/391]\tTime  0.100 ( 0.094)\tLoss 8.4550e-01 (1.0188e+00)\tAcc@1  78.12 ( 70.09)\tAcc@5  92.19 ( 93.33)\n",
            "Epoch: [55][360/391]\tTime  0.090 ( 0.094)\tLoss 1.1737e+00 (1.0196e+00)\tAcc@1  67.19 ( 70.07)\tAcc@5  90.62 ( 93.28)\n",
            "Epoch: [55][390/391]\tTime  0.082 ( 0.094)\tLoss 8.7838e-01 (1.0258e+00)\tAcc@1  75.00 ( 69.89)\tAcc@5  96.25 ( 93.21)\n",
            "==> Train Accuracy: Acc@1 69.892 || Acc@5 93.206\n",
            "==> Test Accuracy:  Acc@1 57.780 || Acc@5 85.480\n",
            "==> 39.26 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 56, lr: 0.1 -----\n",
            "Epoch: [56][  0/391]\tTime  0.289 ( 0.289)\tLoss 1.0385e+00 (1.0385e+00)\tAcc@1  71.88 ( 71.88)\tAcc@5  96.09 ( 96.09)\n",
            "Epoch: [56][ 30/391]\tTime  0.081 ( 0.101)\tLoss 8.2305e-01 (9.1516e-01)\tAcc@1  76.56 ( 72.56)\tAcc@5  94.53 ( 94.93)\n",
            "Epoch: [56][ 60/391]\tTime  0.087 ( 0.097)\tLoss 9.7692e-01 (9.3554e-01)\tAcc@1  70.31 ( 71.85)\tAcc@5  92.97 ( 94.66)\n",
            "Epoch: [56][ 90/391]\tTime  0.094 ( 0.096)\tLoss 8.5756e-01 (9.4842e-01)\tAcc@1  74.22 ( 71.47)\tAcc@5  95.31 ( 94.34)\n",
            "Epoch: [56][120/391]\tTime  0.090 ( 0.096)\tLoss 1.0474e+00 (9.6492e-01)\tAcc@1  71.88 ( 71.32)\tAcc@5  92.19 ( 94.00)\n",
            "Epoch: [56][150/391]\tTime  0.092 ( 0.095)\tLoss 1.1030e+00 (9.7911e-01)\tAcc@1  65.62 ( 70.79)\tAcc@5  92.97 ( 93.85)\n",
            "Epoch: [56][180/391]\tTime  0.093 ( 0.095)\tLoss 1.0029e+00 (9.8122e-01)\tAcc@1  68.75 ( 70.80)\tAcc@5  91.41 ( 93.86)\n",
            "Epoch: [56][210/391]\tTime  0.090 ( 0.095)\tLoss 9.5542e-01 (9.8784e-01)\tAcc@1  69.53 ( 70.63)\tAcc@5  93.75 ( 93.74)\n",
            "Epoch: [56][240/391]\tTime  0.089 ( 0.095)\tLoss 1.1081e+00 (9.9536e-01)\tAcc@1  66.41 ( 70.48)\tAcc@5  95.31 ( 93.63)\n",
            "Epoch: [56][270/391]\tTime  0.090 ( 0.095)\tLoss 1.0086e+00 (1.0054e+00)\tAcc@1  72.66 ( 70.28)\tAcc@5  92.97 ( 93.48)\n",
            "Epoch: [56][300/391]\tTime  0.091 ( 0.095)\tLoss 1.0186e+00 (1.0088e+00)\tAcc@1  66.41 ( 70.15)\tAcc@5  94.53 ( 93.42)\n",
            "Epoch: [56][330/391]\tTime  0.095 ( 0.095)\tLoss 1.0202e+00 (1.0133e+00)\tAcc@1  73.44 ( 70.12)\tAcc@5  90.62 ( 93.33)\n",
            "Epoch: [56][360/391]\tTime  0.091 ( 0.094)\tLoss 1.1027e+00 (1.0178e+00)\tAcc@1  67.97 ( 69.99)\tAcc@5  93.75 ( 93.25)\n",
            "Epoch: [56][390/391]\tTime  0.082 ( 0.094)\tLoss 8.4777e-01 (1.0220e+00)\tAcc@1  78.75 ( 69.91)\tAcc@5  97.50 ( 93.17)\n",
            "==> Train Accuracy: Acc@1 69.910 || Acc@5 93.170\n",
            "==> Test Accuracy:  Acc@1 58.150 || Acc@5 85.150\n",
            "==> 39.32 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 57, lr: 0.1 -----\n",
            "Epoch: [57][  0/391]\tTime  0.295 ( 0.295)\tLoss 9.2509e-01 (9.2509e-01)\tAcc@1  70.31 ( 70.31)\tAcc@5  95.31 ( 95.31)\n",
            "Epoch: [57][ 30/391]\tTime  0.089 ( 0.101)\tLoss 9.5377e-01 (9.5646e-01)\tAcc@1  72.66 ( 70.84)\tAcc@5  92.97 ( 93.98)\n",
            "Epoch: [57][ 60/391]\tTime  0.094 ( 0.098)\tLoss 8.2758e-01 (9.4587e-01)\tAcc@1  71.09 ( 70.94)\tAcc@5  94.53 ( 94.21)\n",
            "Epoch: [57][ 90/391]\tTime  0.096 ( 0.096)\tLoss 1.0547e+00 (9.6871e-01)\tAcc@1  65.62 ( 70.87)\tAcc@5  91.41 ( 93.90)\n",
            "Epoch: [57][120/391]\tTime  0.090 ( 0.096)\tLoss 1.1726e+00 (9.8299e-01)\tAcc@1  67.97 ( 70.56)\tAcc@5  90.62 ( 93.65)\n",
            "Epoch: [57][150/391]\tTime  0.087 ( 0.095)\tLoss 1.3293e+00 (9.8865e-01)\tAcc@1  64.06 ( 70.55)\tAcc@5  89.84 ( 93.61)\n",
            "Epoch: [57][180/391]\tTime  0.091 ( 0.095)\tLoss 1.1071e+00 (9.9614e-01)\tAcc@1  72.66 ( 70.36)\tAcc@5  90.62 ( 93.51)\n",
            "Epoch: [57][210/391]\tTime  0.087 ( 0.095)\tLoss 1.0788e+00 (1.0040e+00)\tAcc@1  66.41 ( 70.21)\tAcc@5  92.19 ( 93.39)\n",
            "Epoch: [57][240/391]\tTime  0.092 ( 0.094)\tLoss 1.0115e+00 (1.0136e+00)\tAcc@1  68.75 ( 69.95)\tAcc@5  91.41 ( 93.40)\n",
            "Epoch: [57][270/391]\tTime  0.091 ( 0.094)\tLoss 1.0915e+00 (1.0185e+00)\tAcc@1  64.84 ( 69.89)\tAcc@5  95.31 ( 93.36)\n",
            "Epoch: [57][300/391]\tTime  0.103 ( 0.094)\tLoss 8.0956e-01 (1.0205e+00)\tAcc@1  78.12 ( 69.82)\tAcc@5  93.75 ( 93.35)\n",
            "Epoch: [57][330/391]\tTime  0.088 ( 0.094)\tLoss 1.0918e+00 (1.0217e+00)\tAcc@1  67.19 ( 69.76)\tAcc@5  91.41 ( 93.29)\n",
            "Epoch: [57][360/391]\tTime  0.093 ( 0.094)\tLoss 1.1583e+00 (1.0225e+00)\tAcc@1  65.62 ( 69.79)\tAcc@5  89.06 ( 93.26)\n",
            "Epoch: [57][390/391]\tTime  0.081 ( 0.094)\tLoss 9.8841e-01 (1.0276e+00)\tAcc@1  70.00 ( 69.62)\tAcc@5  96.25 ( 93.18)\n",
            "==> Train Accuracy: Acc@1 69.616 || Acc@5 93.182\n",
            "==> Test Accuracy:  Acc@1 57.040 || Acc@5 85.470\n",
            "==> 39.35 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 58, lr: 0.1 -----\n",
            "Epoch: [58][  0/391]\tTime  0.291 ( 0.291)\tLoss 9.7219e-01 (9.7219e-01)\tAcc@1  72.66 ( 72.66)\tAcc@5  93.75 ( 93.75)\n",
            "Epoch: [58][ 30/391]\tTime  0.097 ( 0.102)\tLoss 1.1411e+00 (9.9132e-01)\tAcc@1  72.66 ( 71.52)\tAcc@5  90.62 ( 93.85)\n",
            "Epoch: [58][ 60/391]\tTime  0.101 ( 0.099)\tLoss 8.3755e-01 (9.6217e-01)\tAcc@1  74.22 ( 72.05)\tAcc@5  93.75 ( 94.13)\n",
            "Epoch: [58][ 90/391]\tTime  0.090 ( 0.097)\tLoss 9.6860e-01 (9.6098e-01)\tAcc@1  71.09 ( 71.89)\tAcc@5  92.97 ( 94.21)\n",
            "Epoch: [58][120/391]\tTime  0.091 ( 0.096)\tLoss 9.6530e-01 (9.7572e-01)\tAcc@1  71.88 ( 71.26)\tAcc@5  92.97 ( 94.00)\n",
            "Epoch: [58][150/391]\tTime  0.089 ( 0.095)\tLoss 9.6587e-01 (9.7746e-01)\tAcc@1  69.53 ( 71.05)\tAcc@5  92.19 ( 93.89)\n",
            "Epoch: [58][180/391]\tTime  0.092 ( 0.095)\tLoss 1.0220e+00 (9.8208e-01)\tAcc@1  71.09 ( 71.01)\tAcc@5  93.75 ( 93.85)\n",
            "Epoch: [58][210/391]\tTime  0.094 ( 0.095)\tLoss 1.1401e+00 (9.8498e-01)\tAcc@1  66.41 ( 70.95)\tAcc@5  92.19 ( 93.81)\n",
            "Epoch: [58][240/391]\tTime  0.088 ( 0.094)\tLoss 8.8407e-01 (9.8893e-01)\tAcc@1  76.56 ( 70.88)\tAcc@5  96.09 ( 93.75)\n",
            "Epoch: [58][270/391]\tTime  0.096 ( 0.094)\tLoss 9.5723e-01 (9.9416e-01)\tAcc@1  70.31 ( 70.75)\tAcc@5  96.88 ( 93.68)\n",
            "Epoch: [58][300/391]\tTime  0.093 ( 0.094)\tLoss 7.9854e-01 (9.9897e-01)\tAcc@1  75.78 ( 70.68)\tAcc@5  95.31 ( 93.60)\n",
            "Epoch: [58][330/391]\tTime  0.091 ( 0.094)\tLoss 1.1221e+00 (1.0036e+00)\tAcc@1  65.62 ( 70.52)\tAcc@5  92.97 ( 93.56)\n",
            "Epoch: [58][360/391]\tTime  0.091 ( 0.094)\tLoss 1.0406e+00 (1.0084e+00)\tAcc@1  67.97 ( 70.46)\tAcc@5  94.53 ( 93.49)\n",
            "Epoch: [58][390/391]\tTime  0.082 ( 0.094)\tLoss 1.2183e+00 (1.0153e+00)\tAcc@1  60.00 ( 70.20)\tAcc@5  92.50 ( 93.43)\n",
            "==> Train Accuracy: Acc@1 70.202 || Acc@5 93.426\n",
            "==> Test Accuracy:  Acc@1 57.280 || Acc@5 85.250\n",
            "==> 39.23 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 59, lr: 0.1 -----\n",
            "Epoch: [59][  0/391]\tTime  0.296 ( 0.296)\tLoss 9.9686e-01 (9.9686e-01)\tAcc@1  65.62 ( 65.62)\tAcc@5  94.53 ( 94.53)\n",
            "Epoch: [59][ 30/391]\tTime  0.090 ( 0.100)\tLoss 8.9066e-01 (9.3570e-01)\tAcc@1  73.44 ( 72.08)\tAcc@5  95.31 ( 94.35)\n",
            "Epoch: [59][ 60/391]\tTime  0.091 ( 0.096)\tLoss 1.2576e+00 (9.3512e-01)\tAcc@1  67.19 ( 72.20)\tAcc@5  88.28 ( 94.04)\n",
            "Epoch: [59][ 90/391]\tTime  0.094 ( 0.095)\tLoss 1.0174e+00 (9.6481e-01)\tAcc@1  69.53 ( 71.59)\tAcc@5  96.09 ( 93.89)\n",
            "Epoch: [59][120/391]\tTime  0.096 ( 0.095)\tLoss 1.2570e+00 (9.7230e-01)\tAcc@1  67.97 ( 71.46)\tAcc@5  92.19 ( 93.75)\n",
            "Epoch: [59][150/391]\tTime  0.094 ( 0.094)\tLoss 9.3662e-01 (9.7943e-01)\tAcc@1  75.00 ( 71.18)\tAcc@5  94.53 ( 93.64)\n",
            "Epoch: [59][180/391]\tTime  0.102 ( 0.094)\tLoss 8.6460e-01 (9.8284e-01)\tAcc@1  74.22 ( 70.97)\tAcc@5  93.75 ( 93.61)\n",
            "Epoch: [59][210/391]\tTime  0.079 ( 0.095)\tLoss 9.3083e-01 (9.9096e-01)\tAcc@1  67.97 ( 70.63)\tAcc@5  96.09 ( 93.54)\n",
            "Epoch: [59][240/391]\tTime  0.094 ( 0.095)\tLoss 1.0103e+00 (1.0004e+00)\tAcc@1  71.09 ( 70.40)\tAcc@5  92.97 ( 93.44)\n",
            "Epoch: [59][270/391]\tTime  0.102 ( 0.095)\tLoss 9.6162e-01 (1.0123e+00)\tAcc@1  70.31 ( 70.10)\tAcc@5  93.75 ( 93.29)\n",
            "Epoch: [59][300/391]\tTime  0.087 ( 0.094)\tLoss 1.0996e+00 (1.0126e+00)\tAcc@1  68.75 ( 70.15)\tAcc@5  91.41 ( 93.30)\n",
            "Epoch: [59][330/391]\tTime  0.089 ( 0.094)\tLoss 9.4014e-01 (1.0157e+00)\tAcc@1  77.34 ( 70.04)\tAcc@5  94.53 ( 93.32)\n",
            "Epoch: [59][360/391]\tTime  0.103 ( 0.094)\tLoss 1.0796e+00 (1.0154e+00)\tAcc@1  67.97 ( 70.09)\tAcc@5  93.75 ( 93.28)\n",
            "Epoch: [59][390/391]\tTime  0.081 ( 0.094)\tLoss 1.0843e+00 (1.0205e+00)\tAcc@1  72.50 ( 69.97)\tAcc@5  90.00 ( 93.19)\n",
            "==> Train Accuracy: Acc@1 69.966 || Acc@5 93.188\n",
            "==> Test Accuracy:  Acc@1 59.720 || Acc@5 86.640\n",
            "==> 39.36 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 60, lr: 0.020000000000000004 -----\n",
            "Epoch: [60][  0/391]\tTime  0.297 ( 0.297)\tLoss 1.3114e+00 (1.3114e+00)\tAcc@1  60.16 ( 60.16)\tAcc@5  89.06 ( 89.06)\n",
            "Epoch: [60][ 30/391]\tTime  0.092 ( 0.101)\tLoss 5.7377e-01 (7.9489e-01)\tAcc@1  79.69 ( 76.79)\tAcc@5  99.22 ( 95.99)\n",
            "Epoch: [60][ 60/391]\tTime  0.087 ( 0.097)\tLoss 4.8607e-01 (7.2999e-01)\tAcc@1  85.94 ( 78.43)\tAcc@5  99.22 ( 96.32)\n",
            "Epoch: [60][ 90/391]\tTime  0.096 ( 0.096)\tLoss 5.2773e-01 (6.9083e-01)\tAcc@1  85.94 ( 79.51)\tAcc@5  97.66 ( 96.56)\n",
            "Epoch: [60][120/391]\tTime  0.090 ( 0.095)\tLoss 6.8266e-01 (6.5960e-01)\tAcc@1  78.91 ( 80.43)\tAcc@5  93.75 ( 96.82)\n",
            "Epoch: [60][150/391]\tTime  0.082 ( 0.095)\tLoss 6.1496e-01 (6.4213e-01)\tAcc@1  83.59 ( 80.83)\tAcc@5  97.66 ( 96.99)\n",
            "Epoch: [60][180/391]\tTime  0.094 ( 0.095)\tLoss 6.2510e-01 (6.2712e-01)\tAcc@1  84.38 ( 81.38)\tAcc@5  96.88 ( 97.13)\n",
            "Epoch: [60][210/391]\tTime  0.096 ( 0.094)\tLoss 6.2514e-01 (6.1598e-01)\tAcc@1  85.94 ( 81.64)\tAcc@5  97.66 ( 97.25)\n",
            "Epoch: [60][240/391]\tTime  0.094 ( 0.094)\tLoss 6.0737e-01 (6.0492e-01)\tAcc@1  82.81 ( 81.98)\tAcc@5  96.88 ( 97.31)\n",
            "Epoch: [60][270/391]\tTime  0.092 ( 0.094)\tLoss 5.7604e-01 (5.9633e-01)\tAcc@1  82.81 ( 82.14)\tAcc@5  97.66 ( 97.37)\n",
            "Epoch: [60][300/391]\tTime  0.089 ( 0.094)\tLoss 4.0261e-01 (5.8821e-01)\tAcc@1  87.50 ( 82.36)\tAcc@5  99.22 ( 97.46)\n",
            "Epoch: [60][330/391]\tTime  0.103 ( 0.094)\tLoss 5.7928e-01 (5.8486e-01)\tAcc@1  81.25 ( 82.42)\tAcc@5  98.44 ( 97.48)\n",
            "Epoch: [60][360/391]\tTime  0.091 ( 0.094)\tLoss 5.4012e-01 (5.7994e-01)\tAcc@1  82.81 ( 82.56)\tAcc@5  97.66 ( 97.50)\n",
            "Epoch: [60][390/391]\tTime  0.082 ( 0.094)\tLoss 3.6465e-01 (5.7169e-01)\tAcc@1  93.75 ( 82.80)\tAcc@5  97.50 ( 97.56)\n",
            "==> Train Accuracy: Acc@1 82.798 || Acc@5 97.560\n",
            "==> Test Accuracy:  Acc@1 74.080 || Acc@5 93.500\n",
            "==> 39.34 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 61, lr: 0.020000000000000004 -----\n",
            "Epoch: [61][  0/391]\tTime  0.286 ( 0.286)\tLoss 3.3374e-01 (3.3374e-01)\tAcc@1  89.06 ( 89.06)\tAcc@5  99.22 ( 99.22)\n",
            "Epoch: [61][ 30/391]\tTime  0.089 ( 0.102)\tLoss 3.3524e-01 (4.1863e-01)\tAcc@1  91.41 ( 87.32)\tAcc@5 100.00 ( 98.49)\n",
            "Epoch: [61][ 60/391]\tTime  0.104 ( 0.099)\tLoss 4.2920e-01 (3.9698e-01)\tAcc@1  87.50 ( 88.08)\tAcc@5  97.66 ( 98.63)\n",
            "Epoch: [61][ 90/391]\tTime  0.093 ( 0.097)\tLoss 4.0512e-01 (3.9355e-01)\tAcc@1  85.94 ( 88.07)\tAcc@5  98.44 ( 98.71)\n",
            "Epoch: [61][120/391]\tTime  0.109 ( 0.096)\tLoss 5.5380e-01 (3.9270e-01)\tAcc@1  82.81 ( 88.14)\tAcc@5  96.09 ( 98.68)\n",
            "Epoch: [61][150/391]\tTime  0.092 ( 0.096)\tLoss 3.8719e-01 (3.9784e-01)\tAcc@1  89.06 ( 88.04)\tAcc@5  98.44 ( 98.65)\n",
            "Epoch: [61][180/391]\tTime  0.098 ( 0.095)\tLoss 4.6275e-01 (3.9875e-01)\tAcc@1  87.50 ( 88.00)\tAcc@5  97.66 ( 98.68)\n",
            "Epoch: [61][210/391]\tTime  0.097 ( 0.095)\tLoss 3.1641e-01 (3.9849e-01)\tAcc@1  90.62 ( 88.00)\tAcc@5  99.22 ( 98.69)\n",
            "Epoch: [61][240/391]\tTime  0.096 ( 0.095)\tLoss 3.0385e-01 (4.0115e-01)\tAcc@1  89.84 ( 87.94)\tAcc@5  99.22 ( 98.67)\n",
            "Epoch: [61][270/391]\tTime  0.092 ( 0.095)\tLoss 4.9335e-01 (4.0310e-01)\tAcc@1  82.81 ( 87.83)\tAcc@5  97.66 ( 98.65)\n",
            "Epoch: [61][300/391]\tTime  0.100 ( 0.095)\tLoss 3.5251e-01 (4.0189e-01)\tAcc@1  91.41 ( 87.88)\tAcc@5 100.00 ( 98.68)\n",
            "Epoch: [61][330/391]\tTime  0.095 ( 0.094)\tLoss 4.1214e-01 (4.0315e-01)\tAcc@1  87.50 ( 87.84)\tAcc@5  98.44 ( 98.67)\n",
            "Epoch: [61][360/391]\tTime  0.098 ( 0.094)\tLoss 3.0222e-01 (4.0597e-01)\tAcc@1  90.62 ( 87.74)\tAcc@5  99.22 ( 98.65)\n",
            "Epoch: [61][390/391]\tTime  0.083 ( 0.094)\tLoss 5.5746e-01 (4.0788e-01)\tAcc@1  85.00 ( 87.67)\tAcc@5  96.25 ( 98.64)\n",
            "==> Train Accuracy: Acc@1 87.670 || Acc@5 98.638\n",
            "==> Test Accuracy:  Acc@1 73.960 || Acc@5 93.670\n",
            "==> 39.29 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 62, lr: 0.020000000000000004 -----\n",
            "Epoch: [62][  0/391]\tTime  0.284 ( 0.284)\tLoss 4.5353e-01 (4.5353e-01)\tAcc@1  86.72 ( 86.72)\tAcc@5  97.66 ( 97.66)\n",
            "Epoch: [62][ 30/391]\tTime  0.089 ( 0.102)\tLoss 3.0315e-01 (3.2202e-01)\tAcc@1  92.19 ( 90.78)\tAcc@5  99.22 ( 99.24)\n",
            "Epoch: [62][ 60/391]\tTime  0.091 ( 0.097)\tLoss 3.4790e-01 (3.1930e-01)\tAcc@1  86.72 ( 90.59)\tAcc@5 100.00 ( 99.27)\n",
            "Epoch: [62][ 90/391]\tTime  0.090 ( 0.096)\tLoss 2.6119e-01 (3.2000e-01)\tAcc@1  92.19 ( 90.53)\tAcc@5 100.00 ( 99.23)\n",
            "Epoch: [62][120/391]\tTime  0.092 ( 0.095)\tLoss 4.1755e-01 (3.2256e-01)\tAcc@1  89.06 ( 90.50)\tAcc@5 100.00 ( 99.23)\n",
            "Epoch: [62][150/391]\tTime  0.091 ( 0.095)\tLoss 3.3043e-01 (3.2491e-01)\tAcc@1  89.06 ( 90.35)\tAcc@5  98.44 ( 99.21)\n",
            "Epoch: [62][180/391]\tTime  0.093 ( 0.094)\tLoss 3.5095e-01 (3.2885e-01)\tAcc@1  89.06 ( 90.22)\tAcc@5 100.00 ( 99.19)\n",
            "Epoch: [62][210/391]\tTime  0.092 ( 0.094)\tLoss 2.8402e-01 (3.3502e-01)\tAcc@1  91.41 ( 89.97)\tAcc@5  99.22 ( 99.19)\n",
            "Epoch: [62][240/391]\tTime  0.093 ( 0.094)\tLoss 2.0579e-01 (3.3695e-01)\tAcc@1  93.75 ( 89.87)\tAcc@5 100.00 ( 99.18)\n",
            "Epoch: [62][270/391]\tTime  0.089 ( 0.094)\tLoss 4.3009e-01 (3.3882e-01)\tAcc@1  85.16 ( 89.81)\tAcc@5  99.22 ( 99.14)\n",
            "Epoch: [62][300/391]\tTime  0.085 ( 0.094)\tLoss 3.0990e-01 (3.4192e-01)\tAcc@1  88.28 ( 89.61)\tAcc@5 100.00 ( 99.12)\n",
            "Epoch: [62][330/391]\tTime  0.092 ( 0.094)\tLoss 2.9931e-01 (3.4323e-01)\tAcc@1  90.62 ( 89.54)\tAcc@5 100.00 ( 99.11)\n",
            "Epoch: [62][360/391]\tTime  0.101 ( 0.094)\tLoss 2.8749e-01 (3.4431e-01)\tAcc@1  92.97 ( 89.47)\tAcc@5 100.00 ( 99.10)\n",
            "Epoch: [62][390/391]\tTime  0.082 ( 0.094)\tLoss 2.6036e-01 (3.4436e-01)\tAcc@1  92.50 ( 89.46)\tAcc@5  98.75 ( 99.10)\n",
            "==> Train Accuracy: Acc@1 89.462 || Acc@5 99.098\n",
            "==> Test Accuracy:  Acc@1 74.240 || Acc@5 93.880\n",
            "==> 39.25 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 63, lr: 0.020000000000000004 -----\n",
            "Epoch: [63][  0/391]\tTime  0.297 ( 0.297)\tLoss 3.6215e-01 (3.6215e-01)\tAcc@1  90.62 ( 90.62)\tAcc@5  99.22 ( 99.22)\n",
            "Epoch: [63][ 30/391]\tTime  0.095 ( 0.101)\tLoss 3.0079e-01 (2.7483e-01)\tAcc@1  92.97 ( 92.21)\tAcc@5  99.22 ( 99.37)\n",
            "Epoch: [63][ 60/391]\tTime  0.090 ( 0.098)\tLoss 3.3572e-01 (2.8428e-01)\tAcc@1  87.50 ( 91.71)\tAcc@5  99.22 ( 99.35)\n",
            "Epoch: [63][ 90/391]\tTime  0.096 ( 0.096)\tLoss 3.6731e-01 (2.8600e-01)\tAcc@1  89.84 ( 91.55)\tAcc@5  98.44 ( 99.36)\n",
            "Epoch: [63][120/391]\tTime  0.090 ( 0.095)\tLoss 2.6170e-01 (2.8622e-01)\tAcc@1  92.19 ( 91.36)\tAcc@5  99.22 ( 99.41)\n",
            "Epoch: [63][150/391]\tTime  0.094 ( 0.095)\tLoss 4.2700e-01 (2.9000e-01)\tAcc@1  86.72 ( 91.16)\tAcc@5  98.44 ( 99.42)\n",
            "Epoch: [63][180/391]\tTime  0.092 ( 0.094)\tLoss 2.3766e-01 (2.8810e-01)\tAcc@1  92.19 ( 91.19)\tAcc@5 100.00 ( 99.45)\n",
            "Epoch: [63][210/391]\tTime  0.088 ( 0.094)\tLoss 2.4925e-01 (2.9032e-01)\tAcc@1  92.19 ( 91.14)\tAcc@5 100.00 ( 99.46)\n",
            "Epoch: [63][240/391]\tTime  0.094 ( 0.094)\tLoss 1.6265e-01 (2.9125e-01)\tAcc@1  95.31 ( 91.12)\tAcc@5 100.00 ( 99.43)\n",
            "Epoch: [63][270/391]\tTime  0.092 ( 0.094)\tLoss 3.0942e-01 (2.9248e-01)\tAcc@1  89.06 ( 91.13)\tAcc@5 100.00 ( 99.38)\n",
            "Epoch: [63][300/391]\tTime  0.095 ( 0.094)\tLoss 4.3001e-01 (2.9653e-01)\tAcc@1  82.81 ( 90.98)\tAcc@5  97.66 ( 99.36)\n",
            "Epoch: [63][330/391]\tTime  0.088 ( 0.094)\tLoss 2.8016e-01 (2.9988e-01)\tAcc@1  89.84 ( 90.89)\tAcc@5  99.22 ( 99.36)\n",
            "Epoch: [63][360/391]\tTime  0.091 ( 0.094)\tLoss 2.3327e-01 (3.0075e-01)\tAcc@1  92.97 ( 90.86)\tAcc@5 100.00 ( 99.37)\n",
            "Epoch: [63][390/391]\tTime  0.082 ( 0.094)\tLoss 3.6937e-01 (3.0139e-01)\tAcc@1  85.00 ( 90.82)\tAcc@5  98.75 ( 99.37)\n",
            "==> Train Accuracy: Acc@1 90.820 || Acc@5 99.374\n",
            "==> Test Accuracy:  Acc@1 74.510 || Acc@5 93.270\n",
            "==> 39.28 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 64, lr: 0.020000000000000004 -----\n",
            "Epoch: [64][  0/391]\tTime  0.284 ( 0.284)\tLoss 3.0390e-01 (3.0390e-01)\tAcc@1  92.97 ( 92.97)\tAcc@5  98.44 ( 98.44)\n",
            "Epoch: [64][ 30/391]\tTime  0.098 ( 0.102)\tLoss 1.6947e-01 (2.5572e-01)\tAcc@1  95.31 ( 92.34)\tAcc@5 100.00 ( 99.62)\n",
            "Epoch: [64][ 60/391]\tTime  0.103 ( 0.099)\tLoss 1.8933e-01 (2.4981e-01)\tAcc@1  96.88 ( 92.62)\tAcc@5 100.00 ( 99.60)\n",
            "Epoch: [64][ 90/391]\tTime  0.105 ( 0.097)\tLoss 2.2999e-01 (2.4684e-01)\tAcc@1  93.75 ( 92.76)\tAcc@5 100.00 ( 99.61)\n",
            "Epoch: [64][120/391]\tTime  0.103 ( 0.096)\tLoss 2.9987e-01 (2.4985e-01)\tAcc@1  90.62 ( 92.56)\tAcc@5  99.22 ( 99.63)\n",
            "Epoch: [64][150/391]\tTime  0.090 ( 0.096)\tLoss 2.6159e-01 (2.5187e-01)\tAcc@1  91.41 ( 92.47)\tAcc@5 100.00 ( 99.64)\n",
            "Epoch: [64][180/391]\tTime  0.089 ( 0.095)\tLoss 2.8715e-01 (2.5718e-01)\tAcc@1  89.84 ( 92.27)\tAcc@5  99.22 ( 99.58)\n",
            "Epoch: [64][210/391]\tTime  0.092 ( 0.095)\tLoss 1.6433e-01 (2.6143e-01)\tAcc@1  96.88 ( 92.15)\tAcc@5 100.00 ( 99.57)\n",
            "Epoch: [64][240/391]\tTime  0.097 ( 0.095)\tLoss 1.9894e-01 (2.6155e-01)\tAcc@1  94.53 ( 92.14)\tAcc@5 100.00 ( 99.58)\n",
            "Epoch: [64][270/391]\tTime  0.091 ( 0.095)\tLoss 2.2165e-01 (2.6347e-01)\tAcc@1  94.53 ( 92.08)\tAcc@5 100.00 ( 99.58)\n",
            "Epoch: [64][300/391]\tTime  0.090 ( 0.094)\tLoss 3.2047e-01 (2.6491e-01)\tAcc@1  87.50 ( 92.03)\tAcc@5 100.00 ( 99.59)\n",
            "Epoch: [64][330/391]\tTime  0.091 ( 0.094)\tLoss 3.4368e-01 (2.6733e-01)\tAcc@1  90.62 ( 91.96)\tAcc@5  99.22 ( 99.58)\n",
            "Epoch: [64][360/391]\tTime  0.096 ( 0.094)\tLoss 3.0674e-01 (2.7064e-01)\tAcc@1  89.84 ( 91.84)\tAcc@5 100.00 ( 99.56)\n",
            "Epoch: [64][390/391]\tTime  0.081 ( 0.094)\tLoss 3.6506e-01 (2.7380e-01)\tAcc@1  88.75 ( 91.70)\tAcc@5  97.50 ( 99.54)\n",
            "==> Train Accuracy: Acc@1 91.704 || Acc@5 99.538\n",
            "==> Test Accuracy:  Acc@1 73.660 || Acc@5 93.450\n",
            "==> 39.28 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 65, lr: 0.020000000000000004 -----\n",
            "Epoch: [65][  0/391]\tTime  0.282 ( 0.282)\tLoss 2.3931e-01 (2.3931e-01)\tAcc@1  92.97 ( 92.97)\tAcc@5  99.22 ( 99.22)\n",
            "Epoch: [65][ 30/391]\tTime  0.091 ( 0.100)\tLoss 3.0586e-01 (2.2216e-01)\tAcc@1  90.62 ( 93.85)\tAcc@5  99.22 ( 99.60)\n",
            "Epoch: [65][ 60/391]\tTime  0.095 ( 0.096)\tLoss 2.8032e-01 (2.2478e-01)\tAcc@1  93.75 ( 93.75)\tAcc@5  97.66 ( 99.58)\n",
            "Epoch: [65][ 90/391]\tTime  0.098 ( 0.095)\tLoss 3.4568e-01 (2.2930e-01)\tAcc@1  86.72 ( 93.47)\tAcc@5  98.44 ( 99.55)\n",
            "Epoch: [65][120/391]\tTime  0.093 ( 0.095)\tLoss 1.9806e-01 (2.3092e-01)\tAcc@1  94.53 ( 93.32)\tAcc@5 100.00 ( 99.58)\n",
            "Epoch: [65][150/391]\tTime  0.092 ( 0.095)\tLoss 2.9555e-01 (2.3226e-01)\tAcc@1  92.19 ( 93.18)\tAcc@5  98.44 ( 99.59)\n",
            "Epoch: [65][180/391]\tTime  0.091 ( 0.095)\tLoss 2.0897e-01 (2.3464e-01)\tAcc@1  92.19 ( 93.09)\tAcc@5 100.00 ( 99.58)\n",
            "Epoch: [65][210/391]\tTime  0.086 ( 0.094)\tLoss 1.8432e-01 (2.3518e-01)\tAcc@1  91.41 ( 93.07)\tAcc@5 100.00 ( 99.57)\n",
            "Epoch: [65][240/391]\tTime  0.089 ( 0.094)\tLoss 3.0770e-01 (2.3875e-01)\tAcc@1  89.84 ( 92.89)\tAcc@5 100.00 ( 99.55)\n",
            "Epoch: [65][270/391]\tTime  0.099 ( 0.094)\tLoss 2.3014e-01 (2.4198e-01)\tAcc@1  93.75 ( 92.71)\tAcc@5 100.00 ( 99.56)\n",
            "Epoch: [65][300/391]\tTime  0.085 ( 0.094)\tLoss 2.8780e-01 (2.4423e-01)\tAcc@1  88.28 ( 92.62)\tAcc@5 100.00 ( 99.56)\n",
            "Epoch: [65][330/391]\tTime  0.089 ( 0.094)\tLoss 1.7430e-01 (2.4591e-01)\tAcc@1  93.75 ( 92.56)\tAcc@5 100.00 ( 99.57)\n",
            "Epoch: [65][360/391]\tTime  0.094 ( 0.094)\tLoss 3.2776e-01 (2.5008e-01)\tAcc@1  88.28 ( 92.40)\tAcc@5 100.00 ( 99.56)\n",
            "Epoch: [65][390/391]\tTime  0.082 ( 0.094)\tLoss 3.3388e-01 (2.5233e-01)\tAcc@1  92.50 ( 92.32)\tAcc@5 100.00 ( 99.55)\n",
            "==> Train Accuracy: Acc@1 92.316 || Acc@5 99.552\n",
            "==> Test Accuracy:  Acc@1 73.190 || Acc@5 92.980\n",
            "==> 39.34 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 66, lr: 0.020000000000000004 -----\n",
            "Epoch: [66][  0/391]\tTime  0.295 ( 0.295)\tLoss 2.4482e-01 (2.4482e-01)\tAcc@1  93.75 ( 93.75)\tAcc@5  99.22 ( 99.22)\n",
            "Epoch: [66][ 30/391]\tTime  0.094 ( 0.102)\tLoss 1.3724e-01 (2.1318e-01)\tAcc@1  96.09 ( 93.65)\tAcc@5 100.00 ( 99.77)\n",
            "Epoch: [66][ 60/391]\tTime  0.100 ( 0.098)\tLoss 2.2850e-01 (2.1262e-01)\tAcc@1  95.31 ( 93.74)\tAcc@5  99.22 ( 99.77)\n",
            "Epoch: [66][ 90/391]\tTime  0.092 ( 0.096)\tLoss 2.1071e-01 (2.1272e-01)\tAcc@1  94.53 ( 93.73)\tAcc@5  99.22 ( 99.77)\n",
            "Epoch: [66][120/391]\tTime  0.091 ( 0.095)\tLoss 1.4932e-01 (2.1539e-01)\tAcc@1  95.31 ( 93.56)\tAcc@5 100.00 ( 99.77)\n",
            "Epoch: [66][150/391]\tTime  0.090 ( 0.095)\tLoss 2.4670e-01 (2.1841e-01)\tAcc@1  93.75 ( 93.44)\tAcc@5 100.00 ( 99.77)\n",
            "Epoch: [66][180/391]\tTime  0.092 ( 0.094)\tLoss 1.9523e-01 (2.2176e-01)\tAcc@1  93.75 ( 93.29)\tAcc@5 100.00 ( 99.75)\n",
            "Epoch: [66][210/391]\tTime  0.094 ( 0.094)\tLoss 2.0488e-01 (2.2462e-01)\tAcc@1  94.53 ( 93.22)\tAcc@5 100.00 ( 99.75)\n",
            "Epoch: [66][240/391]\tTime  0.096 ( 0.094)\tLoss 2.3060e-01 (2.2508e-01)\tAcc@1  92.97 ( 93.21)\tAcc@5 100.00 ( 99.75)\n",
            "Epoch: [66][270/391]\tTime  0.095 ( 0.094)\tLoss 3.1907e-01 (2.2709e-01)\tAcc@1  89.06 ( 93.13)\tAcc@5 100.00 ( 99.75)\n",
            "Epoch: [66][300/391]\tTime  0.093 ( 0.094)\tLoss 2.1861e-01 (2.3088e-01)\tAcc@1  93.75 ( 93.00)\tAcc@5 100.00 ( 99.74)\n",
            "Epoch: [66][330/391]\tTime  0.093 ( 0.094)\tLoss 1.9246e-01 (2.3242e-01)\tAcc@1  95.31 ( 92.92)\tAcc@5  99.22 ( 99.73)\n",
            "Epoch: [66][360/391]\tTime  0.096 ( 0.094)\tLoss 3.3885e-01 (2.3511e-01)\tAcc@1  85.16 ( 92.82)\tAcc@5 100.00 ( 99.71)\n",
            "Epoch: [66][390/391]\tTime  0.082 ( 0.094)\tLoss 2.9880e-01 (2.3707e-01)\tAcc@1  90.00 ( 92.76)\tAcc@5 100.00 ( 99.71)\n",
            "==> Train Accuracy: Acc@1 92.758 || Acc@5 99.706\n",
            "==> Test Accuracy:  Acc@1 73.540 || Acc@5 92.570\n",
            "==> 39.13 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 67, lr: 0.020000000000000004 -----\n",
            "Epoch: [67][  0/391]\tTime  0.277 ( 0.277)\tLoss 1.7868e-01 (1.7868e-01)\tAcc@1  95.31 ( 95.31)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [67][ 30/391]\tTime  0.092 ( 0.101)\tLoss 2.9430e-01 (2.0537e-01)\tAcc@1  92.19 ( 93.67)\tAcc@5 100.00 ( 99.72)\n",
            "Epoch: [67][ 60/391]\tTime  0.091 ( 0.097)\tLoss 1.6248e-01 (2.0071e-01)\tAcc@1  94.53 ( 93.85)\tAcc@5 100.00 ( 99.81)\n",
            "Epoch: [67][ 90/391]\tTime  0.095 ( 0.096)\tLoss 2.0559e-01 (2.0422e-01)\tAcc@1  95.31 ( 93.78)\tAcc@5 100.00 ( 99.80)\n",
            "Epoch: [67][120/391]\tTime  0.087 ( 0.095)\tLoss 1.7594e-01 (2.0637e-01)\tAcc@1  93.75 ( 93.69)\tAcc@5 100.00 ( 99.81)\n",
            "Epoch: [67][150/391]\tTime  0.088 ( 0.095)\tLoss 1.7947e-01 (2.0712e-01)\tAcc@1  94.53 ( 93.65)\tAcc@5 100.00 ( 99.80)\n",
            "Epoch: [67][180/391]\tTime  0.089 ( 0.095)\tLoss 3.1998e-01 (2.1121e-01)\tAcc@1  88.28 ( 93.51)\tAcc@5 100.00 ( 99.78)\n",
            "Epoch: [67][210/391]\tTime  0.097 ( 0.095)\tLoss 2.4011e-01 (2.1401e-01)\tAcc@1  92.97 ( 93.42)\tAcc@5  99.22 ( 99.77)\n",
            "Epoch: [67][240/391]\tTime  0.093 ( 0.095)\tLoss 2.1055e-01 (2.1782e-01)\tAcc@1  93.75 ( 93.34)\tAcc@5 100.00 ( 99.75)\n",
            "Epoch: [67][270/391]\tTime  0.098 ( 0.094)\tLoss 2.0486e-01 (2.2145e-01)\tAcc@1  94.53 ( 93.20)\tAcc@5 100.00 ( 99.75)\n",
            "Epoch: [67][300/391]\tTime  0.095 ( 0.094)\tLoss 2.9351e-01 (2.2379e-01)\tAcc@1  87.50 ( 93.11)\tAcc@5 100.00 ( 99.75)\n",
            "Epoch: [67][330/391]\tTime  0.094 ( 0.094)\tLoss 2.6811e-01 (2.2744e-01)\tAcc@1  92.19 ( 92.99)\tAcc@5 100.00 ( 99.74)\n",
            "Epoch: [67][360/391]\tTime  0.088 ( 0.094)\tLoss 2.4130e-01 (2.2908e-01)\tAcc@1  92.19 ( 92.95)\tAcc@5  99.22 ( 99.73)\n",
            "Epoch: [67][390/391]\tTime  0.082 ( 0.094)\tLoss 3.2755e-01 (2.3053e-01)\tAcc@1  90.00 ( 92.89)\tAcc@5  97.50 ( 99.72)\n",
            "==> Train Accuracy: Acc@1 92.890 || Acc@5 99.722\n",
            "==> Test Accuracy:  Acc@1 73.340 || Acc@5 92.350\n",
            "==> 39.28 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 68, lr: 0.020000000000000004 -----\n",
            "Epoch: [68][  0/391]\tTime  0.269 ( 0.269)\tLoss 2.0651e-01 (2.0651e-01)\tAcc@1  92.19 ( 92.19)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [68][ 30/391]\tTime  0.091 ( 0.101)\tLoss 1.9023e-01 (1.8836e-01)\tAcc@1  93.75 ( 94.08)\tAcc@5  99.22 ( 99.90)\n",
            "Epoch: [68][ 60/391]\tTime  0.090 ( 0.097)\tLoss 2.0088e-01 (1.9862e-01)\tAcc@1  96.09 ( 93.81)\tAcc@5  99.22 ( 99.81)\n",
            "Epoch: [68][ 90/391]\tTime  0.089 ( 0.096)\tLoss 3.1889e-01 (2.0307e-01)\tAcc@1  89.06 ( 93.61)\tAcc@5  99.22 ( 99.81)\n",
            "Epoch: [68][120/391]\tTime  0.097 ( 0.095)\tLoss 3.1141e-01 (2.0578e-01)\tAcc@1  90.62 ( 93.63)\tAcc@5 100.00 ( 99.79)\n",
            "Epoch: [68][150/391]\tTime  0.093 ( 0.095)\tLoss 2.1053e-01 (2.0768e-01)\tAcc@1  92.97 ( 93.56)\tAcc@5  99.22 ( 99.79)\n",
            "Epoch: [68][180/391]\tTime  0.106 ( 0.095)\tLoss 2.3248e-01 (2.1016e-01)\tAcc@1  93.75 ( 93.53)\tAcc@5  99.22 ( 99.78)\n",
            "Epoch: [68][210/391]\tTime  0.090 ( 0.094)\tLoss 3.3191e-01 (2.1469e-01)\tAcc@1  89.84 ( 93.36)\tAcc@5 100.00 ( 99.77)\n",
            "Epoch: [68][240/391]\tTime  0.093 ( 0.094)\tLoss 2.2945e-01 (2.1769e-01)\tAcc@1  94.53 ( 93.31)\tAcc@5  99.22 ( 99.74)\n",
            "Epoch: [68][270/391]\tTime  0.100 ( 0.094)\tLoss 2.4014e-01 (2.1852e-01)\tAcc@1  92.19 ( 93.29)\tAcc@5  99.22 ( 99.75)\n",
            "Epoch: [68][300/391]\tTime  0.088 ( 0.094)\tLoss 1.7338e-01 (2.2098e-01)\tAcc@1  95.31 ( 93.17)\tAcc@5 100.00 ( 99.75)\n",
            "Epoch: [68][330/391]\tTime  0.092 ( 0.094)\tLoss 2.0971e-01 (2.2295e-01)\tAcc@1  95.31 ( 93.11)\tAcc@5 100.00 ( 99.75)\n",
            "Epoch: [68][360/391]\tTime  0.091 ( 0.094)\tLoss 2.8484e-01 (2.2578e-01)\tAcc@1  90.62 ( 93.01)\tAcc@5 100.00 ( 99.74)\n",
            "Epoch: [68][390/391]\tTime  0.082 ( 0.094)\tLoss 3.0635e-01 (2.2882e-01)\tAcc@1  91.25 ( 92.93)\tAcc@5 100.00 ( 99.75)\n",
            "==> Train Accuracy: Acc@1 92.932 || Acc@5 99.748\n",
            "==> Test Accuracy:  Acc@1 73.040 || Acc@5 92.640\n",
            "==> 39.17 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 69, lr: 0.020000000000000004 -----\n",
            "Epoch: [69][  0/391]\tTime  0.316 ( 0.316)\tLoss 2.0299e-01 (2.0299e-01)\tAcc@1  97.66 ( 97.66)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [69][ 30/391]\tTime  0.099 ( 0.102)\tLoss 2.4310e-01 (1.9273e-01)\tAcc@1  92.97 ( 94.15)\tAcc@5 100.00 ( 99.87)\n",
            "Epoch: [69][ 60/391]\tTime  0.094 ( 0.098)\tLoss 1.9323e-01 (1.9363e-01)\tAcc@1  94.53 ( 94.16)\tAcc@5 100.00 ( 99.87)\n",
            "Epoch: [69][ 90/391]\tTime  0.090 ( 0.096)\tLoss 2.5371e-01 (1.8995e-01)\tAcc@1  92.19 ( 94.33)\tAcc@5  98.44 ( 99.86)\n",
            "Epoch: [69][120/391]\tTime  0.085 ( 0.095)\tLoss 1.7797e-01 (1.8943e-01)\tAcc@1  94.53 ( 94.25)\tAcc@5 100.00 ( 99.86)\n",
            "Epoch: [69][150/391]\tTime  0.090 ( 0.095)\tLoss 2.0109e-01 (1.9322e-01)\tAcc@1  91.41 ( 94.10)\tAcc@5 100.00 ( 99.84)\n",
            "Epoch: [69][180/391]\tTime  0.092 ( 0.094)\tLoss 2.6925e-01 (1.9870e-01)\tAcc@1  89.84 ( 93.88)\tAcc@5 100.00 ( 99.83)\n",
            "Epoch: [69][210/391]\tTime  0.106 ( 0.094)\tLoss 1.1290e-01 (1.9984e-01)\tAcc@1  96.09 ( 93.87)\tAcc@5 100.00 ( 99.83)\n",
            "Epoch: [69][240/391]\tTime  0.094 ( 0.094)\tLoss 2.7647e-01 (2.0122e-01)\tAcc@1  91.41 ( 93.84)\tAcc@5 100.00 ( 99.83)\n",
            "Epoch: [69][270/391]\tTime  0.095 ( 0.094)\tLoss 2.0640e-01 (2.0404e-01)\tAcc@1  94.53 ( 93.74)\tAcc@5  99.22 ( 99.82)\n",
            "Epoch: [69][300/391]\tTime  0.092 ( 0.094)\tLoss 1.8075e-01 (2.0841e-01)\tAcc@1  92.97 ( 93.59)\tAcc@5 100.00 ( 99.80)\n",
            "Epoch: [69][330/391]\tTime  0.095 ( 0.094)\tLoss 2.1114e-01 (2.1106e-01)\tAcc@1  93.75 ( 93.52)\tAcc@5  99.22 ( 99.78)\n",
            "Epoch: [69][360/391]\tTime  0.091 ( 0.094)\tLoss 2.2833e-01 (2.1325e-01)\tAcc@1  91.41 ( 93.43)\tAcc@5 100.00 ( 99.77)\n",
            "Epoch: [69][390/391]\tTime  0.081 ( 0.094)\tLoss 2.1819e-01 (2.1508e-01)\tAcc@1  92.50 ( 93.40)\tAcc@5 100.00 ( 99.77)\n",
            "==> Train Accuracy: Acc@1 93.402 || Acc@5 99.774\n",
            "==> Test Accuracy:  Acc@1 72.030 || Acc@5 92.200\n",
            "==> 39.10 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 70, lr: 0.020000000000000004 -----\n",
            "Epoch: [70][  0/391]\tTime  0.287 ( 0.287)\tLoss 1.2794e-01 (1.2794e-01)\tAcc@1  97.66 ( 97.66)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [70][ 30/391]\tTime  0.093 ( 0.101)\tLoss 1.6544e-01 (1.9137e-01)\tAcc@1  95.31 ( 94.23)\tAcc@5 100.00 ( 99.87)\n",
            "Epoch: [70][ 60/391]\tTime  0.100 ( 0.097)\tLoss 2.4736e-01 (1.9358e-01)\tAcc@1  92.97 ( 94.28)\tAcc@5 100.00 ( 99.81)\n",
            "Epoch: [70][ 90/391]\tTime  0.094 ( 0.096)\tLoss 1.6517e-01 (1.9755e-01)\tAcc@1  95.31 ( 94.26)\tAcc@5 100.00 ( 99.79)\n",
            "Epoch: [70][120/391]\tTime  0.094 ( 0.095)\tLoss 2.1942e-01 (2.0313e-01)\tAcc@1  93.75 ( 94.03)\tAcc@5 100.00 ( 99.75)\n",
            "Epoch: [70][150/391]\tTime  0.088 ( 0.095)\tLoss 2.3843e-01 (2.0616e-01)\tAcc@1  92.97 ( 93.82)\tAcc@5 100.00 ( 99.77)\n",
            "Epoch: [70][180/391]\tTime  0.097 ( 0.095)\tLoss 1.5783e-01 (2.0861e-01)\tAcc@1  97.66 ( 93.74)\tAcc@5 100.00 ( 99.76)\n",
            "Epoch: [70][210/391]\tTime  0.100 ( 0.095)\tLoss 3.3181e-01 (2.1299e-01)\tAcc@1  88.28 ( 93.57)\tAcc@5  99.22 ( 99.76)\n",
            "Epoch: [70][240/391]\tTime  0.104 ( 0.095)\tLoss 2.5642e-01 (2.1604e-01)\tAcc@1  92.97 ( 93.52)\tAcc@5  99.22 ( 99.74)\n",
            "Epoch: [70][270/391]\tTime  0.083 ( 0.095)\tLoss 2.1865e-01 (2.1912e-01)\tAcc@1  91.41 ( 93.39)\tAcc@5 100.00 ( 99.75)\n",
            "Epoch: [70][300/391]\tTime  0.106 ( 0.095)\tLoss 2.3016e-01 (2.2346e-01)\tAcc@1  92.97 ( 93.24)\tAcc@5 100.00 ( 99.74)\n",
            "Epoch: [70][330/391]\tTime  0.088 ( 0.095)\tLoss 3.0324e-01 (2.2791e-01)\tAcc@1  90.62 ( 93.06)\tAcc@5 100.00 ( 99.71)\n",
            "Epoch: [70][360/391]\tTime  0.091 ( 0.094)\tLoss 1.9631e-01 (2.3139e-01)\tAcc@1  93.75 ( 92.95)\tAcc@5 100.00 ( 99.69)\n",
            "Epoch: [70][390/391]\tTime  0.082 ( 0.094)\tLoss 3.7300e-01 (2.3503e-01)\tAcc@1  87.50 ( 92.83)\tAcc@5  98.75 ( 99.69)\n",
            "==> Train Accuracy: Acc@1 92.834 || Acc@5 99.688\n",
            "==> Test Accuracy:  Acc@1 71.520 || Acc@5 91.840\n",
            "==> 39.36 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 71, lr: 0.020000000000000004 -----\n",
            "Epoch: [71][  0/391]\tTime  0.283 ( 0.283)\tLoss 2.8014e-01 (2.8014e-01)\tAcc@1  92.97 ( 92.97)\tAcc@5  99.22 ( 99.22)\n",
            "Epoch: [71][ 30/391]\tTime  0.094 ( 0.101)\tLoss 1.7615e-01 (2.1631e-01)\tAcc@1  94.53 ( 93.78)\tAcc@5 100.00 ( 99.77)\n",
            "Epoch: [71][ 60/391]\tTime  0.091 ( 0.097)\tLoss 2.2582e-01 (2.0576e-01)\tAcc@1  92.19 ( 94.06)\tAcc@5 100.00 ( 99.81)\n",
            "Epoch: [71][ 90/391]\tTime  0.093 ( 0.096)\tLoss 2.7569e-01 (2.0827e-01)\tAcc@1  93.75 ( 93.91)\tAcc@5  99.22 ( 99.79)\n",
            "Epoch: [71][120/391]\tTime  0.091 ( 0.095)\tLoss 3.2235e-01 (2.0881e-01)\tAcc@1  87.50 ( 93.90)\tAcc@5 100.00 ( 99.81)\n",
            "Epoch: [71][150/391]\tTime  0.099 ( 0.095)\tLoss 1.5354e-01 (2.1046e-01)\tAcc@1  96.09 ( 93.79)\tAcc@5 100.00 ( 99.81)\n",
            "Epoch: [71][180/391]\tTime  0.101 ( 0.095)\tLoss 2.1247e-01 (2.1178e-01)\tAcc@1  91.41 ( 93.75)\tAcc@5 100.00 ( 99.79)\n",
            "Epoch: [71][210/391]\tTime  0.100 ( 0.094)\tLoss 1.9422e-01 (2.1390e-01)\tAcc@1  96.88 ( 93.61)\tAcc@5  99.22 ( 99.78)\n",
            "Epoch: [71][240/391]\tTime  0.093 ( 0.094)\tLoss 2.1199e-01 (2.1399e-01)\tAcc@1  95.31 ( 93.57)\tAcc@5 100.00 ( 99.80)\n",
            "Epoch: [71][270/391]\tTime  0.095 ( 0.094)\tLoss 2.9816e-01 (2.1828e-01)\tAcc@1  94.53 ( 93.44)\tAcc@5  98.44 ( 99.78)\n",
            "Epoch: [71][300/391]\tTime  0.095 ( 0.094)\tLoss 3.6335e-01 (2.2038e-01)\tAcc@1  86.72 ( 93.32)\tAcc@5 100.00 ( 99.78)\n",
            "Epoch: [71][330/391]\tTime  0.088 ( 0.094)\tLoss 1.7960e-01 (2.2444e-01)\tAcc@1  94.53 ( 93.18)\tAcc@5 100.00 ( 99.77)\n",
            "Epoch: [71][360/391]\tTime  0.090 ( 0.094)\tLoss 3.9252e-01 (2.2984e-01)\tAcc@1  86.72 ( 92.98)\tAcc@5  99.22 ( 99.75)\n",
            "Epoch: [71][390/391]\tTime  0.082 ( 0.094)\tLoss 4.2217e-01 (2.3325e-01)\tAcc@1  90.00 ( 92.86)\tAcc@5  97.50 ( 99.73)\n",
            "==> Train Accuracy: Acc@1 92.858 || Acc@5 99.732\n",
            "==> Test Accuracy:  Acc@1 71.250 || Acc@5 92.170\n",
            "==> 39.19 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 72, lr: 0.020000000000000004 -----\n",
            "Epoch: [72][  0/391]\tTime  0.322 ( 0.322)\tLoss 2.7792e-01 (2.7792e-01)\tAcc@1  91.41 ( 91.41)\tAcc@5  99.22 ( 99.22)\n",
            "Epoch: [72][ 30/391]\tTime  0.091 ( 0.102)\tLoss 2.0971e-01 (2.2967e-01)\tAcc@1  93.75 ( 92.64)\tAcc@5  99.22 ( 99.67)\n",
            "Epoch: [72][ 60/391]\tTime  0.087 ( 0.098)\tLoss 1.4692e-01 (2.2331e-01)\tAcc@1  96.88 ( 93.02)\tAcc@5 100.00 ( 99.68)\n",
            "Epoch: [72][ 90/391]\tTime  0.103 ( 0.097)\tLoss 2.1649e-01 (2.1814e-01)\tAcc@1  92.97 ( 93.27)\tAcc@5 100.00 ( 99.72)\n",
            "Epoch: [72][120/391]\tTime  0.091 ( 0.096)\tLoss 1.7634e-01 (2.1494e-01)\tAcc@1  93.75 ( 93.46)\tAcc@5 100.00 ( 99.74)\n",
            "Epoch: [72][150/391]\tTime  0.102 ( 0.096)\tLoss 3.0728e-01 (2.1489e-01)\tAcc@1  89.06 ( 93.41)\tAcc@5 100.00 ( 99.76)\n",
            "Epoch: [72][180/391]\tTime  0.090 ( 0.095)\tLoss 1.9759e-01 (2.1466e-01)\tAcc@1  94.53 ( 93.43)\tAcc@5  99.22 ( 99.77)\n",
            "Epoch: [72][210/391]\tTime  0.093 ( 0.095)\tLoss 2.9712e-01 (2.1742e-01)\tAcc@1  89.06 ( 93.39)\tAcc@5  99.22 ( 99.77)\n",
            "Epoch: [72][240/391]\tTime  0.095 ( 0.095)\tLoss 2.1530e-01 (2.2102e-01)\tAcc@1  95.31 ( 93.28)\tAcc@5 100.00 ( 99.78)\n",
            "Epoch: [72][270/391]\tTime  0.092 ( 0.095)\tLoss 2.8921e-01 (2.2481e-01)\tAcc@1  92.19 ( 93.19)\tAcc@5 100.00 ( 99.77)\n",
            "Epoch: [72][300/391]\tTime  0.092 ( 0.095)\tLoss 2.4456e-01 (2.2854e-01)\tAcc@1  90.62 ( 93.04)\tAcc@5 100.00 ( 99.78)\n",
            "Epoch: [72][330/391]\tTime  0.084 ( 0.094)\tLoss 1.2766e-01 (2.3079e-01)\tAcc@1  98.44 ( 92.93)\tAcc@5 100.00 ( 99.77)\n",
            "Epoch: [72][360/391]\tTime  0.088 ( 0.094)\tLoss 3.1221e-01 (2.3393e-01)\tAcc@1  89.06 ( 92.82)\tAcc@5  99.22 ( 99.76)\n",
            "Epoch: [72][390/391]\tTime  0.083 ( 0.094)\tLoss 3.8181e-01 (2.3672e-01)\tAcc@1  90.00 ( 92.74)\tAcc@5 100.00 ( 99.74)\n",
            "==> Train Accuracy: Acc@1 92.744 || Acc@5 99.744\n",
            "==> Test Accuracy:  Acc@1 70.500 || Acc@5 91.120\n",
            "==> 39.31 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 73, lr: 0.020000000000000004 -----\n",
            "Epoch: [73][  0/391]\tTime  0.272 ( 0.272)\tLoss 1.6664e-01 (1.6664e-01)\tAcc@1  96.09 ( 96.09)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [73][ 30/391]\tTime  0.091 ( 0.099)\tLoss 1.8903e-01 (2.0309e-01)\tAcc@1  93.75 ( 93.85)\tAcc@5 100.00 ( 99.95)\n",
            "Epoch: [73][ 60/391]\tTime  0.094 ( 0.096)\tLoss 2.0364e-01 (1.9443e-01)\tAcc@1  92.19 ( 94.04)\tAcc@5 100.00 ( 99.86)\n",
            "Epoch: [73][ 90/391]\tTime  0.100 ( 0.095)\tLoss 1.3990e-01 (1.9522e-01)\tAcc@1  96.09 ( 94.02)\tAcc@5 100.00 ( 99.85)\n",
            "Epoch: [73][120/391]\tTime  0.092 ( 0.094)\tLoss 1.7152e-01 (1.9864e-01)\tAcc@1  93.75 ( 93.87)\tAcc@5  99.22 ( 99.81)\n",
            "Epoch: [73][150/391]\tTime  0.091 ( 0.094)\tLoss 1.6743e-01 (2.0271e-01)\tAcc@1  95.31 ( 93.74)\tAcc@5 100.00 ( 99.81)\n",
            "Epoch: [73][180/391]\tTime  0.093 ( 0.094)\tLoss 2.5430e-01 (2.0864e-01)\tAcc@1  90.62 ( 93.58)\tAcc@5  99.22 ( 99.80)\n",
            "Epoch: [73][210/391]\tTime  0.094 ( 0.094)\tLoss 2.6235e-01 (2.1575e-01)\tAcc@1  91.41 ( 93.36)\tAcc@5  98.44 ( 99.78)\n",
            "Epoch: [73][240/391]\tTime  0.102 ( 0.094)\tLoss 2.4157e-01 (2.2111e-01)\tAcc@1  91.41 ( 93.12)\tAcc@5  99.22 ( 99.78)\n",
            "Epoch: [73][270/391]\tTime  0.092 ( 0.094)\tLoss 1.7439e-01 (2.2481e-01)\tAcc@1  96.09 ( 93.05)\tAcc@5 100.00 ( 99.77)\n",
            "Epoch: [73][300/391]\tTime  0.101 ( 0.094)\tLoss 3.0177e-01 (2.2883e-01)\tAcc@1  92.19 ( 92.88)\tAcc@5  99.22 ( 99.76)\n",
            "Epoch: [73][330/391]\tTime  0.095 ( 0.094)\tLoss 2.6024e-01 (2.3312e-01)\tAcc@1  90.62 ( 92.74)\tAcc@5 100.00 ( 99.75)\n",
            "Epoch: [73][360/391]\tTime  0.087 ( 0.094)\tLoss 1.5039e-01 (2.3684e-01)\tAcc@1  95.31 ( 92.65)\tAcc@5 100.00 ( 99.75)\n",
            "Epoch: [73][390/391]\tTime  0.082 ( 0.094)\tLoss 1.5629e-01 (2.3826e-01)\tAcc@1  95.00 ( 92.60)\tAcc@5 100.00 ( 99.75)\n",
            "==> Train Accuracy: Acc@1 92.602 || Acc@5 99.748\n",
            "==> Test Accuracy:  Acc@1 71.130 || Acc@5 91.570\n",
            "==> 39.13 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 74, lr: 0.020000000000000004 -----\n",
            "Epoch: [74][  0/391]\tTime  0.289 ( 0.289)\tLoss 2.4839e-01 (2.4839e-01)\tAcc@1  92.97 ( 92.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [74][ 30/391]\tTime  0.088 ( 0.101)\tLoss 1.3268e-01 (2.2077e-01)\tAcc@1  96.88 ( 93.40)\tAcc@5 100.00 ( 99.70)\n",
            "Epoch: [74][ 60/391]\tTime  0.102 ( 0.097)\tLoss 1.3774e-01 (2.1007e-01)\tAcc@1  96.09 ( 93.89)\tAcc@5 100.00 ( 99.78)\n",
            "Epoch: [74][ 90/391]\tTime  0.099 ( 0.095)\tLoss 1.3229e-01 (2.1332e-01)\tAcc@1  96.88 ( 93.81)\tAcc@5 100.00 ( 99.79)\n",
            "Epoch: [74][120/391]\tTime  0.092 ( 0.095)\tLoss 2.6468e-01 (2.1764e-01)\tAcc@1  89.84 ( 93.67)\tAcc@5 100.00 ( 99.76)\n",
            "Epoch: [74][150/391]\tTime  0.091 ( 0.094)\tLoss 2.6419e-01 (2.2566e-01)\tAcc@1  92.19 ( 93.36)\tAcc@5 100.00 ( 99.73)\n",
            "Epoch: [74][180/391]\tTime  0.108 ( 0.094)\tLoss 1.9971e-01 (2.2858e-01)\tAcc@1  93.75 ( 93.24)\tAcc@5 100.00 ( 99.73)\n",
            "Epoch: [74][210/391]\tTime  0.089 ( 0.094)\tLoss 2.6547e-01 (2.2919e-01)\tAcc@1  92.19 ( 93.18)\tAcc@5 100.00 ( 99.74)\n",
            "Epoch: [74][240/391]\tTime  0.087 ( 0.094)\tLoss 2.0584e-01 (2.3077e-01)\tAcc@1  93.75 ( 93.06)\tAcc@5 100.00 ( 99.75)\n",
            "Epoch: [74][270/391]\tTime  0.092 ( 0.094)\tLoss 2.7689e-01 (2.3284e-01)\tAcc@1  91.41 ( 92.95)\tAcc@5  99.22 ( 99.75)\n",
            "Epoch: [74][300/391]\tTime  0.086 ( 0.094)\tLoss 2.9344e-01 (2.3460e-01)\tAcc@1  91.41 ( 92.88)\tAcc@5  99.22 ( 99.76)\n",
            "Epoch: [74][330/391]\tTime  0.091 ( 0.094)\tLoss 2.0005e-01 (2.3441e-01)\tAcc@1  92.97 ( 92.91)\tAcc@5 100.00 ( 99.75)\n",
            "Epoch: [74][360/391]\tTime  0.088 ( 0.094)\tLoss 4.1999e-01 (2.3859e-01)\tAcc@1  85.16 ( 92.78)\tAcc@5  99.22 ( 99.73)\n",
            "Epoch: [74][390/391]\tTime  0.082 ( 0.094)\tLoss 1.9896e-01 (2.4235e-01)\tAcc@1  95.00 ( 92.68)\tAcc@5 100.00 ( 99.72)\n",
            "==> Train Accuracy: Acc@1 92.684 || Acc@5 99.722\n",
            "==> Test Accuracy:  Acc@1 70.430 || Acc@5 91.320\n",
            "==> 39.11 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 75, lr: 0.020000000000000004 -----\n",
            "Epoch: [75][  0/391]\tTime  0.270 ( 0.270)\tLoss 2.0127e-01 (2.0127e-01)\tAcc@1  93.75 ( 93.75)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [75][ 30/391]\tTime  0.103 ( 0.100)\tLoss 1.3303e-01 (2.1573e-01)\tAcc@1  96.09 ( 93.22)\tAcc@5 100.00 ( 99.80)\n",
            "Epoch: [75][ 60/391]\tTime  0.105 ( 0.097)\tLoss 2.6426e-01 (2.2008e-01)\tAcc@1  90.62 ( 93.15)\tAcc@5 100.00 ( 99.78)\n",
            "Epoch: [75][ 90/391]\tTime  0.096 ( 0.096)\tLoss 1.3938e-01 (2.1560e-01)\tAcc@1  97.66 ( 93.29)\tAcc@5 100.00 ( 99.81)\n",
            "Epoch: [75][120/391]\tTime  0.093 ( 0.096)\tLoss 1.1148e-01 (2.1325e-01)\tAcc@1  97.66 ( 93.41)\tAcc@5 100.00 ( 99.78)\n",
            "Epoch: [75][150/391]\tTime  0.091 ( 0.095)\tLoss 3.8881e-01 (2.1608e-01)\tAcc@1  86.72 ( 93.32)\tAcc@5 100.00 ( 99.79)\n",
            "Epoch: [75][180/391]\tTime  0.096 ( 0.095)\tLoss 2.3703e-01 (2.2310e-01)\tAcc@1  92.19 ( 93.07)\tAcc@5  98.44 ( 99.77)\n",
            "Epoch: [75][210/391]\tTime  0.091 ( 0.095)\tLoss 1.9334e-01 (2.2380e-01)\tAcc@1  94.53 ( 93.05)\tAcc@5 100.00 ( 99.78)\n",
            "Epoch: [75][240/391]\tTime  0.091 ( 0.095)\tLoss 2.5286e-01 (2.3116e-01)\tAcc@1  92.97 ( 92.79)\tAcc@5 100.00 ( 99.77)\n",
            "Epoch: [75][270/391]\tTime  0.090 ( 0.094)\tLoss 2.1458e-01 (2.3533e-01)\tAcc@1  94.53 ( 92.69)\tAcc@5  99.22 ( 99.76)\n",
            "Epoch: [75][300/391]\tTime  0.088 ( 0.094)\tLoss 1.6757e-01 (2.3780e-01)\tAcc@1  96.09 ( 92.63)\tAcc@5 100.00 ( 99.76)\n",
            "Epoch: [75][330/391]\tTime  0.100 ( 0.094)\tLoss 3.1357e-01 (2.4157e-01)\tAcc@1  89.06 ( 92.49)\tAcc@5  99.22 ( 99.73)\n",
            "Epoch: [75][360/391]\tTime  0.094 ( 0.094)\tLoss 3.1916e-01 (2.4556e-01)\tAcc@1  88.28 ( 92.35)\tAcc@5  99.22 ( 99.73)\n",
            "Epoch: [75][390/391]\tTime  0.082 ( 0.094)\tLoss 3.4628e-01 (2.4965e-01)\tAcc@1  88.75 ( 92.21)\tAcc@5 100.00 ( 99.69)\n",
            "==> Train Accuracy: Acc@1 92.212 || Acc@5 99.694\n",
            "==> Test Accuracy:  Acc@1 69.820 || Acc@5 90.760\n",
            "==> 39.27 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 76, lr: 0.020000000000000004 -----\n",
            "Epoch: [76][  0/391]\tTime  0.266 ( 0.266)\tLoss 2.4728e-01 (2.4728e-01)\tAcc@1  92.97 ( 92.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [76][ 30/391]\tTime  0.092 ( 0.100)\tLoss 1.7127e-01 (1.9911e-01)\tAcc@1  95.31 ( 94.23)\tAcc@5 100.00 ( 99.82)\n",
            "Epoch: [76][ 60/391]\tTime  0.089 ( 0.097)\tLoss 2.9394e-01 (2.1463e-01)\tAcc@1  92.97 ( 93.72)\tAcc@5 100.00 ( 99.80)\n",
            "Epoch: [76][ 90/391]\tTime  0.091 ( 0.096)\tLoss 1.8480e-01 (2.1404e-01)\tAcc@1  92.97 ( 93.60)\tAcc@5 100.00 ( 99.79)\n",
            "Epoch: [76][120/391]\tTime  0.112 ( 0.095)\tLoss 3.2719e-01 (2.2037e-01)\tAcc@1  90.62 ( 93.37)\tAcc@5 100.00 ( 99.77)\n",
            "Epoch: [76][150/391]\tTime  0.090 ( 0.095)\tLoss 1.4806e-01 (2.2427e-01)\tAcc@1  96.88 ( 93.16)\tAcc@5 100.00 ( 99.75)\n",
            "Epoch: [76][180/391]\tTime  0.094 ( 0.095)\tLoss 2.2423e-01 (2.2771e-01)\tAcc@1  92.19 ( 93.06)\tAcc@5 100.00 ( 99.74)\n",
            "Epoch: [76][210/391]\tTime  0.091 ( 0.094)\tLoss 1.9359e-01 (2.3013e-01)\tAcc@1  93.75 ( 92.96)\tAcc@5 100.00 ( 99.72)\n",
            "Epoch: [76][240/391]\tTime  0.097 ( 0.094)\tLoss 2.6740e-01 (2.3741e-01)\tAcc@1  89.06 ( 92.66)\tAcc@5 100.00 ( 99.71)\n",
            "Epoch: [76][270/391]\tTime  0.089 ( 0.094)\tLoss 2.2585e-01 (2.4178e-01)\tAcc@1  93.75 ( 92.46)\tAcc@5  99.22 ( 99.71)\n",
            "Epoch: [76][300/391]\tTime  0.094 ( 0.094)\tLoss 3.5115e-01 (2.4581e-01)\tAcc@1  85.94 ( 92.33)\tAcc@5 100.00 ( 99.71)\n",
            "Epoch: [76][330/391]\tTime  0.094 ( 0.094)\tLoss 3.8743e-01 (2.4937e-01)\tAcc@1  82.81 ( 92.20)\tAcc@5  99.22 ( 99.71)\n",
            "Epoch: [76][360/391]\tTime  0.091 ( 0.094)\tLoss 2.8681e-01 (2.5306e-01)\tAcc@1  91.41 ( 92.12)\tAcc@5 100.00 ( 99.71)\n",
            "Epoch: [76][390/391]\tTime  0.082 ( 0.094)\tLoss 4.4999e-01 (2.5531e-01)\tAcc@1  82.50 ( 92.01)\tAcc@5  98.75 ( 99.72)\n",
            "==> Train Accuracy: Acc@1 92.010 || Acc@5 99.720\n",
            "==> Test Accuracy:  Acc@1 70.420 || Acc@5 91.290\n",
            "==> 39.42 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 77, lr: 0.020000000000000004 -----\n",
            "Epoch: [77][  0/391]\tTime  0.288 ( 0.288)\tLoss 2.0993e-01 (2.0993e-01)\tAcc@1  92.19 ( 92.19)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [77][ 30/391]\tTime  0.089 ( 0.102)\tLoss 2.2078e-01 (2.3430e-01)\tAcc@1  92.97 ( 92.44)\tAcc@5 100.00 ( 99.92)\n",
            "Epoch: [77][ 60/391]\tTime  0.099 ( 0.098)\tLoss 2.4862e-01 (2.1936e-01)\tAcc@1  92.19 ( 93.08)\tAcc@5 100.00 ( 99.85)\n",
            "Epoch: [77][ 90/391]\tTime  0.096 ( 0.097)\tLoss 2.6715e-01 (2.1931e-01)\tAcc@1  92.19 ( 93.15)\tAcc@5 100.00 ( 99.83)\n",
            "Epoch: [77][120/391]\tTime  0.093 ( 0.096)\tLoss 2.7742e-01 (2.1892e-01)\tAcc@1  92.19 ( 93.30)\tAcc@5 100.00 ( 99.84)\n",
            "Epoch: [77][150/391]\tTime  0.113 ( 0.096)\tLoss 2.9083e-01 (2.2106e-01)\tAcc@1  92.19 ( 93.21)\tAcc@5 100.00 ( 99.82)\n",
            "Epoch: [77][180/391]\tTime  0.090 ( 0.095)\tLoss 2.4727e-01 (2.2662e-01)\tAcc@1  90.62 ( 93.07)\tAcc@5  99.22 ( 99.78)\n",
            "Epoch: [77][210/391]\tTime  0.090 ( 0.095)\tLoss 2.2127e-01 (2.3021e-01)\tAcc@1  93.75 ( 92.86)\tAcc@5  99.22 ( 99.77)\n",
            "Epoch: [77][240/391]\tTime  0.112 ( 0.095)\tLoss 2.6634e-01 (2.3285e-01)\tAcc@1  89.84 ( 92.78)\tAcc@5 100.00 ( 99.76)\n",
            "Epoch: [77][270/391]\tTime  0.092 ( 0.095)\tLoss 2.3118e-01 (2.3520e-01)\tAcc@1  92.19 ( 92.70)\tAcc@5 100.00 ( 99.74)\n",
            "Epoch: [77][300/391]\tTime  0.091 ( 0.094)\tLoss 1.6623e-01 (2.3852e-01)\tAcc@1  95.31 ( 92.59)\tAcc@5 100.00 ( 99.74)\n",
            "Epoch: [77][330/391]\tTime  0.090 ( 0.094)\tLoss 2.0141e-01 (2.4266e-01)\tAcc@1  93.75 ( 92.42)\tAcc@5 100.00 ( 99.73)\n",
            "Epoch: [77][360/391]\tTime  0.099 ( 0.094)\tLoss 3.4765e-01 (2.4805e-01)\tAcc@1  91.41 ( 92.25)\tAcc@5 100.00 ( 99.71)\n",
            "Epoch: [77][390/391]\tTime  0.081 ( 0.094)\tLoss 3.4832e-01 (2.5282e-01)\tAcc@1  88.75 ( 92.12)\tAcc@5  97.50 ( 99.69)\n",
            "==> Train Accuracy: Acc@1 92.116 || Acc@5 99.690\n",
            "==> Test Accuracy:  Acc@1 69.070 || Acc@5 90.460\n",
            "==> 39.32 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 78, lr: 0.020000000000000004 -----\n",
            "Epoch: [78][  0/391]\tTime  0.291 ( 0.291)\tLoss 1.4794e-01 (1.4794e-01)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [78][ 30/391]\tTime  0.085 ( 0.100)\tLoss 2.5106e-01 (2.2735e-01)\tAcc@1  93.75 ( 93.52)\tAcc@5 100.00 ( 99.52)\n",
            "Epoch: [78][ 60/391]\tTime  0.091 ( 0.097)\tLoss 2.3892e-01 (2.2490e-01)\tAcc@1  92.97 ( 93.47)\tAcc@5  99.22 ( 99.59)\n",
            "Epoch: [78][ 90/391]\tTime  0.091 ( 0.096)\tLoss 2.3141e-01 (2.2194e-01)\tAcc@1  94.53 ( 93.40)\tAcc@5 100.00 ( 99.67)\n",
            "Epoch: [78][120/391]\tTime  0.095 ( 0.096)\tLoss 2.8667e-01 (2.2301e-01)\tAcc@1  91.41 ( 93.31)\tAcc@5 100.00 ( 99.70)\n",
            "Epoch: [78][150/391]\tTime  0.093 ( 0.095)\tLoss 2.7541e-01 (2.2613e-01)\tAcc@1  92.97 ( 93.19)\tAcc@5 100.00 ( 99.68)\n",
            "Epoch: [78][180/391]\tTime  0.091 ( 0.095)\tLoss 2.4910e-01 (2.3015e-01)\tAcc@1  90.62 ( 93.06)\tAcc@5  99.22 ( 99.68)\n",
            "Epoch: [78][210/391]\tTime  0.100 ( 0.095)\tLoss 2.2042e-01 (2.2825e-01)\tAcc@1  93.75 ( 93.17)\tAcc@5 100.00 ( 99.69)\n",
            "Epoch: [78][240/391]\tTime  0.091 ( 0.095)\tLoss 2.9942e-01 (2.2973e-01)\tAcc@1  91.41 ( 93.10)\tAcc@5 100.00 ( 99.71)\n",
            "Epoch: [78][270/391]\tTime  0.089 ( 0.095)\tLoss 5.3574e-01 (2.3324e-01)\tAcc@1  82.03 ( 92.99)\tAcc@5 100.00 ( 99.73)\n",
            "Epoch: [78][300/391]\tTime  0.093 ( 0.095)\tLoss 2.3148e-01 (2.3496e-01)\tAcc@1  92.19 ( 92.96)\tAcc@5 100.00 ( 99.74)\n",
            "Epoch: [78][330/391]\tTime  0.092 ( 0.095)\tLoss 2.8514e-01 (2.3847e-01)\tAcc@1  89.84 ( 92.79)\tAcc@5  99.22 ( 99.72)\n",
            "Epoch: [78][360/391]\tTime  0.095 ( 0.095)\tLoss 3.1642e-01 (2.3953e-01)\tAcc@1  90.62 ( 92.72)\tAcc@5  99.22 ( 99.71)\n",
            "Epoch: [78][390/391]\tTime  0.082 ( 0.095)\tLoss 3.5456e-01 (2.4262e-01)\tAcc@1  90.00 ( 92.59)\tAcc@5  98.75 ( 99.70)\n",
            "==> Train Accuracy: Acc@1 92.586 || Acc@5 99.704\n",
            "==> Test Accuracy:  Acc@1 69.480 || Acc@5 91.000\n",
            "==> 39.48 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 79, lr: 0.020000000000000004 -----\n",
            "Epoch: [79][  0/391]\tTime  0.293 ( 0.293)\tLoss 2.0678e-01 (2.0678e-01)\tAcc@1  93.75 ( 93.75)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [79][ 30/391]\tTime  0.089 ( 0.101)\tLoss 1.9458e-01 (2.2474e-01)\tAcc@1  95.31 ( 93.22)\tAcc@5 100.00 ( 99.70)\n",
            "Epoch: [79][ 60/391]\tTime  0.092 ( 0.097)\tLoss 1.6790e-01 (2.1545e-01)\tAcc@1  96.88 ( 93.42)\tAcc@5 100.00 ( 99.78)\n",
            "Epoch: [79][ 90/391]\tTime  0.096 ( 0.096)\tLoss 1.5600e-01 (2.2157e-01)\tAcc@1  96.88 ( 93.38)\tAcc@5 100.00 ( 99.72)\n",
            "Epoch: [79][120/391]\tTime  0.095 ( 0.095)\tLoss 2.5634e-01 (2.2786e-01)\tAcc@1  91.41 ( 93.14)\tAcc@5 100.00 ( 99.74)\n",
            "Epoch: [79][150/391]\tTime  0.090 ( 0.095)\tLoss 1.8383e-01 (2.3192e-01)\tAcc@1  94.53 ( 92.89)\tAcc@5 100.00 ( 99.76)\n",
            "Epoch: [79][180/391]\tTime  0.087 ( 0.094)\tLoss 2.0240e-01 (2.3493e-01)\tAcc@1  92.19 ( 92.72)\tAcc@5 100.00 ( 99.75)\n",
            "Epoch: [79][210/391]\tTime  0.095 ( 0.094)\tLoss 1.4073e-01 (2.3505e-01)\tAcc@1  96.88 ( 92.75)\tAcc@5 100.00 ( 99.73)\n",
            "Epoch: [79][240/391]\tTime  0.091 ( 0.094)\tLoss 1.5064e-01 (2.3429e-01)\tAcc@1  96.09 ( 92.80)\tAcc@5 100.00 ( 99.75)\n",
            "Epoch: [79][270/391]\tTime  0.088 ( 0.094)\tLoss 3.1195e-01 (2.3834e-01)\tAcc@1  92.19 ( 92.71)\tAcc@5 100.00 ( 99.74)\n",
            "Epoch: [79][300/391]\tTime  0.095 ( 0.094)\tLoss 2.6590e-01 (2.4329e-01)\tAcc@1  91.41 ( 92.54)\tAcc@5 100.00 ( 99.73)\n",
            "Epoch: [79][330/391]\tTime  0.090 ( 0.094)\tLoss 3.0815e-01 (2.4650e-01)\tAcc@1  92.19 ( 92.44)\tAcc@5  99.22 ( 99.73)\n",
            "Epoch: [79][360/391]\tTime  0.108 ( 0.094)\tLoss 3.0357e-01 (2.4979e-01)\tAcc@1  90.62 ( 92.35)\tAcc@5  99.22 ( 99.73)\n",
            "Epoch: [79][390/391]\tTime  0.081 ( 0.094)\tLoss 3.3942e-01 (2.5319e-01)\tAcc@1  88.75 ( 92.23)\tAcc@5 100.00 ( 99.72)\n",
            "==> Train Accuracy: Acc@1 92.232 || Acc@5 99.718\n",
            "==> Test Accuracy:  Acc@1 69.260 || Acc@5 90.810\n",
            "==> 39.16 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 80, lr: 0.020000000000000004 -----\n",
            "Epoch: [80][  0/391]\tTime  0.288 ( 0.288)\tLoss 2.3041e-01 (2.3041e-01)\tAcc@1  93.75 ( 93.75)\tAcc@5  99.22 ( 99.22)\n",
            "Epoch: [80][ 30/391]\tTime  0.086 ( 0.101)\tLoss 2.0025e-01 (2.2766e-01)\tAcc@1  94.53 ( 93.27)\tAcc@5 100.00 ( 99.72)\n",
            "Epoch: [80][ 60/391]\tTime  0.096 ( 0.098)\tLoss 2.8832e-01 (2.3525e-01)\tAcc@1  92.19 ( 93.02)\tAcc@5  99.22 ( 99.71)\n",
            "Epoch: [80][ 90/391]\tTime  0.097 ( 0.097)\tLoss 2.6940e-01 (2.3331e-01)\tAcc@1  92.19 ( 93.05)\tAcc@5  99.22 ( 99.70)\n",
            "Epoch: [80][120/391]\tTime  0.092 ( 0.096)\tLoss 2.7390e-01 (2.3027e-01)\tAcc@1  91.41 ( 93.20)\tAcc@5  99.22 ( 99.71)\n",
            "Epoch: [80][150/391]\tTime  0.095 ( 0.095)\tLoss 2.9492e-01 (2.2903e-01)\tAcc@1  90.62 ( 93.18)\tAcc@5  99.22 ( 99.72)\n",
            "Epoch: [80][180/391]\tTime  0.094 ( 0.095)\tLoss 2.9621e-01 (2.2932e-01)\tAcc@1  91.41 ( 93.15)\tAcc@5  99.22 ( 99.70)\n",
            "Epoch: [80][210/391]\tTime  0.088 ( 0.095)\tLoss 2.4876e-01 (2.3165e-01)\tAcc@1  92.19 ( 93.05)\tAcc@5 100.00 ( 99.70)\n",
            "Epoch: [80][240/391]\tTime  0.103 ( 0.095)\tLoss 2.8951e-01 (2.3509e-01)\tAcc@1  90.62 ( 92.87)\tAcc@5 100.00 ( 99.71)\n",
            "Epoch: [80][270/391]\tTime  0.095 ( 0.094)\tLoss 1.9919e-01 (2.3832e-01)\tAcc@1  93.75 ( 92.74)\tAcc@5 100.00 ( 99.71)\n",
            "Epoch: [80][300/391]\tTime  0.096 ( 0.094)\tLoss 2.7734e-01 (2.3935e-01)\tAcc@1  88.28 ( 92.72)\tAcc@5  99.22 ( 99.70)\n",
            "Epoch: [80][330/391]\tTime  0.094 ( 0.094)\tLoss 2.3189e-01 (2.4090e-01)\tAcc@1  91.41 ( 92.65)\tAcc@5 100.00 ( 99.70)\n",
            "Epoch: [80][360/391]\tTime  0.094 ( 0.094)\tLoss 3.1064e-01 (2.4559e-01)\tAcc@1  90.62 ( 92.51)\tAcc@5 100.00 ( 99.70)\n",
            "Epoch: [80][390/391]\tTime  0.079 ( 0.094)\tLoss 3.7208e-01 (2.4834e-01)\tAcc@1  87.50 ( 92.40)\tAcc@5 100.00 ( 99.69)\n",
            "==> Train Accuracy: Acc@1 92.402 || Acc@5 99.692\n",
            "==> Test Accuracy:  Acc@1 70.600 || Acc@5 91.930\n",
            "==> 39.26 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 81, lr: 0.020000000000000004 -----\n",
            "Epoch: [81][  0/391]\tTime  0.281 ( 0.281)\tLoss 2.5284e-01 (2.5284e-01)\tAcc@1  92.19 ( 92.19)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [81][ 30/391]\tTime  0.093 ( 0.101)\tLoss 1.9799e-01 (2.4128e-01)\tAcc@1  92.97 ( 92.41)\tAcc@5 100.00 ( 99.67)\n",
            "Epoch: [81][ 60/391]\tTime  0.096 ( 0.097)\tLoss 2.3550e-01 (2.3552e-01)\tAcc@1  93.75 ( 92.88)\tAcc@5  99.22 ( 99.67)\n",
            "Epoch: [81][ 90/391]\tTime  0.096 ( 0.096)\tLoss 1.8687e-01 (2.3106e-01)\tAcc@1  92.97 ( 92.89)\tAcc@5 100.00 ( 99.67)\n",
            "Epoch: [81][120/391]\tTime  0.086 ( 0.095)\tLoss 1.4003e-01 (2.2852e-01)\tAcc@1  95.31 ( 92.88)\tAcc@5 100.00 ( 99.72)\n",
            "Epoch: [81][150/391]\tTime  0.092 ( 0.095)\tLoss 2.9876e-01 (2.3026e-01)\tAcc@1  89.06 ( 92.91)\tAcc@5  99.22 ( 99.73)\n",
            "Epoch: [81][180/391]\tTime  0.089 ( 0.095)\tLoss 1.9980e-01 (2.3461e-01)\tAcc@1  96.88 ( 92.77)\tAcc@5  99.22 ( 99.72)\n",
            "Epoch: [81][210/391]\tTime  0.092 ( 0.095)\tLoss 2.2491e-01 (2.3484e-01)\tAcc@1  92.19 ( 92.72)\tAcc@5 100.00 ( 99.73)\n",
            "Epoch: [81][240/391]\tTime  0.092 ( 0.095)\tLoss 2.0592e-01 (2.3634e-01)\tAcc@1  94.53 ( 92.71)\tAcc@5 100.00 ( 99.73)\n",
            "Epoch: [81][270/391]\tTime  0.097 ( 0.095)\tLoss 1.5876e-01 (2.3839e-01)\tAcc@1  95.31 ( 92.63)\tAcc@5 100.00 ( 99.74)\n",
            "Epoch: [81][300/391]\tTime  0.095 ( 0.095)\tLoss 2.6276e-01 (2.3934e-01)\tAcc@1  92.97 ( 92.63)\tAcc@5 100.00 ( 99.75)\n",
            "Epoch: [81][330/391]\tTime  0.091 ( 0.094)\tLoss 3.2980e-01 (2.4080e-01)\tAcc@1  92.19 ( 92.60)\tAcc@5  99.22 ( 99.73)\n",
            "Epoch: [81][360/391]\tTime  0.092 ( 0.094)\tLoss 1.9105e-01 (2.4273e-01)\tAcc@1  96.09 ( 92.51)\tAcc@5 100.00 ( 99.73)\n",
            "Epoch: [81][390/391]\tTime  0.081 ( 0.094)\tLoss 2.9640e-01 (2.4514e-01)\tAcc@1  92.50 ( 92.45)\tAcc@5 100.00 ( 99.72)\n",
            "==> Train Accuracy: Acc@1 92.454 || Acc@5 99.720\n",
            "==> Test Accuracy:  Acc@1 70.350 || Acc@5 90.800\n",
            "==> 39.39 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 82, lr: 0.020000000000000004 -----\n",
            "Epoch: [82][  0/391]\tTime  0.262 ( 0.262)\tLoss 2.1842e-01 (2.1842e-01)\tAcc@1  94.53 ( 94.53)\tAcc@5  99.22 ( 99.22)\n",
            "Epoch: [82][ 30/391]\tTime  0.092 ( 0.100)\tLoss 2.3495e-01 (2.2539e-01)\tAcc@1  94.53 ( 93.42)\tAcc@5  98.44 ( 99.62)\n",
            "Epoch: [82][ 60/391]\tTime  0.102 ( 0.096)\tLoss 2.2611e-01 (2.1815e-01)\tAcc@1  92.97 ( 93.30)\tAcc@5 100.00 ( 99.73)\n",
            "Epoch: [82][ 90/391]\tTime  0.105 ( 0.095)\tLoss 2.7091e-01 (2.2015e-01)\tAcc@1  91.41 ( 93.23)\tAcc@5 100.00 ( 99.75)\n",
            "Epoch: [82][120/391]\tTime  0.094 ( 0.095)\tLoss 2.2212e-01 (2.2566e-01)\tAcc@1  93.75 ( 93.09)\tAcc@5 100.00 ( 99.74)\n",
            "Epoch: [82][150/391]\tTime  0.085 ( 0.095)\tLoss 1.6854e-01 (2.2410e-01)\tAcc@1  96.09 ( 93.10)\tAcc@5 100.00 ( 99.75)\n",
            "Epoch: [82][180/391]\tTime  0.088 ( 0.094)\tLoss 2.2424e-01 (2.2797e-01)\tAcc@1  93.75 ( 92.97)\tAcc@5 100.00 ( 99.75)\n",
            "Epoch: [82][210/391]\tTime  0.092 ( 0.094)\tLoss 2.0385e-01 (2.3026e-01)\tAcc@1  95.31 ( 92.85)\tAcc@5  99.22 ( 99.75)\n",
            "Epoch: [82][240/391]\tTime  0.091 ( 0.094)\tLoss 4.1583e-01 (2.3490e-01)\tAcc@1  86.72 ( 92.68)\tAcc@5 100.00 ( 99.74)\n",
            "Epoch: [82][270/391]\tTime  0.097 ( 0.094)\tLoss 3.3065e-01 (2.3960e-01)\tAcc@1  90.62 ( 92.54)\tAcc@5  99.22 ( 99.73)\n",
            "Epoch: [82][300/391]\tTime  0.082 ( 0.094)\tLoss 2.7787e-01 (2.4292e-01)\tAcc@1  90.62 ( 92.45)\tAcc@5  99.22 ( 99.73)\n",
            "Epoch: [82][330/391]\tTime  0.095 ( 0.094)\tLoss 2.7887e-01 (2.4552e-01)\tAcc@1  92.97 ( 92.40)\tAcc@5 100.00 ( 99.70)\n",
            "Epoch: [82][360/391]\tTime  0.092 ( 0.094)\tLoss 2.8329e-01 (2.4875e-01)\tAcc@1  89.06 ( 92.27)\tAcc@5 100.00 ( 99.69)\n",
            "Epoch: [82][390/391]\tTime  0.082 ( 0.094)\tLoss 2.1389e-01 (2.5275e-01)\tAcc@1  93.75 ( 92.14)\tAcc@5 100.00 ( 99.68)\n",
            "==> Train Accuracy: Acc@1 92.142 || Acc@5 99.678\n",
            "==> Test Accuracy:  Acc@1 68.950 || Acc@5 90.680\n",
            "==> 39.13 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 83, lr: 0.020000000000000004 -----\n",
            "Epoch: [83][  0/391]\tTime  0.288 ( 0.288)\tLoss 1.9904e-01 (1.9904e-01)\tAcc@1  93.75 ( 93.75)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [83][ 30/391]\tTime  0.096 ( 0.101)\tLoss 1.8151e-01 (2.2392e-01)\tAcc@1  95.31 ( 92.94)\tAcc@5 100.00 ( 99.80)\n",
            "Epoch: [83][ 60/391]\tTime  0.094 ( 0.098)\tLoss 1.7605e-01 (2.2249e-01)\tAcc@1  94.53 ( 93.16)\tAcc@5 100.00 ( 99.83)\n",
            "Epoch: [83][ 90/391]\tTime  0.089 ( 0.096)\tLoss 1.6100e-01 (2.2329e-01)\tAcc@1  95.31 ( 93.08)\tAcc@5 100.00 ( 99.79)\n",
            "Epoch: [83][120/391]\tTime  0.091 ( 0.096)\tLoss 1.9953e-01 (2.1574e-01)\tAcc@1  92.19 ( 93.34)\tAcc@5 100.00 ( 99.80)\n",
            "Epoch: [83][150/391]\tTime  0.091 ( 0.096)\tLoss 2.0994e-01 (2.1693e-01)\tAcc@1  91.41 ( 93.23)\tAcc@5 100.00 ( 99.79)\n",
            "Epoch: [83][180/391]\tTime  0.097 ( 0.095)\tLoss 2.7876e-01 (2.1715e-01)\tAcc@1  89.84 ( 93.31)\tAcc@5 100.00 ( 99.76)\n",
            "Epoch: [83][210/391]\tTime  0.106 ( 0.095)\tLoss 3.5130e-01 (2.1817e-01)\tAcc@1  89.06 ( 93.26)\tAcc@5 100.00 ( 99.77)\n",
            "Epoch: [83][240/391]\tTime  0.102 ( 0.095)\tLoss 2.1486e-01 (2.1785e-01)\tAcc@1  94.53 ( 93.29)\tAcc@5 100.00 ( 99.78)\n",
            "Epoch: [83][270/391]\tTime  0.114 ( 0.095)\tLoss 3.4371e-01 (2.2247e-01)\tAcc@1  89.06 ( 93.15)\tAcc@5  99.22 ( 99.78)\n",
            "Epoch: [83][300/391]\tTime  0.099 ( 0.095)\tLoss 3.9264e-01 (2.2617e-01)\tAcc@1  86.72 ( 92.99)\tAcc@5  99.22 ( 99.77)\n",
            "Epoch: [83][330/391]\tTime  0.089 ( 0.094)\tLoss 2.5531e-01 (2.3292e-01)\tAcc@1  92.19 ( 92.80)\tAcc@5 100.00 ( 99.74)\n",
            "Epoch: [83][360/391]\tTime  0.089 ( 0.094)\tLoss 3.9929e-01 (2.3824e-01)\tAcc@1  88.28 ( 92.61)\tAcc@5  99.22 ( 99.71)\n",
            "Epoch: [83][390/391]\tTime  0.082 ( 0.094)\tLoss 1.9877e-01 (2.4199e-01)\tAcc@1  95.00 ( 92.45)\tAcc@5  98.75 ( 99.69)\n",
            "==> Train Accuracy: Acc@1 92.450 || Acc@5 99.688\n",
            "==> Test Accuracy:  Acc@1 69.520 || Acc@5 91.160\n",
            "==> 39.33 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 84, lr: 0.020000000000000004 -----\n",
            "Epoch: [84][  0/391]\tTime  0.288 ( 0.288)\tLoss 2.9037e-01 (2.9037e-01)\tAcc@1  92.97 ( 92.97)\tAcc@5  98.44 ( 98.44)\n",
            "Epoch: [84][ 30/391]\tTime  0.099 ( 0.100)\tLoss 2.3144e-01 (2.1073e-01)\tAcc@1  95.31 ( 93.83)\tAcc@5 100.00 ( 99.75)\n",
            "Epoch: [84][ 60/391]\tTime  0.084 ( 0.097)\tLoss 2.9742e-01 (2.2253e-01)\tAcc@1  91.41 ( 93.30)\tAcc@5 100.00 ( 99.74)\n",
            "Epoch: [84][ 90/391]\tTime  0.092 ( 0.096)\tLoss 2.5219e-01 (2.2236e-01)\tAcc@1  91.41 ( 93.28)\tAcc@5 100.00 ( 99.77)\n",
            "Epoch: [84][120/391]\tTime  0.091 ( 0.096)\tLoss 1.9251e-01 (2.1934e-01)\tAcc@1  95.31 ( 93.44)\tAcc@5  99.22 ( 99.75)\n",
            "Epoch: [84][150/391]\tTime  0.091 ( 0.095)\tLoss 1.5548e-01 (2.1877e-01)\tAcc@1  96.09 ( 93.36)\tAcc@5 100.00 ( 99.77)\n",
            "Epoch: [84][180/391]\tTime  0.090 ( 0.095)\tLoss 3.4599e-01 (2.2289e-01)\tAcc@1  89.84 ( 93.20)\tAcc@5  99.22 ( 99.76)\n",
            "Epoch: [84][210/391]\tTime  0.090 ( 0.095)\tLoss 2.7238e-01 (2.2571e-01)\tAcc@1  91.41 ( 93.13)\tAcc@5 100.00 ( 99.76)\n",
            "Epoch: [84][240/391]\tTime  0.092 ( 0.095)\tLoss 1.7130e-01 (2.2719e-01)\tAcc@1  92.97 ( 93.04)\tAcc@5 100.00 ( 99.76)\n",
            "Epoch: [84][270/391]\tTime  0.103 ( 0.095)\tLoss 2.2007e-01 (2.2793e-01)\tAcc@1  95.31 ( 92.96)\tAcc@5  99.22 ( 99.76)\n",
            "Epoch: [84][300/391]\tTime  0.093 ( 0.095)\tLoss 3.6013e-01 (2.2947e-01)\tAcc@1  90.62 ( 92.91)\tAcc@5  99.22 ( 99.75)\n",
            "Epoch: [84][330/391]\tTime  0.088 ( 0.095)\tLoss 2.8676e-01 (2.3164e-01)\tAcc@1  92.19 ( 92.85)\tAcc@5  98.44 ( 99.74)\n",
            "Epoch: [84][360/391]\tTime  0.099 ( 0.094)\tLoss 2.6187e-01 (2.3459e-01)\tAcc@1  92.97 ( 92.74)\tAcc@5 100.00 ( 99.74)\n",
            "Epoch: [84][390/391]\tTime  0.082 ( 0.094)\tLoss 3.4151e-01 (2.3875e-01)\tAcc@1  85.00 ( 92.60)\tAcc@5 100.00 ( 99.74)\n",
            "==> Train Accuracy: Acc@1 92.596 || Acc@5 99.736\n",
            "==> Test Accuracy:  Acc@1 69.680 || Acc@5 91.070\n",
            "==> 39.48 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 85, lr: 0.020000000000000004 -----\n",
            "Epoch: [85][  0/391]\tTime  0.286 ( 0.286)\tLoss 1.8134e-01 (1.8134e-01)\tAcc@1  96.88 ( 96.88)\tAcc@5  98.44 ( 98.44)\n",
            "Epoch: [85][ 30/391]\tTime  0.093 ( 0.101)\tLoss 1.6346e-01 (2.1973e-01)\tAcc@1  93.75 ( 93.37)\tAcc@5 100.00 ( 99.85)\n",
            "Epoch: [85][ 60/391]\tTime  0.086 ( 0.098)\tLoss 1.9591e-01 (2.1507e-01)\tAcc@1  95.31 ( 93.55)\tAcc@5 100.00 ( 99.88)\n",
            "Epoch: [85][ 90/391]\tTime  0.095 ( 0.096)\tLoss 2.1282e-01 (2.0968e-01)\tAcc@1  92.19 ( 93.78)\tAcc@5 100.00 ( 99.85)\n",
            "Epoch: [85][120/391]\tTime  0.100 ( 0.095)\tLoss 3.1278e-01 (2.1216e-01)\tAcc@1  90.62 ( 93.60)\tAcc@5 100.00 ( 99.84)\n",
            "Epoch: [85][150/391]\tTime  0.094 ( 0.095)\tLoss 2.0096e-01 (2.1588e-01)\tAcc@1  93.75 ( 93.46)\tAcc@5 100.00 ( 99.83)\n",
            "Epoch: [85][180/391]\tTime  0.093 ( 0.095)\tLoss 2.3894e-01 (2.1399e-01)\tAcc@1  89.84 ( 93.50)\tAcc@5 100.00 ( 99.84)\n",
            "Epoch: [85][210/391]\tTime  0.094 ( 0.095)\tLoss 2.2414e-01 (2.1812e-01)\tAcc@1  95.31 ( 93.31)\tAcc@5 100.00 ( 99.82)\n",
            "Epoch: [85][240/391]\tTime  0.092 ( 0.094)\tLoss 2.7248e-01 (2.2210e-01)\tAcc@1  90.62 ( 93.19)\tAcc@5  98.44 ( 99.79)\n",
            "Epoch: [85][270/391]\tTime  0.093 ( 0.094)\tLoss 2.1901e-01 (2.2493e-01)\tAcc@1  93.75 ( 93.12)\tAcc@5  99.22 ( 99.75)\n",
            "Epoch: [85][300/391]\tTime  0.096 ( 0.094)\tLoss 3.9737e-01 (2.2842e-01)\tAcc@1  91.41 ( 93.00)\tAcc@5  99.22 ( 99.74)\n",
            "Epoch: [85][330/391]\tTime  0.107 ( 0.094)\tLoss 3.7083e-01 (2.3258e-01)\tAcc@1  86.72 ( 92.85)\tAcc@5 100.00 ( 99.73)\n",
            "Epoch: [85][360/391]\tTime  0.094 ( 0.094)\tLoss 2.9450e-01 (2.3663e-01)\tAcc@1  89.84 ( 92.72)\tAcc@5 100.00 ( 99.72)\n",
            "Epoch: [85][390/391]\tTime  0.081 ( 0.094)\tLoss 2.1741e-01 (2.3861e-01)\tAcc@1  95.00 ( 92.64)\tAcc@5 100.00 ( 99.72)\n",
            "==> Train Accuracy: Acc@1 92.640 || Acc@5 99.718\n",
            "==> Test Accuracy:  Acc@1 68.920 || Acc@5 90.380\n",
            "==> 39.42 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 86, lr: 0.020000000000000004 -----\n",
            "Epoch: [86][  0/391]\tTime  0.296 ( 0.296)\tLoss 1.5717e-01 (1.5717e-01)\tAcc@1  96.09 ( 96.09)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [86][ 30/391]\tTime  0.095 ( 0.102)\tLoss 2.9570e-01 (2.1145e-01)\tAcc@1  87.50 ( 93.62)\tAcc@5 100.00 ( 99.77)\n",
            "Epoch: [86][ 60/391]\tTime  0.091 ( 0.098)\tLoss 2.2075e-01 (2.0218e-01)\tAcc@1  95.31 ( 94.04)\tAcc@5  99.22 ( 99.86)\n",
            "Epoch: [86][ 90/391]\tTime  0.111 ( 0.097)\tLoss 2.0452e-01 (2.0562e-01)\tAcc@1  95.31 ( 93.85)\tAcc@5 100.00 ( 99.85)\n",
            "Epoch: [86][120/391]\tTime  0.097 ( 0.096)\tLoss 2.4012e-01 (2.1068e-01)\tAcc@1  90.62 ( 93.77)\tAcc@5 100.00 ( 99.83)\n",
            "Epoch: [86][150/391]\tTime  0.101 ( 0.096)\tLoss 2.8782e-01 (2.1214e-01)\tAcc@1  92.19 ( 93.66)\tAcc@5  99.22 ( 99.81)\n",
            "Epoch: [86][180/391]\tTime  0.090 ( 0.096)\tLoss 1.0427e-01 (2.1221e-01)\tAcc@1  97.66 ( 93.66)\tAcc@5 100.00 ( 99.81)\n",
            "Epoch: [86][210/391]\tTime  0.085 ( 0.095)\tLoss 1.3570e-01 (2.1439e-01)\tAcc@1  97.66 ( 93.48)\tAcc@5 100.00 ( 99.81)\n",
            "Epoch: [86][240/391]\tTime  0.101 ( 0.095)\tLoss 2.5408e-01 (2.1787e-01)\tAcc@1  91.41 ( 93.29)\tAcc@5  99.22 ( 99.81)\n",
            "Epoch: [86][270/391]\tTime  0.086 ( 0.095)\tLoss 2.6211e-01 (2.2107e-01)\tAcc@1  91.41 ( 93.17)\tAcc@5 100.00 ( 99.79)\n",
            "Epoch: [86][300/391]\tTime  0.092 ( 0.095)\tLoss 2.0348e-01 (2.2559e-01)\tAcc@1  94.53 ( 93.01)\tAcc@5 100.00 ( 99.78)\n",
            "Epoch: [86][330/391]\tTime  0.092 ( 0.095)\tLoss 2.4266e-01 (2.3035e-01)\tAcc@1  92.19 ( 92.88)\tAcc@5 100.00 ( 99.76)\n",
            "Epoch: [86][360/391]\tTime  0.093 ( 0.095)\tLoss 2.3728e-01 (2.3312e-01)\tAcc@1  92.97 ( 92.80)\tAcc@5 100.00 ( 99.76)\n",
            "Epoch: [86][390/391]\tTime  0.082 ( 0.095)\tLoss 3.7149e-01 (2.3649e-01)\tAcc@1  88.75 ( 92.70)\tAcc@5 100.00 ( 99.75)\n",
            "==> Train Accuracy: Acc@1 92.700 || Acc@5 99.748\n",
            "==> Test Accuracy:  Acc@1 69.480 || Acc@5 90.630\n",
            "==> 39.53 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 87, lr: 0.020000000000000004 -----\n",
            "Epoch: [87][  0/391]\tTime  0.289 ( 0.289)\tLoss 1.8286e-01 (1.8286e-01)\tAcc@1  94.53 ( 94.53)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [87][ 30/391]\tTime  0.094 ( 0.101)\tLoss 3.0039e-01 (2.3156e-01)\tAcc@1  90.62 ( 92.77)\tAcc@5  99.22 ( 99.72)\n",
            "Epoch: [87][ 60/391]\tTime  0.082 ( 0.097)\tLoss 1.6379e-01 (2.2156e-01)\tAcc@1  95.31 ( 93.26)\tAcc@5 100.00 ( 99.73)\n",
            "Epoch: [87][ 90/391]\tTime  0.092 ( 0.096)\tLoss 1.4362e-01 (2.1682e-01)\tAcc@1  95.31 ( 93.44)\tAcc@5 100.00 ( 99.72)\n",
            "Epoch: [87][120/391]\tTime  0.091 ( 0.095)\tLoss 2.0010e-01 (2.1398e-01)\tAcc@1  93.75 ( 93.49)\tAcc@5 100.00 ( 99.75)\n",
            "Epoch: [87][150/391]\tTime  0.087 ( 0.095)\tLoss 2.0044e-01 (2.1687e-01)\tAcc@1  92.97 ( 93.44)\tAcc@5 100.00 ( 99.74)\n",
            "Epoch: [87][180/391]\tTime  0.091 ( 0.095)\tLoss 1.9444e-01 (2.2007e-01)\tAcc@1  95.31 ( 93.36)\tAcc@5 100.00 ( 99.75)\n",
            "Epoch: [87][210/391]\tTime  0.104 ( 0.095)\tLoss 1.2351e-01 (2.1837e-01)\tAcc@1  96.88 ( 93.48)\tAcc@5 100.00 ( 99.76)\n",
            "Epoch: [87][240/391]\tTime  0.091 ( 0.094)\tLoss 2.8762e-01 (2.2002e-01)\tAcc@1  90.62 ( 93.41)\tAcc@5 100.00 ( 99.77)\n",
            "Epoch: [87][270/391]\tTime  0.091 ( 0.094)\tLoss 3.5267e-01 (2.2420e-01)\tAcc@1  87.50 ( 93.25)\tAcc@5  97.66 ( 99.75)\n",
            "Epoch: [87][300/391]\tTime  0.094 ( 0.094)\tLoss 2.8880e-01 (2.2817e-01)\tAcc@1  92.19 ( 93.11)\tAcc@5 100.00 ( 99.75)\n",
            "Epoch: [87][330/391]\tTime  0.080 ( 0.094)\tLoss 1.8071e-01 (2.3456e-01)\tAcc@1  95.31 ( 92.87)\tAcc@5 100.00 ( 99.73)\n",
            "Epoch: [87][360/391]\tTime  0.094 ( 0.094)\tLoss 2.0657e-01 (2.3838e-01)\tAcc@1  92.19 ( 92.74)\tAcc@5 100.00 ( 99.72)\n",
            "Epoch: [87][390/391]\tTime  0.081 ( 0.094)\tLoss 5.2695e-01 (2.4428e-01)\tAcc@1  85.00 ( 92.51)\tAcc@5  97.50 ( 99.71)\n",
            "==> Train Accuracy: Acc@1 92.510 || Acc@5 99.710\n",
            "==> Test Accuracy:  Acc@1 68.840 || Acc@5 90.400\n",
            "==> 39.40 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 88, lr: 0.020000000000000004 -----\n",
            "Epoch: [88][  0/391]\tTime  0.302 ( 0.302)\tLoss 2.5322e-01 (2.5322e-01)\tAcc@1  90.62 ( 90.62)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [88][ 30/391]\tTime  0.088 ( 0.102)\tLoss 2.7322e-01 (2.1710e-01)\tAcc@1  91.41 ( 93.22)\tAcc@5  99.22 ( 99.85)\n",
            "Epoch: [88][ 60/391]\tTime  0.094 ( 0.099)\tLoss 2.4611e-01 (2.0537e-01)\tAcc@1  92.19 ( 93.87)\tAcc@5 100.00 ( 99.86)\n",
            "Epoch: [88][ 90/391]\tTime  0.093 ( 0.097)\tLoss 1.3082e-01 (2.0446e-01)\tAcc@1  98.44 ( 93.90)\tAcc@5 100.00 ( 99.85)\n",
            "Epoch: [88][120/391]\tTime  0.092 ( 0.096)\tLoss 2.3129e-01 (2.0341e-01)\tAcc@1  90.62 ( 93.85)\tAcc@5 100.00 ( 99.86)\n",
            "Epoch: [88][150/391]\tTime  0.096 ( 0.096)\tLoss 1.9926e-01 (2.0625e-01)\tAcc@1  92.19 ( 93.68)\tAcc@5 100.00 ( 99.86)\n",
            "Epoch: [88][180/391]\tTime  0.091 ( 0.095)\tLoss 2.9775e-01 (2.0936e-01)\tAcc@1  89.84 ( 93.50)\tAcc@5 100.00 ( 99.82)\n",
            "Epoch: [88][210/391]\tTime  0.090 ( 0.095)\tLoss 2.3864e-01 (2.1295e-01)\tAcc@1  92.97 ( 93.47)\tAcc@5  99.22 ( 99.82)\n",
            "Epoch: [88][240/391]\tTime  0.089 ( 0.095)\tLoss 2.1070e-01 (2.1986e-01)\tAcc@1  94.53 ( 93.21)\tAcc@5  99.22 ( 99.79)\n",
            "Epoch: [88][270/391]\tTime  0.080 ( 0.095)\tLoss 1.7781e-01 (2.2423e-01)\tAcc@1  92.97 ( 93.11)\tAcc@5 100.00 ( 99.79)\n",
            "Epoch: [88][300/391]\tTime  0.097 ( 0.095)\tLoss 2.1628e-01 (2.2591e-01)\tAcc@1  92.97 ( 93.06)\tAcc@5  99.22 ( 99.78)\n",
            "Epoch: [88][330/391]\tTime  0.096 ( 0.095)\tLoss 2.7905e-01 (2.2737e-01)\tAcc@1  92.19 ( 93.01)\tAcc@5  99.22 ( 99.78)\n",
            "Epoch: [88][360/391]\tTime  0.096 ( 0.094)\tLoss 3.1841e-01 (2.3078e-01)\tAcc@1  88.28 ( 92.87)\tAcc@5  98.44 ( 99.78)\n",
            "Epoch: [88][390/391]\tTime  0.082 ( 0.094)\tLoss 2.2047e-01 (2.3268e-01)\tAcc@1  92.50 ( 92.83)\tAcc@5 100.00 ( 99.77)\n",
            "==> Train Accuracy: Acc@1 92.830 || Acc@5 99.770\n",
            "==> Test Accuracy:  Acc@1 70.330 || Acc@5 91.280\n",
            "==> 39.40 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 89, lr: 0.020000000000000004 -----\n",
            "Epoch: [89][  0/391]\tTime  0.296 ( 0.296)\tLoss 1.4733e-01 (1.4733e-01)\tAcc@1  93.75 ( 93.75)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [89][ 30/391]\tTime  0.100 ( 0.102)\tLoss 1.7202e-01 (1.9930e-01)\tAcc@1  95.31 ( 93.90)\tAcc@5 100.00 ( 99.87)\n",
            "Epoch: [89][ 60/391]\tTime  0.097 ( 0.098)\tLoss 1.4375e-01 (1.9633e-01)\tAcc@1  96.09 ( 94.04)\tAcc@5 100.00 ( 99.82)\n",
            "Epoch: [89][ 90/391]\tTime  0.101 ( 0.097)\tLoss 2.2409e-01 (1.9885e-01)\tAcc@1  92.97 ( 94.09)\tAcc@5 100.00 ( 99.82)\n",
            "Epoch: [89][120/391]\tTime  0.098 ( 0.097)\tLoss 2.2949e-01 (1.9848e-01)\tAcc@1  92.19 ( 94.13)\tAcc@5 100.00 ( 99.81)\n",
            "Epoch: [89][150/391]\tTime  0.091 ( 0.096)\tLoss 2.6619e-01 (2.0103e-01)\tAcc@1  91.41 ( 94.06)\tAcc@5 100.00 ( 99.80)\n",
            "Epoch: [89][180/391]\tTime  0.099 ( 0.096)\tLoss 1.8864e-01 (2.0490e-01)\tAcc@1  93.75 ( 93.96)\tAcc@5  99.22 ( 99.79)\n",
            "Epoch: [89][210/391]\tTime  0.080 ( 0.096)\tLoss 1.8645e-01 (2.0694e-01)\tAcc@1  93.75 ( 93.93)\tAcc@5 100.00 ( 99.78)\n",
            "Epoch: [89][240/391]\tTime  0.091 ( 0.096)\tLoss 1.9718e-01 (2.1009e-01)\tAcc@1  93.75 ( 93.78)\tAcc@5 100.00 ( 99.78)\n",
            "Epoch: [89][270/391]\tTime  0.110 ( 0.095)\tLoss 3.1721e-01 (2.1476e-01)\tAcc@1  89.84 ( 93.59)\tAcc@5 100.00 ( 99.76)\n",
            "Epoch: [89][300/391]\tTime  0.099 ( 0.095)\tLoss 2.4036e-01 (2.1829e-01)\tAcc@1  93.75 ( 93.50)\tAcc@5  99.22 ( 99.75)\n",
            "Epoch: [89][330/391]\tTime  0.096 ( 0.095)\tLoss 3.2446e-01 (2.2230e-01)\tAcc@1  91.41 ( 93.32)\tAcc@5  99.22 ( 99.75)\n",
            "Epoch: [89][360/391]\tTime  0.091 ( 0.095)\tLoss 2.0296e-01 (2.2583e-01)\tAcc@1  92.97 ( 93.21)\tAcc@5 100.00 ( 99.73)\n",
            "Epoch: [89][390/391]\tTime  0.082 ( 0.095)\tLoss 4.1008e-01 (2.3002e-01)\tAcc@1  90.00 ( 93.07)\tAcc@5  97.50 ( 99.73)\n",
            "==> Train Accuracy: Acc@1 93.072 || Acc@5 99.728\n",
            "==> Test Accuracy:  Acc@1 69.220 || Acc@5 90.430\n",
            "==> 39.63 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 90, lr: 0.004000000000000001 -----\n",
            "Epoch: [90][  0/391]\tTime  0.308 ( 0.308)\tLoss 2.0181e-01 (2.0181e-01)\tAcc@1  92.97 ( 92.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [90][ 30/391]\tTime  0.086 ( 0.102)\tLoss 1.3246e-01 (1.7463e-01)\tAcc@1  95.31 ( 94.93)\tAcc@5 100.00 ( 99.77)\n",
            "Epoch: [90][ 60/391]\tTime  0.091 ( 0.097)\tLoss 1.3295e-01 (1.4874e-01)\tAcc@1  96.09 ( 95.98)\tAcc@5 100.00 ( 99.88)\n",
            "Epoch: [90][ 90/391]\tTime  0.090 ( 0.096)\tLoss 6.2681e-02 (1.3800e-01)\tAcc@1  99.22 ( 96.27)\tAcc@5 100.00 ( 99.91)\n",
            "Epoch: [90][120/391]\tTime  0.098 ( 0.096)\tLoss 1.0434e-01 (1.3035e-01)\tAcc@1  97.66 ( 96.56)\tAcc@5 100.00 ( 99.94)\n",
            "Epoch: [90][150/391]\tTime  0.100 ( 0.096)\tLoss 7.8723e-02 (1.2256e-01)\tAcc@1  97.66 ( 96.72)\tAcc@5 100.00 ( 99.94)\n",
            "Epoch: [90][180/391]\tTime  0.089 ( 0.095)\tLoss 1.1929e-01 (1.1676e-01)\tAcc@1  97.66 ( 96.89)\tAcc@5 100.00 ( 99.95)\n",
            "Epoch: [90][210/391]\tTime  0.092 ( 0.095)\tLoss 8.8547e-02 (1.1069e-01)\tAcc@1  98.44 ( 97.12)\tAcc@5 100.00 ( 99.96)\n",
            "Epoch: [90][240/391]\tTime  0.091 ( 0.095)\tLoss 1.1164e-01 (1.0650e-01)\tAcc@1  96.88 ( 97.25)\tAcc@5 100.00 ( 99.96)\n",
            "Epoch: [90][270/391]\tTime  0.097 ( 0.095)\tLoss 7.0739e-02 (1.0235e-01)\tAcc@1  96.88 ( 97.36)\tAcc@5 100.00 ( 99.97)\n",
            "Epoch: [90][300/391]\tTime  0.103 ( 0.095)\tLoss 6.0168e-02 (9.8714e-02)\tAcc@1  98.44 ( 97.47)\tAcc@5 100.00 ( 99.97)\n",
            "Epoch: [90][330/391]\tTime  0.098 ( 0.095)\tLoss 6.0921e-02 (9.5915e-02)\tAcc@1  99.22 ( 97.58)\tAcc@5 100.00 ( 99.96)\n",
            "Epoch: [90][360/391]\tTime  0.094 ( 0.095)\tLoss 3.9277e-02 (9.3127e-02)\tAcc@1 100.00 ( 97.67)\tAcc@5 100.00 ( 99.96)\n",
            "Epoch: [90][390/391]\tTime  0.081 ( 0.095)\tLoss 1.2940e-01 (9.1289e-02)\tAcc@1  97.50 ( 97.73)\tAcc@5 100.00 ( 99.97)\n",
            "==> Train Accuracy: Acc@1 97.728 || Acc@5 99.966\n",
            "==> Test Accuracy:  Acc@1 75.760 || Acc@5 93.580\n",
            "==> 39.49 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 91, lr: 0.004000000000000001 -----\n",
            "Epoch: [91][  0/391]\tTime  0.304 ( 0.304)\tLoss 5.2364e-02 (5.2364e-02)\tAcc@1  97.66 ( 97.66)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [91][ 30/391]\tTime  0.081 ( 0.103)\tLoss 8.4265e-02 (5.4367e-02)\tAcc@1  96.88 ( 98.84)\tAcc@5 100.00 ( 99.97)\n",
            "Epoch: [91][ 60/391]\tTime  0.088 ( 0.099)\tLoss 4.2539e-02 (4.9359e-02)\tAcc@1  99.22 ( 99.07)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [91][ 90/391]\tTime  0.092 ( 0.097)\tLoss 5.0886e-02 (4.9395e-02)\tAcc@1  98.44 ( 99.04)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [91][120/391]\tTime  0.095 ( 0.096)\tLoss 8.6925e-02 (4.9671e-02)\tAcc@1  98.44 ( 99.02)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [91][150/391]\tTime  0.090 ( 0.095)\tLoss 1.5529e-02 (4.7977e-02)\tAcc@1 100.00 ( 99.05)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [91][180/391]\tTime  0.101 ( 0.095)\tLoss 5.7188e-02 (4.8076e-02)\tAcc@1  98.44 ( 99.06)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [91][210/391]\tTime  0.082 ( 0.095)\tLoss 2.9219e-02 (4.8249e-02)\tAcc@1  99.22 ( 99.04)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [91][240/391]\tTime  0.094 ( 0.095)\tLoss 7.0849e-02 (4.8838e-02)\tAcc@1  98.44 ( 98.99)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [91][270/391]\tTime  0.090 ( 0.095)\tLoss 5.1801e-02 (4.8633e-02)\tAcc@1  97.66 ( 98.98)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [91][300/391]\tTime  0.094 ( 0.094)\tLoss 5.0663e-02 (4.8211e-02)\tAcc@1  98.44 ( 98.99)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [91][330/391]\tTime  0.088 ( 0.094)\tLoss 7.5534e-02 (4.8111e-02)\tAcc@1  95.31 ( 98.98)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [91][360/391]\tTime  0.084 ( 0.094)\tLoss 8.5773e-02 (4.7885e-02)\tAcc@1  97.66 ( 98.99)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [91][390/391]\tTime  0.082 ( 0.094)\tLoss 4.9280e-02 (4.7591e-02)\tAcc@1  97.50 ( 99.00)\tAcc@5 100.00 ( 99.99)\n",
            "==> Train Accuracy: Acc@1 98.998 || Acc@5 99.992\n",
            "==> Test Accuracy:  Acc@1 76.480 || Acc@5 93.560\n",
            "==> 39.25 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 92, lr: 0.004000000000000001 -----\n",
            "Epoch: [92][  0/391]\tTime  0.288 ( 0.288)\tLoss 1.4183e-02 (1.4183e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [92][ 30/391]\tTime  0.089 ( 0.101)\tLoss 3.6560e-02 (3.7883e-02)\tAcc@1  99.22 ( 99.22)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [92][ 60/391]\tTime  0.091 ( 0.097)\tLoss 3.7350e-02 (3.9078e-02)\tAcc@1  99.22 ( 99.09)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [92][ 90/391]\tTime  0.087 ( 0.095)\tLoss 3.5282e-02 (3.7563e-02)\tAcc@1 100.00 ( 99.25)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [92][120/391]\tTime  0.090 ( 0.095)\tLoss 2.6065e-02 (3.6250e-02)\tAcc@1  99.22 ( 99.28)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [92][150/391]\tTime  0.093 ( 0.094)\tLoss 5.6126e-02 (3.6728e-02)\tAcc@1  99.22 ( 99.29)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [92][180/391]\tTime  0.092 ( 0.094)\tLoss 4.3778e-02 (3.7285e-02)\tAcc@1  98.44 ( 99.27)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [92][210/391]\tTime  0.089 ( 0.094)\tLoss 3.9087e-02 (3.7019e-02)\tAcc@1  99.22 ( 99.30)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [92][240/391]\tTime  0.092 ( 0.094)\tLoss 1.3910e-02 (3.7060e-02)\tAcc@1 100.00 ( 99.28)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [92][270/391]\tTime  0.091 ( 0.094)\tLoss 3.3851e-02 (3.6545e-02)\tAcc@1  99.22 ( 99.29)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [92][300/391]\tTime  0.095 ( 0.094)\tLoss 2.3955e-02 (3.6160e-02)\tAcc@1 100.00 ( 99.32)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [92][330/391]\tTime  0.093 ( 0.094)\tLoss 4.8114e-02 (3.6367e-02)\tAcc@1  99.22 ( 99.31)\tAcc@5  99.22 (100.00)\n",
            "Epoch: [92][360/391]\tTime  0.094 ( 0.094)\tLoss 6.1284e-02 (3.6506e-02)\tAcc@1  96.88 ( 99.30)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [92][390/391]\tTime  0.082 ( 0.094)\tLoss 7.0733e-02 (3.6246e-02)\tAcc@1  96.25 ( 99.31)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.308 || Acc@5 99.998\n",
            "==> Test Accuracy:  Acc@1 76.860 || Acc@5 93.550\n",
            "==> 39.22 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 93, lr: 0.004000000000000001 -----\n",
            "Epoch: [93][  0/391]\tTime  0.291 ( 0.291)\tLoss 1.7505e-02 (1.7505e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [93][ 30/391]\tTime  0.075 ( 0.101)\tLoss 4.2605e-02 (2.8916e-02)\tAcc@1  99.22 ( 99.52)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [93][ 60/391]\tTime  0.108 ( 0.097)\tLoss 4.2891e-02 (2.9409e-02)\tAcc@1  99.22 ( 99.56)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [93][ 90/391]\tTime  0.095 ( 0.096)\tLoss 1.2737e-02 (2.9564e-02)\tAcc@1 100.00 ( 99.57)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [93][120/391]\tTime  0.093 ( 0.095)\tLoss 2.0281e-02 (3.1018e-02)\tAcc@1 100.00 ( 99.52)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [93][150/391]\tTime  0.091 ( 0.094)\tLoss 1.6062e-02 (3.0765e-02)\tAcc@1 100.00 ( 99.51)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [93][180/391]\tTime  0.097 ( 0.094)\tLoss 1.8376e-02 (3.0882e-02)\tAcc@1 100.00 ( 99.49)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [93][210/391]\tTime  0.084 ( 0.094)\tLoss 4.7442e-02 (3.0800e-02)\tAcc@1  99.22 ( 99.49)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [93][240/391]\tTime  0.095 ( 0.094)\tLoss 2.8662e-02 (3.0802e-02)\tAcc@1  99.22 ( 99.48)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [93][270/391]\tTime  0.092 ( 0.094)\tLoss 3.3681e-02 (3.1139e-02)\tAcc@1  99.22 ( 99.46)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [93][300/391]\tTime  0.094 ( 0.094)\tLoss 3.4329e-02 (3.1492e-02)\tAcc@1  99.22 ( 99.44)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [93][330/391]\tTime  0.095 ( 0.093)\tLoss 1.9977e-02 (3.1108e-02)\tAcc@1 100.00 ( 99.46)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [93][360/391]\tTime  0.088 ( 0.093)\tLoss 2.8280e-02 (3.1141e-02)\tAcc@1 100.00 ( 99.47)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [93][390/391]\tTime  0.081 ( 0.093)\tLoss 2.2108e-02 (3.1176e-02)\tAcc@1 100.00 ( 99.48)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.478 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 76.800 || Acc@5 93.520\n",
            "==> 38.96 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 94, lr: 0.004000000000000001 -----\n",
            "Epoch: [94][  0/391]\tTime  0.301 ( 0.301)\tLoss 2.2788e-02 (2.2788e-02)\tAcc@1  99.22 ( 99.22)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [94][ 30/391]\tTime  0.101 ( 0.101)\tLoss 8.2941e-03 (2.3934e-02)\tAcc@1 100.00 ( 99.60)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [94][ 60/391]\tTime  0.093 ( 0.097)\tLoss 1.9752e-02 (2.5750e-02)\tAcc@1 100.00 ( 99.56)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [94][ 90/391]\tTime  0.089 ( 0.096)\tLoss 2.0665e-02 (2.6235e-02)\tAcc@1 100.00 ( 99.59)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [94][120/391]\tTime  0.091 ( 0.095)\tLoss 3.0278e-02 (2.6342e-02)\tAcc@1  99.22 ( 99.59)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [94][150/391]\tTime  0.089 ( 0.095)\tLoss 2.0826e-02 (2.6367e-02)\tAcc@1 100.00 ( 99.59)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [94][180/391]\tTime  0.091 ( 0.095)\tLoss 4.1122e-02 (2.6431e-02)\tAcc@1  99.22 ( 99.58)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [94][210/391]\tTime  0.078 ( 0.095)\tLoss 1.7523e-02 (2.6349e-02)\tAcc@1 100.00 ( 99.58)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [94][240/391]\tTime  0.089 ( 0.094)\tLoss 1.4500e-02 (2.5852e-02)\tAcc@1 100.00 ( 99.59)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [94][270/391]\tTime  0.083 ( 0.094)\tLoss 1.4206e-02 (2.5825e-02)\tAcc@1 100.00 ( 99.60)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [94][300/391]\tTime  0.089 ( 0.094)\tLoss 2.7777e-02 (2.5726e-02)\tAcc@1  99.22 ( 99.61)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [94][330/391]\tTime  0.090 ( 0.094)\tLoss 1.7827e-02 (2.5931e-02)\tAcc@1  99.22 ( 99.60)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [94][360/391]\tTime  0.091 ( 0.094)\tLoss 2.2351e-02 (2.6026e-02)\tAcc@1 100.00 ( 99.60)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [94][390/391]\tTime  0.082 ( 0.094)\tLoss 1.8908e-02 (2.6100e-02)\tAcc@1 100.00 ( 99.59)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.592 || Acc@5 99.998\n",
            "==> Test Accuracy:  Acc@1 77.050 || Acc@5 93.530\n",
            "==> 39.16 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 95, lr: 0.004000000000000001 -----\n",
            "Epoch: [95][  0/391]\tTime  0.299 ( 0.299)\tLoss 1.6360e-02 (1.6360e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [95][ 30/391]\tTime  0.090 ( 0.101)\tLoss 2.3013e-02 (2.3921e-02)\tAcc@1 100.00 ( 99.75)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [95][ 60/391]\tTime  0.091 ( 0.097)\tLoss 5.4515e-02 (2.3651e-02)\tAcc@1  99.22 ( 99.71)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [95][ 90/391]\tTime  0.096 ( 0.096)\tLoss 2.6456e-02 (2.4438e-02)\tAcc@1  99.22 ( 99.67)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [95][120/391]\tTime  0.091 ( 0.095)\tLoss 1.6168e-02 (2.4212e-02)\tAcc@1 100.00 ( 99.68)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [95][150/391]\tTime  0.091 ( 0.095)\tLoss 2.6491e-02 (2.3955e-02)\tAcc@1 100.00 ( 99.68)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [95][180/391]\tTime  0.098 ( 0.094)\tLoss 2.5117e-02 (2.3480e-02)\tAcc@1 100.00 ( 99.71)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [95][210/391]\tTime  0.091 ( 0.094)\tLoss 3.1216e-02 (2.3390e-02)\tAcc@1 100.00 ( 99.71)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [95][240/391]\tTime  0.096 ( 0.094)\tLoss 1.6546e-02 (2.3360e-02)\tAcc@1  99.22 ( 99.70)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [95][270/391]\tTime  0.083 ( 0.094)\tLoss 1.6269e-02 (2.3655e-02)\tAcc@1 100.00 ( 99.67)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [95][300/391]\tTime  0.094 ( 0.094)\tLoss 2.5534e-02 (2.3863e-02)\tAcc@1  99.22 ( 99.66)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [95][330/391]\tTime  0.097 ( 0.094)\tLoss 1.7005e-02 (2.3795e-02)\tAcc@1 100.00 ( 99.66)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [95][360/391]\tTime  0.092 ( 0.094)\tLoss 1.9642e-02 (2.3827e-02)\tAcc@1 100.00 ( 99.66)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [95][390/391]\tTime  0.082 ( 0.094)\tLoss 1.9737e-02 (2.4093e-02)\tAcc@1 100.00 ( 99.65)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.648 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 76.730 || Acc@5 93.610\n",
            "==> 39.11 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 96, lr: 0.004000000000000001 -----\n",
            "Epoch: [96][  0/391]\tTime  0.277 ( 0.277)\tLoss 1.6399e-02 (1.6399e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [96][ 30/391]\tTime  0.097 ( 0.100)\tLoss 3.3163e-02 (2.0925e-02)\tAcc@1  99.22 ( 99.77)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [96][ 60/391]\tTime  0.091 ( 0.096)\tLoss 1.1486e-02 (2.0847e-02)\tAcc@1 100.00 ( 99.72)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [96][ 90/391]\tTime  0.092 ( 0.095)\tLoss 1.3484e-02 (2.0946e-02)\tAcc@1 100.00 ( 99.72)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [96][120/391]\tTime  0.092 ( 0.094)\tLoss 1.8828e-02 (2.1652e-02)\tAcc@1 100.00 ( 99.68)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [96][150/391]\tTime  0.104 ( 0.094)\tLoss 1.7948e-02 (2.1872e-02)\tAcc@1  99.22 ( 99.66)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [96][180/391]\tTime  0.090 ( 0.094)\tLoss 1.5855e-02 (2.1591e-02)\tAcc@1 100.00 ( 99.67)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [96][210/391]\tTime  0.090 ( 0.094)\tLoss 2.0167e-02 (2.1506e-02)\tAcc@1 100.00 ( 99.68)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [96][240/391]\tTime  0.097 ( 0.094)\tLoss 1.1800e-02 (2.1518e-02)\tAcc@1 100.00 ( 99.68)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [96][270/391]\tTime  0.092 ( 0.093)\tLoss 1.7052e-02 (2.1606e-02)\tAcc@1 100.00 ( 99.69)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [96][300/391]\tTime  0.100 ( 0.093)\tLoss 2.8795e-02 (2.1521e-02)\tAcc@1 100.00 ( 99.69)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [96][330/391]\tTime  0.085 ( 0.093)\tLoss 2.8387e-02 (2.1609e-02)\tAcc@1  98.44 ( 99.68)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [96][360/391]\tTime  0.085 ( 0.093)\tLoss 1.8801e-02 (2.1801e-02)\tAcc@1 100.00 ( 99.68)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [96][390/391]\tTime  0.082 ( 0.093)\tLoss 2.8941e-02 (2.2046e-02)\tAcc@1 100.00 ( 99.68)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.676 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 76.970 || Acc@5 93.750\n",
            "==> 38.90 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 97, lr: 0.004000000000000001 -----\n",
            "Epoch: [97][  0/391]\tTime  0.274 ( 0.274)\tLoss 1.7797e-02 (1.7797e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [97][ 30/391]\tTime  0.092 ( 0.100)\tLoss 2.1939e-02 (2.0087e-02)\tAcc@1  99.22 ( 99.77)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [97][ 60/391]\tTime  0.095 ( 0.097)\tLoss 1.6093e-02 (2.0198e-02)\tAcc@1 100.00 ( 99.74)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [97][ 90/391]\tTime  0.099 ( 0.096)\tLoss 2.8638e-02 (1.9805e-02)\tAcc@1  99.22 ( 99.74)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [97][120/391]\tTime  0.107 ( 0.095)\tLoss 2.7728e-02 (2.0231e-02)\tAcc@1  99.22 ( 99.75)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [97][150/391]\tTime  0.091 ( 0.095)\tLoss 1.3140e-02 (2.0301e-02)\tAcc@1 100.00 ( 99.75)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [97][180/391]\tTime  0.091 ( 0.095)\tLoss 3.3070e-02 (2.0090e-02)\tAcc@1  98.44 ( 99.75)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [97][210/391]\tTime  0.090 ( 0.094)\tLoss 2.9751e-02 (2.0220e-02)\tAcc@1 100.00 ( 99.75)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [97][240/391]\tTime  0.098 ( 0.094)\tLoss 1.4849e-02 (2.0577e-02)\tAcc@1 100.00 ( 99.74)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [97][270/391]\tTime  0.092 ( 0.094)\tLoss 3.3640e-02 (2.0656e-02)\tAcc@1 100.00 ( 99.74)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [97][300/391]\tTime  0.095 ( 0.094)\tLoss 2.0053e-02 (2.0589e-02)\tAcc@1 100.00 ( 99.74)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [97][330/391]\tTime  0.091 ( 0.094)\tLoss 1.6601e-02 (2.0498e-02)\tAcc@1 100.00 ( 99.74)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [97][360/391]\tTime  0.092 ( 0.094)\tLoss 1.4692e-02 (2.0809e-02)\tAcc@1 100.00 ( 99.73)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [97][390/391]\tTime  0.082 ( 0.094)\tLoss 1.6199e-02 (2.0905e-02)\tAcc@1 100.00 ( 99.72)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.722 || Acc@5 99.996\n",
            "==> Test Accuracy:  Acc@1 76.890 || Acc@5 93.610\n",
            "==> 39.08 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 98, lr: 0.004000000000000001 -----\n",
            "Epoch: [98][  0/391]\tTime  0.279 ( 0.279)\tLoss 2.4438e-02 (2.4438e-02)\tAcc@1  99.22 ( 99.22)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [98][ 30/391]\tTime  0.090 ( 0.100)\tLoss 1.8818e-02 (1.9298e-02)\tAcc@1 100.00 ( 99.72)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [98][ 60/391]\tTime  0.094 ( 0.096)\tLoss 7.9255e-03 (1.7996e-02)\tAcc@1 100.00 ( 99.77)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [98][ 90/391]\tTime  0.092 ( 0.095)\tLoss 1.3361e-02 (1.7793e-02)\tAcc@1 100.00 ( 99.79)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [98][120/391]\tTime  0.090 ( 0.094)\tLoss 1.2675e-02 (1.7801e-02)\tAcc@1 100.00 ( 99.79)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [98][150/391]\tTime  0.088 ( 0.094)\tLoss 9.2201e-03 (1.8187e-02)\tAcc@1 100.00 ( 99.75)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [98][180/391]\tTime  0.091 ( 0.094)\tLoss 1.7234e-02 (1.8224e-02)\tAcc@1 100.00 ( 99.75)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [98][210/391]\tTime  0.093 ( 0.094)\tLoss 3.2714e-02 (1.8994e-02)\tAcc@1  99.22 ( 99.72)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [98][240/391]\tTime  0.089 ( 0.093)\tLoss 1.4475e-02 (1.8791e-02)\tAcc@1 100.00 ( 99.74)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [98][270/391]\tTime  0.098 ( 0.093)\tLoss 1.2134e-02 (1.9032e-02)\tAcc@1 100.00 ( 99.73)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [98][300/391]\tTime  0.088 ( 0.093)\tLoss 1.9749e-02 (1.9417e-02)\tAcc@1 100.00 ( 99.72)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [98][330/391]\tTime  0.089 ( 0.093)\tLoss 1.5647e-02 (1.9346e-02)\tAcc@1 100.00 ( 99.72)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [98][360/391]\tTime  0.088 ( 0.093)\tLoss 1.9581e-02 (1.9375e-02)\tAcc@1 100.00 ( 99.72)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [98][390/391]\tTime  0.082 ( 0.093)\tLoss 1.4516e-02 (1.9547e-02)\tAcc@1 100.00 ( 99.71)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.710 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.190 || Acc@5 93.620\n",
            "==> 39.00 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 99, lr: 0.004000000000000001 -----\n",
            "Epoch: [99][  0/391]\tTime  0.295 ( 0.295)\tLoss 2.6030e-02 (2.6030e-02)\tAcc@1  99.22 ( 99.22)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [99][ 30/391]\tTime  0.093 ( 0.102)\tLoss 1.4222e-02 (1.6298e-02)\tAcc@1 100.00 ( 99.85)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [99][ 60/391]\tTime  0.095 ( 0.098)\tLoss 1.4698e-02 (1.6402e-02)\tAcc@1 100.00 ( 99.85)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [99][ 90/391]\tTime  0.091 ( 0.096)\tLoss 1.0585e-02 (1.7106e-02)\tAcc@1 100.00 ( 99.83)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [99][120/391]\tTime  0.093 ( 0.096)\tLoss 1.4751e-02 (1.7416e-02)\tAcc@1 100.00 ( 99.80)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [99][150/391]\tTime  0.098 ( 0.095)\tLoss 1.4869e-02 (1.7026e-02)\tAcc@1 100.00 ( 99.81)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [99][180/391]\tTime  0.092 ( 0.095)\tLoss 1.1371e-02 (1.7464e-02)\tAcc@1 100.00 ( 99.80)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [99][210/391]\tTime  0.088 ( 0.094)\tLoss 2.4218e-02 (1.7621e-02)\tAcc@1 100.00 ( 99.79)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [99][240/391]\tTime  0.099 ( 0.094)\tLoss 1.6421e-02 (1.7778e-02)\tAcc@1 100.00 ( 99.77)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [99][270/391]\tTime  0.096 ( 0.094)\tLoss 1.3801e-02 (1.8016e-02)\tAcc@1 100.00 ( 99.77)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [99][300/391]\tTime  0.094 ( 0.094)\tLoss 3.2086e-02 (1.8334e-02)\tAcc@1  99.22 ( 99.75)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [99][330/391]\tTime  0.094 ( 0.094)\tLoss 1.0527e-02 (1.8054e-02)\tAcc@1 100.00 ( 99.76)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [99][360/391]\tTime  0.094 ( 0.094)\tLoss 1.4700e-02 (1.8139e-02)\tAcc@1 100.00 ( 99.77)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [99][390/391]\tTime  0.084 ( 0.093)\tLoss 5.2626e-02 (1.8070e-02)\tAcc@1  98.75 ( 99.78)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.778 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.440 || Acc@5 93.620\n",
            "==> 39.04 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 100, lr: 0.004000000000000001 -----\n",
            "Epoch: [100][  0/391]\tTime  0.291 ( 0.291)\tLoss 1.2026e-02 (1.2026e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [100][ 30/391]\tTime  0.109 ( 0.101)\tLoss 2.0880e-02 (1.6514e-02)\tAcc@1 100.00 ( 99.72)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [100][ 60/391]\tTime  0.094 ( 0.098)\tLoss 2.5493e-02 (1.7201e-02)\tAcc@1  99.22 ( 99.74)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [100][ 90/391]\tTime  0.098 ( 0.096)\tLoss 1.3349e-02 (1.7564e-02)\tAcc@1 100.00 ( 99.72)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [100][120/391]\tTime  0.095 ( 0.095)\tLoss 1.8944e-02 (1.7324e-02)\tAcc@1 100.00 ( 99.75)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [100][150/391]\tTime  0.090 ( 0.095)\tLoss 1.6464e-02 (1.7247e-02)\tAcc@1 100.00 ( 99.77)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [100][180/391]\tTime  0.089 ( 0.095)\tLoss 1.9039e-02 (1.7847e-02)\tAcc@1 100.00 ( 99.76)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [100][210/391]\tTime  0.092 ( 0.095)\tLoss 1.4356e-02 (1.7356e-02)\tAcc@1 100.00 ( 99.78)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [100][240/391]\tTime  0.096 ( 0.094)\tLoss 1.3732e-02 (1.7456e-02)\tAcc@1 100.00 ( 99.79)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [100][270/391]\tTime  0.086 ( 0.094)\tLoss 1.2220e-02 (1.7579e-02)\tAcc@1 100.00 ( 99.78)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [100][300/391]\tTime  0.088 ( 0.094)\tLoss 1.3365e-02 (1.7418e-02)\tAcc@1 100.00 ( 99.79)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [100][330/391]\tTime  0.096 ( 0.094)\tLoss 1.6783e-02 (1.7327e-02)\tAcc@1 100.00 ( 99.79)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [100][360/391]\tTime  0.087 ( 0.094)\tLoss 9.4774e-03 (1.7399e-02)\tAcc@1 100.00 ( 99.79)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [100][390/391]\tTime  0.081 ( 0.094)\tLoss 8.2418e-03 (1.7409e-02)\tAcc@1 100.00 ( 99.79)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.792 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.630 || Acc@5 93.740\n",
            "==> 39.21 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 101, lr: 0.004000000000000001 -----\n",
            "Epoch: [101][  0/391]\tTime  0.298 ( 0.298)\tLoss 9.9807e-03 (9.9807e-03)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [101][ 30/391]\tTime  0.092 ( 0.101)\tLoss 1.0011e-02 (1.5756e-02)\tAcc@1 100.00 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [101][ 60/391]\tTime  0.109 ( 0.097)\tLoss 1.2480e-02 (1.5638e-02)\tAcc@1 100.00 ( 99.86)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [101][ 90/391]\tTime  0.093 ( 0.095)\tLoss 1.0615e-02 (1.6182e-02)\tAcc@1 100.00 ( 99.85)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [101][120/391]\tTime  0.098 ( 0.095)\tLoss 1.0235e-02 (1.5605e-02)\tAcc@1 100.00 ( 99.86)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [101][150/391]\tTime  0.094 ( 0.094)\tLoss 1.3828e-02 (1.5490e-02)\tAcc@1  99.22 ( 99.86)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [101][180/391]\tTime  0.094 ( 0.094)\tLoss 1.9298e-02 (1.5364e-02)\tAcc@1 100.00 ( 99.87)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [101][210/391]\tTime  0.089 ( 0.094)\tLoss 1.4363e-02 (1.5273e-02)\tAcc@1 100.00 ( 99.87)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [101][240/391]\tTime  0.088 ( 0.094)\tLoss 1.5728e-02 (1.5406e-02)\tAcc@1 100.00 ( 99.87)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [101][270/391]\tTime  0.095 ( 0.094)\tLoss 1.0765e-02 (1.5579e-02)\tAcc@1 100.00 ( 99.86)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [101][300/391]\tTime  0.096 ( 0.094)\tLoss 7.8937e-03 (1.5632e-02)\tAcc@1 100.00 ( 99.87)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [101][330/391]\tTime  0.095 ( 0.094)\tLoss 2.6392e-02 (1.5811e-02)\tAcc@1  99.22 ( 99.87)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [101][360/391]\tTime  0.094 ( 0.094)\tLoss 8.1817e-03 (1.5726e-02)\tAcc@1 100.00 ( 99.87)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [101][390/391]\tTime  0.083 ( 0.094)\tLoss 1.7084e-02 (1.5653e-02)\tAcc@1 100.00 ( 99.87)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.870 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.460 || Acc@5 93.670\n",
            "==> 39.14 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 102, lr: 0.004000000000000001 -----\n",
            "Epoch: [102][  0/391]\tTime  0.293 ( 0.293)\tLoss 2.0155e-02 (2.0155e-02)\tAcc@1  99.22 ( 99.22)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [102][ 30/391]\tTime  0.100 ( 0.101)\tLoss 9.7740e-03 (1.2893e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [102][ 60/391]\tTime  0.085 ( 0.097)\tLoss 2.5471e-02 (1.4234e-02)\tAcc@1  99.22 ( 99.86)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [102][ 90/391]\tTime  0.099 ( 0.096)\tLoss 1.1355e-02 (1.4313e-02)\tAcc@1 100.00 ( 99.86)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [102][120/391]\tTime  0.097 ( 0.095)\tLoss 1.7402e-02 (1.4288e-02)\tAcc@1 100.00 ( 99.86)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [102][150/391]\tTime  0.106 ( 0.095)\tLoss 1.0418e-02 (1.4645e-02)\tAcc@1 100.00 ( 99.85)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [102][180/391]\tTime  0.100 ( 0.094)\tLoss 3.1610e-02 (1.4962e-02)\tAcc@1  99.22 ( 99.85)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [102][210/391]\tTime  0.088 ( 0.094)\tLoss 4.6530e-02 (1.5156e-02)\tAcc@1  97.66 ( 99.84)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [102][240/391]\tTime  0.098 ( 0.094)\tLoss 9.0119e-03 (1.5189e-02)\tAcc@1 100.00 ( 99.84)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [102][270/391]\tTime  0.093 ( 0.094)\tLoss 1.2857e-02 (1.5571e-02)\tAcc@1 100.00 ( 99.82)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [102][300/391]\tTime  0.080 ( 0.094)\tLoss 7.2596e-03 (1.5620e-02)\tAcc@1 100.00 ( 99.82)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [102][330/391]\tTime  0.092 ( 0.094)\tLoss 1.5708e-02 (1.5763e-02)\tAcc@1 100.00 ( 99.82)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [102][360/391]\tTime  0.091 ( 0.094)\tLoss 1.7733e-02 (1.5686e-02)\tAcc@1 100.00 ( 99.82)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [102][390/391]\tTime  0.082 ( 0.094)\tLoss 1.3660e-02 (1.5819e-02)\tAcc@1 100.00 ( 99.81)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.814 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.250 || Acc@5 93.740\n",
            "==> 39.09 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 103, lr: 0.004000000000000001 -----\n",
            "Epoch: [103][  0/391]\tTime  0.287 ( 0.287)\tLoss 1.1196e-02 (1.1196e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [103][ 30/391]\tTime  0.092 ( 0.100)\tLoss 1.0324e-02 (1.4670e-02)\tAcc@1 100.00 ( 99.82)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [103][ 60/391]\tTime  0.096 ( 0.096)\tLoss 9.7760e-03 (1.4432e-02)\tAcc@1 100.00 ( 99.87)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [103][ 90/391]\tTime  0.101 ( 0.095)\tLoss 1.2891e-02 (1.4530e-02)\tAcc@1 100.00 ( 99.87)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [103][120/391]\tTime  0.094 ( 0.095)\tLoss 1.0639e-02 (1.4072e-02)\tAcc@1 100.00 ( 99.89)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [103][150/391]\tTime  0.087 ( 0.094)\tLoss 1.5365e-02 (1.4173e-02)\tAcc@1 100.00 ( 99.89)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [103][180/391]\tTime  0.093 ( 0.094)\tLoss 2.1362e-02 (1.4183e-02)\tAcc@1 100.00 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [103][210/391]\tTime  0.092 ( 0.094)\tLoss 1.4823e-02 (1.4321e-02)\tAcc@1 100.00 ( 99.89)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [103][240/391]\tTime  0.091 ( 0.094)\tLoss 6.8845e-03 (1.4646e-02)\tAcc@1 100.00 ( 99.87)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [103][270/391]\tTime  0.092 ( 0.094)\tLoss 1.5614e-02 (1.4472e-02)\tAcc@1 100.00 ( 99.88)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [103][300/391]\tTime  0.095 ( 0.094)\tLoss 2.2178e-02 (1.4745e-02)\tAcc@1 100.00 ( 99.86)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [103][330/391]\tTime  0.097 ( 0.094)\tLoss 3.1050e-02 (1.5026e-02)\tAcc@1  99.22 ( 99.84)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [103][360/391]\tTime  0.090 ( 0.094)\tLoss 1.4232e-02 (1.4933e-02)\tAcc@1 100.00 ( 99.84)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [103][390/391]\tTime  0.080 ( 0.094)\tLoss 1.6676e-02 (1.4975e-02)\tAcc@1 100.00 ( 99.84)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.838 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.330 || Acc@5 93.770\n",
            "==> 39.11 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 104, lr: 0.004000000000000001 -----\n",
            "Epoch: [104][  0/391]\tTime  0.290 ( 0.290)\tLoss 1.4321e-02 (1.4321e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [104][ 30/391]\tTime  0.091 ( 0.100)\tLoss 2.3914e-02 (1.3739e-02)\tAcc@1  99.22 ( 99.87)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [104][ 60/391]\tTime  0.091 ( 0.096)\tLoss 1.1094e-02 (1.4779e-02)\tAcc@1 100.00 ( 99.86)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [104][ 90/391]\tTime  0.089 ( 0.095)\tLoss 1.4526e-02 (1.5548e-02)\tAcc@1 100.00 ( 99.85)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [104][120/391]\tTime  0.093 ( 0.095)\tLoss 8.8313e-03 (1.5344e-02)\tAcc@1 100.00 ( 99.85)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [104][150/391]\tTime  0.085 ( 0.094)\tLoss 1.8608e-02 (1.5306e-02)\tAcc@1 100.00 ( 99.85)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [104][180/391]\tTime  0.099 ( 0.094)\tLoss 1.7202e-02 (1.5295e-02)\tAcc@1  99.22 ( 99.84)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [104][210/391]\tTime  0.098 ( 0.094)\tLoss 2.9717e-02 (1.4985e-02)\tAcc@1  98.44 ( 99.84)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [104][240/391]\tTime  0.091 ( 0.094)\tLoss 9.6205e-03 (1.5042e-02)\tAcc@1 100.00 ( 99.85)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [104][270/391]\tTime  0.091 ( 0.094)\tLoss 1.5828e-02 (1.5244e-02)\tAcc@1 100.00 ( 99.84)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [104][300/391]\tTime  0.102 ( 0.094)\tLoss 1.0961e-02 (1.5086e-02)\tAcc@1 100.00 ( 99.85)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [104][330/391]\tTime  0.092 ( 0.093)\tLoss 5.0808e-03 (1.5235e-02)\tAcc@1 100.00 ( 99.84)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [104][360/391]\tTime  0.091 ( 0.093)\tLoss 1.8984e-02 (1.5139e-02)\tAcc@1 100.00 ( 99.85)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [104][390/391]\tTime  0.082 ( 0.093)\tLoss 2.3368e-02 (1.5324e-02)\tAcc@1 100.00 ( 99.84)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.844 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.330 || Acc@5 93.880\n",
            "==> 39.02 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 105, lr: 0.004000000000000001 -----\n",
            "Epoch: [105][  0/391]\tTime  0.299 ( 0.299)\tLoss 1.4975e-02 (1.4975e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [105][ 30/391]\tTime  0.088 ( 0.100)\tLoss 2.1097e-02 (1.3434e-02)\tAcc@1  99.22 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [105][ 60/391]\tTime  0.097 ( 0.097)\tLoss 6.6878e-03 (1.4546e-02)\tAcc@1 100.00 ( 99.87)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [105][ 90/391]\tTime  0.089 ( 0.096)\tLoss 9.1612e-03 (1.4408e-02)\tAcc@1 100.00 ( 99.86)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [105][120/391]\tTime  0.092 ( 0.095)\tLoss 1.4833e-02 (1.4511e-02)\tAcc@1 100.00 ( 99.85)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [105][150/391]\tTime  0.091 ( 0.095)\tLoss 7.4960e-03 (1.4426e-02)\tAcc@1 100.00 ( 99.83)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [105][180/391]\tTime  0.092 ( 0.095)\tLoss 2.4624e-02 (1.4586e-02)\tAcc@1  99.22 ( 99.84)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [105][210/391]\tTime  0.090 ( 0.095)\tLoss 1.1341e-02 (1.4558e-02)\tAcc@1 100.00 ( 99.84)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [105][240/391]\tTime  0.095 ( 0.095)\tLoss 9.8593e-03 (1.4466e-02)\tAcc@1 100.00 ( 99.84)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [105][270/391]\tTime  0.097 ( 0.094)\tLoss 1.3385e-02 (1.4472e-02)\tAcc@1 100.00 ( 99.84)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [105][300/391]\tTime  0.088 ( 0.094)\tLoss 1.1792e-02 (1.4373e-02)\tAcc@1 100.00 ( 99.84)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [105][330/391]\tTime  0.093 ( 0.094)\tLoss 6.1580e-03 (1.4291e-02)\tAcc@1 100.00 ( 99.85)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [105][360/391]\tTime  0.077 ( 0.094)\tLoss 9.7355e-03 (1.4299e-02)\tAcc@1 100.00 ( 99.85)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [105][390/391]\tTime  0.081 ( 0.094)\tLoss 5.5487e-03 (1.4412e-02)\tAcc@1 100.00 ( 99.85)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.846 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.460 || Acc@5 93.770\n",
            "==> 39.23 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 106, lr: 0.004000000000000001 -----\n",
            "Epoch: [106][  0/391]\tTime  0.274 ( 0.274)\tLoss 1.5348e-02 (1.5348e-02)\tAcc@1  99.22 ( 99.22)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [106][ 30/391]\tTime  0.093 ( 0.100)\tLoss 1.2510e-02 (1.5009e-02)\tAcc@1 100.00 ( 99.80)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [106][ 60/391]\tTime  0.094 ( 0.096)\tLoss 8.9411e-03 (1.5174e-02)\tAcc@1 100.00 ( 99.80)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [106][ 90/391]\tTime  0.099 ( 0.095)\tLoss 1.7961e-02 (1.4641e-02)\tAcc@1  99.22 ( 99.80)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [106][120/391]\tTime  0.088 ( 0.094)\tLoss 6.6502e-02 (1.4779e-02)\tAcc@1  97.66 ( 99.80)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [106][150/391]\tTime  0.092 ( 0.094)\tLoss 2.1237e-02 (1.4506e-02)\tAcc@1 100.00 ( 99.81)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [106][180/391]\tTime  0.096 ( 0.094)\tLoss 1.1065e-02 (1.4161e-02)\tAcc@1 100.00 ( 99.83)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [106][210/391]\tTime  0.092 ( 0.094)\tLoss 3.7232e-02 (1.4052e-02)\tAcc@1  98.44 ( 99.84)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [106][240/391]\tTime  0.088 ( 0.094)\tLoss 8.7191e-03 (1.3890e-02)\tAcc@1 100.00 ( 99.85)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [106][270/391]\tTime  0.090 ( 0.093)\tLoss 1.3922e-02 (1.3712e-02)\tAcc@1 100.00 ( 99.86)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [106][300/391]\tTime  0.090 ( 0.093)\tLoss 1.5936e-02 (1.3968e-02)\tAcc@1 100.00 ( 99.85)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [106][330/391]\tTime  0.094 ( 0.093)\tLoss 1.3460e-02 (1.3889e-02)\tAcc@1 100.00 ( 99.86)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [106][360/391]\tTime  0.091 ( 0.093)\tLoss 1.1346e-02 (1.3801e-02)\tAcc@1 100.00 ( 99.87)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [106][390/391]\tTime  0.082 ( 0.093)\tLoss 1.5780e-02 (1.3697e-02)\tAcc@1 100.00 ( 99.87)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.872 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.430 || Acc@5 93.820\n",
            "==> 39.01 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 107, lr: 0.004000000000000001 -----\n",
            "Epoch: [107][  0/391]\tTime  0.292 ( 0.292)\tLoss 7.1068e-03 (7.1068e-03)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [107][ 30/391]\tTime  0.091 ( 0.100)\tLoss 1.7807e-02 (1.3075e-02)\tAcc@1  99.22 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [107][ 60/391]\tTime  0.095 ( 0.097)\tLoss 2.0997e-02 (1.3490e-02)\tAcc@1 100.00 ( 99.86)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [107][ 90/391]\tTime  0.096 ( 0.096)\tLoss 9.6181e-03 (1.3133e-02)\tAcc@1 100.00 ( 99.88)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [107][120/391]\tTime  0.091 ( 0.095)\tLoss 2.4232e-02 (1.3297e-02)\tAcc@1  99.22 ( 99.86)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [107][150/391]\tTime  0.092 ( 0.095)\tLoss 7.3540e-03 (1.3491e-02)\tAcc@1 100.00 ( 99.84)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [107][180/391]\tTime  0.089 ( 0.094)\tLoss 1.0926e-02 (1.3501e-02)\tAcc@1 100.00 ( 99.85)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [107][210/391]\tTime  0.095 ( 0.094)\tLoss 1.0734e-02 (1.3313e-02)\tAcc@1 100.00 ( 99.86)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [107][240/391]\tTime  0.091 ( 0.094)\tLoss 2.7453e-02 (1.3496e-02)\tAcc@1  98.44 ( 99.86)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [107][270/391]\tTime  0.092 ( 0.094)\tLoss 1.6880e-02 (1.3564e-02)\tAcc@1 100.00 ( 99.85)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [107][300/391]\tTime  0.091 ( 0.094)\tLoss 1.4973e-02 (1.3534e-02)\tAcc@1 100.00 ( 99.85)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [107][330/391]\tTime  0.093 ( 0.094)\tLoss 1.0578e-02 (1.3575e-02)\tAcc@1 100.00 ( 99.86)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [107][360/391]\tTime  0.093 ( 0.094)\tLoss 1.0665e-02 (1.3360e-02)\tAcc@1 100.00 ( 99.87)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [107][390/391]\tTime  0.082 ( 0.093)\tLoss 1.0982e-02 (1.3340e-02)\tAcc@1 100.00 ( 99.87)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.870 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.370 || Acc@5 93.880\n",
            "==> 39.02 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 108, lr: 0.004000000000000001 -----\n",
            "Epoch: [108][  0/391]\tTime  0.269 ( 0.269)\tLoss 9.2033e-03 (9.2033e-03)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [108][ 30/391]\tTime  0.094 ( 0.099)\tLoss 8.0200e-03 (1.2440e-02)\tAcc@1 100.00 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [108][ 60/391]\tTime  0.091 ( 0.096)\tLoss 8.8621e-03 (1.2231e-02)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [108][ 90/391]\tTime  0.105 ( 0.095)\tLoss 1.0416e-02 (1.2592e-02)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [108][120/391]\tTime  0.095 ( 0.095)\tLoss 6.4909e-03 (1.2491e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [108][150/391]\tTime  0.093 ( 0.094)\tLoss 5.5522e-03 (1.2556e-02)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [108][180/391]\tTime  0.092 ( 0.094)\tLoss 1.5597e-02 (1.2580e-02)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [108][210/391]\tTime  0.092 ( 0.094)\tLoss 1.6992e-02 (1.2874e-02)\tAcc@1 100.00 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [108][240/391]\tTime  0.092 ( 0.094)\tLoss 1.1036e-02 (1.3142e-02)\tAcc@1 100.00 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [108][270/391]\tTime  0.091 ( 0.094)\tLoss 7.0627e-03 (1.3343e-02)\tAcc@1 100.00 ( 99.89)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [108][300/391]\tTime  0.094 ( 0.094)\tLoss 9.6107e-03 (1.3429e-02)\tAcc@1 100.00 ( 99.89)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [108][330/391]\tTime  0.091 ( 0.094)\tLoss 1.5593e-02 (1.3365e-02)\tAcc@1 100.00 ( 99.89)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [108][360/391]\tTime  0.092 ( 0.094)\tLoss 1.1538e-02 (1.3570e-02)\tAcc@1 100.00 ( 99.89)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [108][390/391]\tTime  0.082 ( 0.094)\tLoss 1.2243e-02 (1.3599e-02)\tAcc@1 100.00 ( 99.88)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.880 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.340 || Acc@5 93.740\n",
            "==> 39.09 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 109, lr: 0.004000000000000001 -----\n",
            "Epoch: [109][  0/391]\tTime  0.285 ( 0.285)\tLoss 1.3605e-02 (1.3605e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [109][ 30/391]\tTime  0.092 ( 0.100)\tLoss 6.4279e-03 (1.0736e-02)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [109][ 60/391]\tTime  0.096 ( 0.096)\tLoss 1.7216e-02 (1.1458e-02)\tAcc@1  99.22 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [109][ 90/391]\tTime  0.089 ( 0.095)\tLoss 5.0425e-03 (1.2286e-02)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [109][120/391]\tTime  0.094 ( 0.095)\tLoss 1.5317e-02 (1.2421e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [109][150/391]\tTime  0.092 ( 0.094)\tLoss 6.8781e-03 (1.2869e-02)\tAcc@1 100.00 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [109][180/391]\tTime  0.090 ( 0.094)\tLoss 5.4152e-03 (1.3150e-02)\tAcc@1 100.00 ( 99.89)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [109][210/391]\tTime  0.078 ( 0.094)\tLoss 1.2801e-02 (1.3311e-02)\tAcc@1 100.00 ( 99.89)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [109][240/391]\tTime  0.098 ( 0.094)\tLoss 4.8729e-03 (1.3353e-02)\tAcc@1 100.00 ( 99.89)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [109][270/391]\tTime  0.101 ( 0.094)\tLoss 7.5190e-03 (1.3209e-02)\tAcc@1 100.00 ( 99.89)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [109][300/391]\tTime  0.090 ( 0.094)\tLoss 1.1831e-02 (1.3410e-02)\tAcc@1 100.00 ( 99.89)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [109][330/391]\tTime  0.085 ( 0.094)\tLoss 1.1392e-02 (1.3446e-02)\tAcc@1 100.00 ( 99.88)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [109][360/391]\tTime  0.090 ( 0.093)\tLoss 1.0043e-02 (1.3464e-02)\tAcc@1 100.00 ( 99.89)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [109][390/391]\tTime  0.082 ( 0.093)\tLoss 3.1083e-02 (1.3476e-02)\tAcc@1 100.00 ( 99.88)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.882 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.050 || Acc@5 93.770\n",
            "==> 39.05 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 110, lr: 0.004000000000000001 -----\n",
            "Epoch: [110][  0/391]\tTime  0.283 ( 0.283)\tLoss 9.6904e-03 (9.6904e-03)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [110][ 30/391]\tTime  0.087 ( 0.101)\tLoss 1.2756e-02 (1.3381e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [110][ 60/391]\tTime  0.092 ( 0.098)\tLoss 1.0247e-02 (1.2905e-02)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [110][ 90/391]\tTime  0.084 ( 0.097)\tLoss 2.5944e-02 (1.2675e-02)\tAcc@1  99.22 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [110][120/391]\tTime  0.094 ( 0.096)\tLoss 9.6089e-03 (1.2167e-02)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [110][150/391]\tTime  0.091 ( 0.095)\tLoss 7.7401e-03 (1.2370e-02)\tAcc@1 100.00 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [110][180/391]\tTime  0.089 ( 0.095)\tLoss 1.4263e-02 (1.2496e-02)\tAcc@1 100.00 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [110][210/391]\tTime  0.088 ( 0.095)\tLoss 1.1508e-02 (1.2718e-02)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [110][240/391]\tTime  0.091 ( 0.094)\tLoss 1.3584e-02 (1.2702e-02)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [110][270/391]\tTime  0.090 ( 0.094)\tLoss 7.9629e-03 (1.2911e-02)\tAcc@1 100.00 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [110][300/391]\tTime  0.094 ( 0.094)\tLoss 1.1680e-02 (1.2854e-02)\tAcc@1 100.00 ( 99.89)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [110][330/391]\tTime  0.098 ( 0.094)\tLoss 1.3523e-02 (1.2867e-02)\tAcc@1 100.00 ( 99.89)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [110][360/391]\tTime  0.091 ( 0.094)\tLoss 1.4167e-02 (1.2952e-02)\tAcc@1 100.00 ( 99.89)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [110][390/391]\tTime  0.082 ( 0.094)\tLoss 1.4034e-02 (1.2876e-02)\tAcc@1 100.00 ( 99.89)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.894 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.520 || Acc@5 93.830\n",
            "==> 39.11 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 111, lr: 0.004000000000000001 -----\n",
            "Epoch: [111][  0/391]\tTime  0.284 ( 0.284)\tLoss 1.2343e-02 (1.2343e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [111][ 30/391]\tTime  0.095 ( 0.102)\tLoss 1.0669e-02 (1.3974e-02)\tAcc@1 100.00 ( 99.85)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [111][ 60/391]\tTime  0.091 ( 0.098)\tLoss 1.8142e-02 (1.4204e-02)\tAcc@1 100.00 ( 99.83)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [111][ 90/391]\tTime  0.105 ( 0.097)\tLoss 1.3258e-02 (1.3618e-02)\tAcc@1  99.22 ( 99.85)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [111][120/391]\tTime  0.091 ( 0.096)\tLoss 1.1593e-02 (1.3278e-02)\tAcc@1 100.00 ( 99.86)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [111][150/391]\tTime  0.089 ( 0.095)\tLoss 4.3504e-02 (1.3310e-02)\tAcc@1  99.22 ( 99.85)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [111][180/391]\tTime  0.091 ( 0.094)\tLoss 1.0671e-02 (1.3260e-02)\tAcc@1 100.00 ( 99.85)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [111][210/391]\tTime  0.082 ( 0.094)\tLoss 9.8498e-03 (1.3387e-02)\tAcc@1 100.00 ( 99.86)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [111][240/391]\tTime  0.094 ( 0.094)\tLoss 8.9103e-03 (1.3538e-02)\tAcc@1 100.00 ( 99.86)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [111][270/391]\tTime  0.095 ( 0.094)\tLoss 1.1491e-02 (1.3524e-02)\tAcc@1 100.00 ( 99.86)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [111][300/391]\tTime  0.092 ( 0.094)\tLoss 1.1705e-02 (1.3581e-02)\tAcc@1 100.00 ( 99.86)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [111][330/391]\tTime  0.093 ( 0.094)\tLoss 5.0619e-03 (1.3413e-02)\tAcc@1 100.00 ( 99.87)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [111][360/391]\tTime  0.096 ( 0.094)\tLoss 7.4502e-03 (1.3420e-02)\tAcc@1 100.00 ( 99.87)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [111][390/391]\tTime  0.082 ( 0.094)\tLoss 2.0011e-02 (1.3445e-02)\tAcc@1 100.00 ( 99.87)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.868 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.450 || Acc@5 93.710\n",
            "==> 39.19 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 112, lr: 0.004000000000000001 -----\n",
            "Epoch: [112][  0/391]\tTime  0.274 ( 0.274)\tLoss 1.0613e-02 (1.0613e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [112][ 30/391]\tTime  0.101 ( 0.101)\tLoss 1.3695e-02 (1.1925e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [112][ 60/391]\tTime  0.096 ( 0.097)\tLoss 1.0369e-02 (1.1662e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [112][ 90/391]\tTime  0.093 ( 0.095)\tLoss 8.4927e-03 (1.1734e-02)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [112][120/391]\tTime  0.093 ( 0.095)\tLoss 1.4535e-02 (1.2125e-02)\tAcc@1 100.00 ( 99.89)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [112][150/391]\tTime  0.093 ( 0.094)\tLoss 9.5094e-03 (1.1887e-02)\tAcc@1 100.00 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [112][180/391]\tTime  0.095 ( 0.094)\tLoss 1.2286e-02 (1.1940e-02)\tAcc@1 100.00 ( 99.89)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [112][210/391]\tTime  0.090 ( 0.094)\tLoss 9.1640e-03 (1.1994e-02)\tAcc@1 100.00 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [112][240/391]\tTime  0.081 ( 0.093)\tLoss 1.5389e-02 (1.2008e-02)\tAcc@1 100.00 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [112][270/391]\tTime  0.090 ( 0.093)\tLoss 1.0926e-02 (1.2235e-02)\tAcc@1 100.00 ( 99.89)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [112][300/391]\tTime  0.106 ( 0.093)\tLoss 8.9807e-03 (1.2227e-02)\tAcc@1 100.00 ( 99.89)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [112][330/391]\tTime  0.094 ( 0.093)\tLoss 6.6770e-03 (1.2131e-02)\tAcc@1 100.00 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [112][360/391]\tTime  0.091 ( 0.093)\tLoss 2.0117e-02 (1.2145e-02)\tAcc@1  99.22 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [112][390/391]\tTime  0.082 ( 0.093)\tLoss 4.5526e-03 (1.2112e-02)\tAcc@1 100.00 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.900 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.550 || Acc@5 93.750\n",
            "==> 38.88 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 113, lr: 0.004000000000000001 -----\n",
            "Epoch: [113][  0/391]\tTime  0.296 ( 0.296)\tLoss 9.0206e-03 (9.0206e-03)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [113][ 30/391]\tTime  0.092 ( 0.100)\tLoss 1.5894e-02 (1.2090e-02)\tAcc@1 100.00 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [113][ 60/391]\tTime  0.098 ( 0.097)\tLoss 9.8494e-03 (1.1596e-02)\tAcc@1 100.00 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [113][ 90/391]\tTime  0.091 ( 0.096)\tLoss 1.0116e-02 (1.1882e-02)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [113][120/391]\tTime  0.083 ( 0.095)\tLoss 1.2310e-02 (1.1861e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [113][150/391]\tTime  0.089 ( 0.095)\tLoss 1.5573e-02 (1.1942e-02)\tAcc@1 100.00 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [113][180/391]\tTime  0.094 ( 0.094)\tLoss 1.3791e-02 (1.1776e-02)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [113][210/391]\tTime  0.092 ( 0.094)\tLoss 1.8630e-02 (1.2033e-02)\tAcc@1  99.22 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [113][240/391]\tTime  0.102 ( 0.094)\tLoss 1.1375e-02 (1.1979e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [113][270/391]\tTime  0.110 ( 0.094)\tLoss 8.1382e-03 (1.1936e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [113][300/391]\tTime  0.104 ( 0.094)\tLoss 1.5484e-02 (1.1820e-02)\tAcc@1 100.00 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [113][330/391]\tTime  0.091 ( 0.094)\tLoss 1.3770e-02 (1.1908e-02)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [113][360/391]\tTime  0.090 ( 0.094)\tLoss 9.7077e-03 (1.1915e-02)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [113][390/391]\tTime  0.082 ( 0.094)\tLoss 2.2597e-02 (1.2006e-02)\tAcc@1  98.75 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.908 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.550 || Acc@5 93.810\n",
            "==> 39.12 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 114, lr: 0.004000000000000001 -----\n",
            "Epoch: [114][  0/391]\tTime  0.290 ( 0.290)\tLoss 1.2603e-02 (1.2603e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [114][ 30/391]\tTime  0.093 ( 0.100)\tLoss 1.3860e-02 (1.0726e-02)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [114][ 60/391]\tTime  0.090 ( 0.096)\tLoss 6.7186e-03 (1.0493e-02)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [114][ 90/391]\tTime  0.094 ( 0.095)\tLoss 1.6181e-02 (1.0478e-02)\tAcc@1  99.22 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [114][120/391]\tTime  0.090 ( 0.095)\tLoss 2.0015e-02 (1.0575e-02)\tAcc@1  99.22 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [114][150/391]\tTime  0.091 ( 0.094)\tLoss 2.9724e-02 (1.0653e-02)\tAcc@1  98.44 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [114][180/391]\tTime  0.093 ( 0.094)\tLoss 1.7258e-02 (1.0918e-02)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [114][210/391]\tTime  0.105 ( 0.094)\tLoss 8.1299e-03 (1.1206e-02)\tAcc@1 100.00 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [114][240/391]\tTime  0.093 ( 0.094)\tLoss 1.2151e-02 (1.1531e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [114][270/391]\tTime  0.094 ( 0.094)\tLoss 9.3782e-03 (1.1577e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [114][300/391]\tTime  0.113 ( 0.094)\tLoss 1.6346e-02 (1.1801e-02)\tAcc@1  99.22 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [114][330/391]\tTime  0.097 ( 0.094)\tLoss 7.7910e-03 (1.2019e-02)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [114][360/391]\tTime  0.104 ( 0.094)\tLoss 7.1876e-03 (1.1958e-02)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [114][390/391]\tTime  0.082 ( 0.094)\tLoss 1.5782e-02 (1.2066e-02)\tAcc@1 100.00 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.898 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 78.020 || Acc@5 93.900\n",
            "==> 39.17 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 115, lr: 0.004000000000000001 -----\n",
            "Epoch: [115][  0/391]\tTime  0.284 ( 0.284)\tLoss 5.6027e-03 (5.6027e-03)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [115][ 30/391]\tTime  0.094 ( 0.101)\tLoss 1.3362e-02 (1.1247e-02)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [115][ 60/391]\tTime  0.095 ( 0.097)\tLoss 1.0723e-02 (1.1230e-02)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [115][ 90/391]\tTime  0.108 ( 0.096)\tLoss 6.7054e-03 (1.1492e-02)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [115][120/391]\tTime  0.093 ( 0.095)\tLoss 7.7452e-03 (1.1608e-02)\tAcc@1 100.00 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [115][150/391]\tTime  0.091 ( 0.095)\tLoss 9.1229e-03 (1.1507e-02)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [115][180/391]\tTime  0.093 ( 0.095)\tLoss 7.7778e-03 (1.1546e-02)\tAcc@1 100.00 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [115][210/391]\tTime  0.090 ( 0.094)\tLoss 2.4176e-02 (1.1586e-02)\tAcc@1  99.22 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [115][240/391]\tTime  0.091 ( 0.094)\tLoss 1.3802e-02 (1.1710e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [115][270/391]\tTime  0.092 ( 0.094)\tLoss 8.7654e-03 (1.1660e-02)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [115][300/391]\tTime  0.091 ( 0.094)\tLoss 1.4720e-02 (1.1667e-02)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [115][330/391]\tTime  0.095 ( 0.094)\tLoss 8.8819e-03 (1.1675e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [115][360/391]\tTime  0.100 ( 0.094)\tLoss 1.1714e-02 (1.1737e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [115][390/391]\tTime  0.082 ( 0.094)\tLoss 2.6002e-02 (1.1877e-02)\tAcc@1  98.75 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.910 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.560 || Acc@5 93.930\n",
            "==> 39.09 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 116, lr: 0.004000000000000001 -----\n",
            "Epoch: [116][  0/391]\tTime  0.276 ( 0.276)\tLoss 1.3959e-02 (1.3959e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [116][ 30/391]\tTime  0.096 ( 0.101)\tLoss 1.5406e-02 (1.1633e-02)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [116][ 60/391]\tTime  0.089 ( 0.097)\tLoss 9.9404e-03 (1.1067e-02)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [116][ 90/391]\tTime  0.093 ( 0.096)\tLoss 1.1470e-02 (1.1448e-02)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [116][120/391]\tTime  0.085 ( 0.095)\tLoss 1.4052e-02 (1.1888e-02)\tAcc@1 100.00 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [116][150/391]\tTime  0.100 ( 0.095)\tLoss 2.5177e-02 (1.1917e-02)\tAcc@1  99.22 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [116][180/391]\tTime  0.109 ( 0.095)\tLoss 9.9428e-03 (1.1764e-02)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [116][210/391]\tTime  0.106 ( 0.095)\tLoss 8.4880e-03 (1.1806e-02)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [116][240/391]\tTime  0.091 ( 0.094)\tLoss 1.4797e-02 (1.2179e-02)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [116][270/391]\tTime  0.095 ( 0.094)\tLoss 2.2190e-02 (1.2326e-02)\tAcc@1  99.22 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [116][300/391]\tTime  0.092 ( 0.094)\tLoss 2.8710e-02 (1.2374e-02)\tAcc@1 100.00 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [116][330/391]\tTime  0.091 ( 0.094)\tLoss 1.3382e-02 (1.2339e-02)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [116][360/391]\tTime  0.104 ( 0.094)\tLoss 2.0483e-02 (1.2383e-02)\tAcc@1  99.22 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [116][390/391]\tTime  0.081 ( 0.094)\tLoss 1.0602e-02 (1.2416e-02)\tAcc@1 100.00 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.898 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.630 || Acc@5 93.900\n",
            "==> 39.25 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 117, lr: 0.004000000000000001 -----\n",
            "Epoch: [117][  0/391]\tTime  0.287 ( 0.287)\tLoss 7.7834e-03 (7.7834e-03)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [117][ 30/391]\tTime  0.092 ( 0.100)\tLoss 1.1655e-02 (1.3342e-02)\tAcc@1 100.00 ( 99.85)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [117][ 60/391]\tTime  0.091 ( 0.097)\tLoss 1.0582e-02 (1.2215e-02)\tAcc@1 100.00 ( 99.88)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [117][ 90/391]\tTime  0.091 ( 0.095)\tLoss 9.2693e-03 (1.1766e-02)\tAcc@1 100.00 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [117][120/391]\tTime  0.077 ( 0.095)\tLoss 8.7239e-03 (1.1604e-02)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [117][150/391]\tTime  0.088 ( 0.094)\tLoss 1.1304e-02 (1.1583e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [117][180/391]\tTime  0.093 ( 0.094)\tLoss 9.8078e-03 (1.1756e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [117][210/391]\tTime  0.097 ( 0.094)\tLoss 1.0935e-02 (1.1760e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [117][240/391]\tTime  0.085 ( 0.094)\tLoss 7.2803e-03 (1.1657e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [117][270/391]\tTime  0.102 ( 0.094)\tLoss 1.3467e-02 (1.1587e-02)\tAcc@1 100.00 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [117][300/391]\tTime  0.092 ( 0.094)\tLoss 1.2309e-02 (1.1712e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [117][330/391]\tTime  0.094 ( 0.094)\tLoss 1.2594e-02 (1.1749e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [117][360/391]\tTime  0.090 ( 0.094)\tLoss 1.3608e-02 (1.1817e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [117][390/391]\tTime  0.082 ( 0.094)\tLoss 1.7067e-02 (1.1826e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.920 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.640 || Acc@5 94.050\n",
            "==> 39.11 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 118, lr: 0.004000000000000001 -----\n",
            "Epoch: [118][  0/391]\tTime  0.304 ( 0.304)\tLoss 8.3225e-03 (8.3225e-03)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [118][ 30/391]\tTime  0.089 ( 0.101)\tLoss 1.8659e-02 (1.1356e-02)\tAcc@1  99.22 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [118][ 60/391]\tTime  0.092 ( 0.097)\tLoss 7.6116e-03 (1.0890e-02)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [118][ 90/391]\tTime  0.091 ( 0.096)\tLoss 7.4334e-03 (1.1701e-02)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [118][120/391]\tTime  0.091 ( 0.095)\tLoss 8.3002e-03 (1.1445e-02)\tAcc@1 100.00 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [118][150/391]\tTime  0.101 ( 0.095)\tLoss 9.4850e-03 (1.1383e-02)\tAcc@1 100.00 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [118][180/391]\tTime  0.095 ( 0.095)\tLoss 1.2006e-02 (1.1483e-02)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [118][210/391]\tTime  0.094 ( 0.094)\tLoss 1.3370e-02 (1.1276e-02)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [118][240/391]\tTime  0.092 ( 0.094)\tLoss 1.3180e-02 (1.1252e-02)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [118][270/391]\tTime  0.110 ( 0.094)\tLoss 1.2463e-02 (1.1404e-02)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [118][300/391]\tTime  0.087 ( 0.094)\tLoss 6.2399e-03 (1.1543e-02)\tAcc@1 100.00 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [118][330/391]\tTime  0.091 ( 0.094)\tLoss 1.3085e-02 (1.1489e-02)\tAcc@1 100.00 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [118][360/391]\tTime  0.095 ( 0.094)\tLoss 1.0526e-02 (1.1634e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [118][390/391]\tTime  0.081 ( 0.094)\tLoss 1.4965e-02 (1.1723e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.916 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.610 || Acc@5 93.800\n",
            "==> 39.15 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 119, lr: 0.004000000000000001 -----\n",
            "Epoch: [119][  0/391]\tTime  0.281 ( 0.281)\tLoss 1.6082e-02 (1.6082e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [119][ 30/391]\tTime  0.103 ( 0.101)\tLoss 1.0183e-02 (1.0799e-02)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [119][ 60/391]\tTime  0.092 ( 0.097)\tLoss 2.0977e-02 (1.2045e-02)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [119][ 90/391]\tTime  0.092 ( 0.095)\tLoss 1.0553e-02 (1.1758e-02)\tAcc@1 100.00 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [119][120/391]\tTime  0.093 ( 0.094)\tLoss 8.7730e-03 (1.1621e-02)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [119][150/391]\tTime  0.091 ( 0.094)\tLoss 7.8830e-03 (1.1384e-02)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [119][180/391]\tTime  0.094 ( 0.094)\tLoss 1.3040e-02 (1.1645e-02)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [119][210/391]\tTime  0.102 ( 0.094)\tLoss 2.7210e-02 (1.1805e-02)\tAcc@1  99.22 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [119][240/391]\tTime  0.080 ( 0.094)\tLoss 8.6772e-03 (1.1629e-02)\tAcc@1 100.00 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [119][270/391]\tTime  0.083 ( 0.094)\tLoss 1.3734e-02 (1.1437e-02)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [119][300/391]\tTime  0.092 ( 0.094)\tLoss 9.1551e-03 (1.1455e-02)\tAcc@1 100.00 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [119][330/391]\tTime  0.089 ( 0.094)\tLoss 9.9624e-03 (1.1587e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [119][360/391]\tTime  0.089 ( 0.094)\tLoss 7.4248e-03 (1.1684e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [119][390/391]\tTime  0.082 ( 0.094)\tLoss 2.0679e-02 (1.1632e-02)\tAcc@1  98.75 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.918 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.800 || Acc@5 93.900\n",
            "==> 39.11 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 120, lr: 0.0008000000000000003 -----\n",
            "Epoch: [120][  0/391]\tTime  0.290 ( 0.290)\tLoss 5.2674e-03 (5.2674e-03)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [120][ 30/391]\tTime  0.091 ( 0.100)\tLoss 7.2945e-03 (1.0594e-02)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [120][ 60/391]\tTime  0.080 ( 0.097)\tLoss 1.5124e-02 (1.0265e-02)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [120][ 90/391]\tTime  0.094 ( 0.095)\tLoss 9.3111e-03 (1.0690e-02)\tAcc@1 100.00 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [120][120/391]\tTime  0.094 ( 0.094)\tLoss 6.8420e-03 (1.0773e-02)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [120][150/391]\tTime  0.091 ( 0.094)\tLoss 6.0834e-03 (1.0602e-02)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [120][180/391]\tTime  0.091 ( 0.094)\tLoss 1.2736e-02 (1.0762e-02)\tAcc@1 100.00 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [120][210/391]\tTime  0.091 ( 0.094)\tLoss 7.4803e-03 (1.0883e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [120][240/391]\tTime  0.091 ( 0.094)\tLoss 9.1173e-03 (1.1037e-02)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [120][270/391]\tTime  0.088 ( 0.094)\tLoss 2.7646e-02 (1.1042e-02)\tAcc@1  99.22 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [120][300/391]\tTime  0.089 ( 0.094)\tLoss 8.1049e-03 (1.0916e-02)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [120][330/391]\tTime  0.093 ( 0.094)\tLoss 1.1220e-02 (1.0765e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [120][360/391]\tTime  0.093 ( 0.094)\tLoss 9.2393e-03 (1.0703e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [120][390/391]\tTime  0.082 ( 0.093)\tLoss 1.2084e-02 (1.0637e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.920 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.810 || Acc@5 93.840\n",
            "==> 39.08 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 121, lr: 0.0008000000000000003 -----\n",
            "Epoch: [121][  0/391]\tTime  0.290 ( 0.290)\tLoss 7.3617e-03 (7.3617e-03)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [121][ 30/391]\tTime  0.092 ( 0.101)\tLoss 5.2293e-03 (1.0423e-02)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [121][ 60/391]\tTime  0.102 ( 0.097)\tLoss 9.8472e-03 (1.0276e-02)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [121][ 90/391]\tTime  0.092 ( 0.096)\tLoss 8.8894e-03 (1.0265e-02)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [121][120/391]\tTime  0.097 ( 0.095)\tLoss 1.0444e-02 (1.0218e-02)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [121][150/391]\tTime  0.094 ( 0.095)\tLoss 8.7297e-03 (1.0212e-02)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [121][180/391]\tTime  0.091 ( 0.095)\tLoss 6.5137e-03 (9.9835e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [121][210/391]\tTime  0.091 ( 0.094)\tLoss 8.1375e-03 (1.0014e-02)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [121][240/391]\tTime  0.086 ( 0.094)\tLoss 6.6002e-03 (1.0121e-02)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [121][270/391]\tTime  0.084 ( 0.094)\tLoss 9.3692e-03 (1.0192e-02)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [121][300/391]\tTime  0.092 ( 0.094)\tLoss 6.2253e-03 (1.0416e-02)\tAcc@1 100.00 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [121][330/391]\tTime  0.096 ( 0.094)\tLoss 1.1029e-02 (1.0393e-02)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [121][360/391]\tTime  0.091 ( 0.094)\tLoss 5.9164e-03 (1.0343e-02)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [121][390/391]\tTime  0.082 ( 0.094)\tLoss 8.1152e-03 (1.0295e-02)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.944 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.940 || Acc@5 93.840\n",
            "==> 39.07 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 122, lr: 0.0008000000000000003 -----\n",
            "Epoch: [122][  0/391]\tTime  0.284 ( 0.284)\tLoss 1.1907e-02 (1.1907e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [122][ 30/391]\tTime  0.091 ( 0.102)\tLoss 1.1614e-02 (1.1028e-02)\tAcc@1 100.00 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [122][ 60/391]\tTime  0.088 ( 0.099)\tLoss 8.5441e-03 (1.0579e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [122][ 90/391]\tTime  0.094 ( 0.098)\tLoss 1.8098e-02 (1.0622e-02)\tAcc@1  99.22 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [122][120/391]\tTime  0.083 ( 0.097)\tLoss 6.2572e-03 (1.0528e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [122][150/391]\tTime  0.094 ( 0.097)\tLoss 5.9171e-03 (1.0337e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [122][180/391]\tTime  0.096 ( 0.096)\tLoss 8.9649e-03 (1.0358e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [122][210/391]\tTime  0.091 ( 0.096)\tLoss 1.0097e-02 (1.0375e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [122][240/391]\tTime  0.088 ( 0.096)\tLoss 6.4396e-03 (1.0415e-02)\tAcc@1 100.00 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [122][270/391]\tTime  0.088 ( 0.096)\tLoss 7.9187e-03 (1.0448e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [122][300/391]\tTime  0.107 ( 0.096)\tLoss 1.3565e-02 (1.0397e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [122][330/391]\tTime  0.093 ( 0.096)\tLoss 8.5453e-03 (1.0320e-02)\tAcc@1 100.00 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [122][360/391]\tTime  0.085 ( 0.096)\tLoss 1.0524e-02 (1.0341e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [122][390/391]\tTime  0.082 ( 0.096)\tLoss 1.3607e-02 (1.0304e-02)\tAcc@1 100.00 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.928 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 78.060 || Acc@5 93.890\n",
            "==> 40.26 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 123, lr: 0.0008000000000000003 -----\n",
            "Epoch: [123][  0/391]\tTime  0.303 ( 0.303)\tLoss 6.7575e-03 (6.7575e-03)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [123][ 30/391]\tTime  0.077 ( 0.104)\tLoss 9.5035e-03 (9.8612e-03)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [123][ 60/391]\tTime  0.088 ( 0.100)\tLoss 9.5274e-03 (9.2510e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [123][ 90/391]\tTime  0.097 ( 0.099)\tLoss 9.9352e-03 (9.8867e-03)\tAcc@1 100.00 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [123][120/391]\tTime  0.095 ( 0.098)\tLoss 6.3404e-03 (9.7839e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [123][150/391]\tTime  0.092 ( 0.097)\tLoss 4.3189e-03 (9.8797e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [123][180/391]\tTime  0.086 ( 0.097)\tLoss 7.0053e-03 (9.8947e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [123][210/391]\tTime  0.092 ( 0.096)\tLoss 7.0375e-03 (1.0056e-02)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [123][240/391]\tTime  0.091 ( 0.096)\tLoss 1.3451e-02 (1.0192e-02)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [123][270/391]\tTime  0.098 ( 0.096)\tLoss 1.0272e-02 (1.0122e-02)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [123][300/391]\tTime  0.095 ( 0.096)\tLoss 6.1138e-03 (1.0072e-02)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [123][330/391]\tTime  0.091 ( 0.096)\tLoss 5.2053e-03 (1.0011e-02)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [123][360/391]\tTime  0.084 ( 0.096)\tLoss 8.3392e-03 (1.0047e-02)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [123][390/391]\tTime  0.082 ( 0.096)\tLoss 8.7010e-03 (9.9554e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.950 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 78.050 || Acc@5 93.930\n",
            "==> 40.25 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 124, lr: 0.0008000000000000003 -----\n",
            "Epoch: [124][  0/391]\tTime  0.284 ( 0.284)\tLoss 8.0913e-03 (8.0913e-03)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [124][ 30/391]\tTime  0.102 ( 0.104)\tLoss 1.1280e-02 (9.6860e-03)\tAcc@1  99.22 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [124][ 60/391]\tTime  0.107 ( 0.100)\tLoss 8.1165e-03 (9.6779e-03)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [124][ 90/391]\tTime  0.094 ( 0.098)\tLoss 6.8219e-03 (9.8316e-03)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [124][120/391]\tTime  0.104 ( 0.098)\tLoss 6.9600e-03 (9.9748e-03)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [124][150/391]\tTime  0.094 ( 0.097)\tLoss 8.0314e-03 (1.0103e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [124][180/391]\tTime  0.105 ( 0.097)\tLoss 8.6959e-03 (9.8419e-03)\tAcc@1 100.00 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [124][210/391]\tTime  0.093 ( 0.096)\tLoss 1.0352e-02 (9.9747e-03)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [124][240/391]\tTime  0.097 ( 0.096)\tLoss 1.5273e-02 (9.9760e-03)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [124][270/391]\tTime  0.094 ( 0.096)\tLoss 1.8185e-02 (1.0019e-02)\tAcc@1 100.00 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [124][300/391]\tTime  0.099 ( 0.096)\tLoss 7.6452e-03 (9.9053e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [124][330/391]\tTime  0.092 ( 0.096)\tLoss 8.6785e-03 (9.8339e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [124][360/391]\tTime  0.098 ( 0.096)\tLoss 9.8941e-03 (9.8511e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [124][390/391]\tTime  0.082 ( 0.096)\tLoss 8.8482e-03 (9.7237e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.940 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.910 || Acc@5 93.910\n",
            "==> 39.94 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 125, lr: 0.0008000000000000003 -----\n",
            "Epoch: [125][  0/391]\tTime  0.300 ( 0.300)\tLoss 7.1949e-03 (7.1949e-03)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [125][ 30/391]\tTime  0.097 ( 0.102)\tLoss 1.1217e-02 (9.9866e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [125][ 60/391]\tTime  0.094 ( 0.098)\tLoss 7.3113e-03 (1.0192e-02)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [125][ 90/391]\tTime  0.093 ( 0.097)\tLoss 6.9951e-03 (9.7735e-03)\tAcc@1 100.00 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [125][120/391]\tTime  0.091 ( 0.096)\tLoss 6.0828e-03 (1.0412e-02)\tAcc@1 100.00 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [125][150/391]\tTime  0.092 ( 0.095)\tLoss 6.4738e-03 (1.0457e-02)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [125][180/391]\tTime  0.090 ( 0.095)\tLoss 1.0492e-02 (1.0250e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [125][210/391]\tTime  0.091 ( 0.095)\tLoss 9.3610e-03 (1.0162e-02)\tAcc@1 100.00 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [125][240/391]\tTime  0.090 ( 0.094)\tLoss 1.9503e-02 (1.0099e-02)\tAcc@1  99.22 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [125][270/391]\tTime  0.089 ( 0.094)\tLoss 1.1606e-02 (1.0122e-02)\tAcc@1 100.00 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [125][300/391]\tTime  0.082 ( 0.094)\tLoss 8.1625e-03 (1.0055e-02)\tAcc@1 100.00 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [125][330/391]\tTime  0.082 ( 0.094)\tLoss 1.5590e-02 (1.0089e-02)\tAcc@1  99.22 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [125][360/391]\tTime  0.104 ( 0.094)\tLoss 1.1109e-02 (1.0173e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [125][390/391]\tTime  0.082 ( 0.094)\tLoss 1.2779e-02 (1.0046e-02)\tAcc@1 100.00 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.928 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.890 || Acc@5 93.960\n",
            "==> 39.33 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 126, lr: 0.0008000000000000003 -----\n",
            "Epoch: [126][  0/391]\tTime  0.287 ( 0.287)\tLoss 9.8072e-03 (9.8072e-03)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [126][ 30/391]\tTime  0.100 ( 0.101)\tLoss 6.6527e-03 (9.4559e-03)\tAcc@1 100.00 ( 99.87)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [126][ 60/391]\tTime  0.101 ( 0.097)\tLoss 1.2911e-02 (9.4172e-03)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [126][ 90/391]\tTime  0.086 ( 0.095)\tLoss 1.0431e-02 (9.6532e-03)\tAcc@1 100.00 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [126][120/391]\tTime  0.092 ( 0.095)\tLoss 1.1073e-02 (9.6803e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [126][150/391]\tTime  0.092 ( 0.094)\tLoss 5.0732e-03 (9.6712e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [126][180/391]\tTime  0.091 ( 0.094)\tLoss 9.3881e-03 (9.8316e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [126][210/391]\tTime  0.094 ( 0.094)\tLoss 1.0215e-02 (9.7210e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [126][240/391]\tTime  0.086 ( 0.094)\tLoss 5.7194e-03 (9.7002e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [126][270/391]\tTime  0.091 ( 0.094)\tLoss 1.3718e-02 (9.8553e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [126][300/391]\tTime  0.093 ( 0.094)\tLoss 6.2514e-03 (9.8394e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [126][330/391]\tTime  0.086 ( 0.094)\tLoss 7.6761e-03 (9.7673e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [126][360/391]\tTime  0.090 ( 0.094)\tLoss 9.3894e-03 (9.8179e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [126][390/391]\tTime  0.082 ( 0.094)\tLoss 8.4854e-03 (9.9313e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.956 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 78.010 || Acc@5 93.960\n",
            "==> 39.10 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 127, lr: 0.0008000000000000003 -----\n",
            "Epoch: [127][  0/391]\tTime  0.274 ( 0.274)\tLoss 1.4660e-02 (1.4660e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [127][ 30/391]\tTime  0.097 ( 0.100)\tLoss 7.2345e-03 (9.2914e-03)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [127][ 60/391]\tTime  0.093 ( 0.096)\tLoss 7.6105e-03 (1.0167e-02)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [127][ 90/391]\tTime  0.089 ( 0.095)\tLoss 8.2725e-03 (9.8503e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [127][120/391]\tTime  0.091 ( 0.095)\tLoss 5.7916e-03 (9.8919e-03)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [127][150/391]\tTime  0.097 ( 0.095)\tLoss 5.9045e-03 (9.6443e-03)\tAcc@1 100.00 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [127][180/391]\tTime  0.097 ( 0.095)\tLoss 6.0573e-03 (9.5324e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [127][210/391]\tTime  0.098 ( 0.095)\tLoss 1.2550e-02 (9.5627e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [127][240/391]\tTime  0.094 ( 0.094)\tLoss 1.5232e-02 (9.5958e-03)\tAcc@1  99.22 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [127][270/391]\tTime  0.101 ( 0.094)\tLoss 6.0955e-03 (9.5491e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [127][300/391]\tTime  0.094 ( 0.094)\tLoss 8.4936e-03 (9.5595e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [127][330/391]\tTime  0.094 ( 0.094)\tLoss 1.0302e-02 (9.5274e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [127][360/391]\tTime  0.098 ( 0.094)\tLoss 1.6639e-02 (9.6134e-03)\tAcc@1  99.22 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [127][390/391]\tTime  0.082 ( 0.094)\tLoss 1.0639e-02 (9.6410e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.940 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.950 || Acc@5 93.870\n",
            "==> 39.16 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 128, lr: 0.0008000000000000003 -----\n",
            "Epoch: [128][  0/391]\tTime  0.276 ( 0.276)\tLoss 9.4817e-03 (9.4817e-03)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [128][ 30/391]\tTime  0.093 ( 0.101)\tLoss 7.2057e-03 (9.0825e-03)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [128][ 60/391]\tTime  0.090 ( 0.098)\tLoss 7.3235e-03 (9.1457e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [128][ 90/391]\tTime  0.103 ( 0.096)\tLoss 7.3406e-03 (9.4492e-03)\tAcc@1 100.00 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [128][120/391]\tTime  0.091 ( 0.095)\tLoss 8.5535e-03 (9.2707e-03)\tAcc@1 100.00 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [128][150/391]\tTime  0.094 ( 0.095)\tLoss 6.1095e-03 (9.1948e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [128][180/391]\tTime  0.094 ( 0.094)\tLoss 9.3462e-03 (9.1792e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [128][210/391]\tTime  0.090 ( 0.094)\tLoss 1.0865e-02 (9.2596e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [128][240/391]\tTime  0.092 ( 0.094)\tLoss 1.6019e-02 (9.3441e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [128][270/391]\tTime  0.095 ( 0.094)\tLoss 6.7901e-03 (9.4276e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [128][300/391]\tTime  0.094 ( 0.094)\tLoss 8.1380e-03 (9.5066e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [128][330/391]\tTime  0.093 ( 0.094)\tLoss 7.4329e-03 (9.5807e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [128][360/391]\tTime  0.094 ( 0.094)\tLoss 7.0533e-03 (9.5554e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [128][390/391]\tTime  0.082 ( 0.094)\tLoss 1.6957e-02 (9.5922e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.954 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.960 || Acc@5 93.960\n",
            "==> 39.12 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 129, lr: 0.0008000000000000003 -----\n",
            "Epoch: [129][  0/391]\tTime  0.308 ( 0.308)\tLoss 2.3086e-02 (2.3086e-02)\tAcc@1  99.22 ( 99.22)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [129][ 30/391]\tTime  0.092 ( 0.102)\tLoss 6.1458e-03 (9.5940e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [129][ 60/391]\tTime  0.105 ( 0.098)\tLoss 8.8725e-03 (1.0111e-02)\tAcc@1 100.00 ( 99.88)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [129][ 90/391]\tTime  0.090 ( 0.096)\tLoss 6.6060e-03 (9.7987e-03)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [129][120/391]\tTime  0.093 ( 0.095)\tLoss 7.7788e-03 (9.8126e-03)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [129][150/391]\tTime  0.085 ( 0.095)\tLoss 1.1311e-02 (9.6703e-03)\tAcc@1 100.00 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [129][180/391]\tTime  0.088 ( 0.094)\tLoss 1.0300e-02 (9.5164e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [129][210/391]\tTime  0.097 ( 0.094)\tLoss 9.2776e-03 (9.5234e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [129][240/391]\tTime  0.088 ( 0.094)\tLoss 7.2408e-03 (9.4741e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [129][270/391]\tTime  0.094 ( 0.094)\tLoss 6.9023e-03 (9.5196e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [129][300/391]\tTime  0.081 ( 0.094)\tLoss 6.8666e-03 (9.6502e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [129][330/391]\tTime  0.110 ( 0.094)\tLoss 9.7347e-03 (9.7554e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [129][360/391]\tTime  0.091 ( 0.094)\tLoss 8.7399e-03 (9.6873e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [129][390/391]\tTime  0.083 ( 0.094)\tLoss 8.4869e-03 (9.7634e-03)\tAcc@1 100.00 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.932 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.920 || Acc@5 93.960\n",
            "==> 39.16 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 130, lr: 0.0008000000000000003 -----\n",
            "Epoch: [130][  0/391]\tTime  0.274 ( 0.274)\tLoss 1.2678e-02 (1.2678e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [130][ 30/391]\tTime  0.089 ( 0.100)\tLoss 1.0075e-02 (9.0966e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [130][ 60/391]\tTime  0.092 ( 0.097)\tLoss 7.1386e-03 (9.2354e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [130][ 90/391]\tTime  0.090 ( 0.096)\tLoss 7.1074e-03 (8.9644e-03)\tAcc@1 100.00 ( 99.98)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [130][120/391]\tTime  0.093 ( 0.095)\tLoss 1.2435e-02 (9.0013e-03)\tAcc@1 100.00 ( 99.98)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [130][150/391]\tTime  0.084 ( 0.095)\tLoss 7.3185e-03 (8.9824e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [130][180/391]\tTime  0.101 ( 0.094)\tLoss 8.0936e-03 (9.1525e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [130][210/391]\tTime  0.088 ( 0.094)\tLoss 9.9795e-03 (9.3159e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [130][240/391]\tTime  0.093 ( 0.094)\tLoss 6.8386e-03 (9.2427e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [130][270/391]\tTime  0.099 ( 0.094)\tLoss 8.2159e-03 (9.2611e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [130][300/391]\tTime  0.089 ( 0.094)\tLoss 9.1976e-03 (9.4403e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [130][330/391]\tTime  0.092 ( 0.094)\tLoss 8.3297e-03 (9.4195e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [130][360/391]\tTime  0.091 ( 0.094)\tLoss 9.6570e-03 (9.4425e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [130][390/391]\tTime  0.082 ( 0.094)\tLoss 9.0020e-03 (9.5812e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.954 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 78.040 || Acc@5 94.030\n",
            "==> 39.11 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 131, lr: 0.0008000000000000003 -----\n",
            "Epoch: [131][  0/391]\tTime  0.294 ( 0.294)\tLoss 7.8605e-03 (7.8605e-03)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [131][ 30/391]\tTime  0.112 ( 0.101)\tLoss 6.4085e-03 (1.0268e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [131][ 60/391]\tTime  0.092 ( 0.097)\tLoss 1.1270e-02 (9.5632e-03)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [131][ 90/391]\tTime  0.090 ( 0.095)\tLoss 8.7269e-03 (9.3848e-03)\tAcc@1 100.00 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [131][120/391]\tTime  0.094 ( 0.095)\tLoss 7.9329e-03 (9.6269e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [131][150/391]\tTime  0.094 ( 0.094)\tLoss 6.8450e-03 (9.5433e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [131][180/391]\tTime  0.090 ( 0.094)\tLoss 5.6514e-03 (9.5016e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [131][210/391]\tTime  0.098 ( 0.094)\tLoss 8.8807e-03 (9.4960e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [131][240/391]\tTime  0.089 ( 0.094)\tLoss 9.1038e-03 (9.6265e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [131][270/391]\tTime  0.090 ( 0.094)\tLoss 1.3292e-02 (9.7024e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [131][300/391]\tTime  0.093 ( 0.094)\tLoss 6.3831e-03 (9.7453e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [131][330/391]\tTime  0.092 ( 0.093)\tLoss 1.0065e-02 (9.7517e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [131][360/391]\tTime  0.090 ( 0.093)\tLoss 2.5966e-02 (9.7167e-03)\tAcc@1  99.22 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [131][390/391]\tTime  0.081 ( 0.093)\tLoss 9.5946e-03 (9.7437e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.940 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 78.000 || Acc@5 93.960\n",
            "==> 38.98 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 132, lr: 0.0008000000000000003 -----\n",
            "Epoch: [132][  0/391]\tTime  0.288 ( 0.288)\tLoss 1.4112e-02 (1.4112e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [132][ 30/391]\tTime  0.089 ( 0.102)\tLoss 1.7949e-02 (9.0302e-03)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [132][ 60/391]\tTime  0.091 ( 0.098)\tLoss 1.0360e-02 (9.2285e-03)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [132][ 90/391]\tTime  0.096 ( 0.096)\tLoss 1.1375e-02 (9.3415e-03)\tAcc@1 100.00 ( 99.98)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [132][120/391]\tTime  0.106 ( 0.096)\tLoss 6.7119e-03 (9.3744e-03)\tAcc@1 100.00 ( 99.98)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [132][150/391]\tTime  0.093 ( 0.095)\tLoss 8.8843e-03 (9.3919e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [132][180/391]\tTime  0.090 ( 0.095)\tLoss 1.4758e-02 (9.3050e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [132][210/391]\tTime  0.092 ( 0.095)\tLoss 1.1606e-02 (9.4541e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [132][240/391]\tTime  0.092 ( 0.094)\tLoss 6.1862e-03 (9.5388e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [132][270/391]\tTime  0.087 ( 0.094)\tLoss 1.2799e-02 (9.5502e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [132][300/391]\tTime  0.089 ( 0.094)\tLoss 7.1466e-03 (9.5820e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [132][330/391]\tTime  0.104 ( 0.094)\tLoss 9.2323e-03 (9.4872e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [132][360/391]\tTime  0.091 ( 0.094)\tLoss 2.7543e-02 (9.6566e-03)\tAcc@1  99.22 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [132][390/391]\tTime  0.083 ( 0.094)\tLoss 1.5483e-02 (9.6790e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.954 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.960 || Acc@5 94.000\n",
            "==> 39.34 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 133, lr: 0.0008000000000000003 -----\n",
            "Epoch: [133][  0/391]\tTime  0.294 ( 0.294)\tLoss 6.5691e-03 (6.5691e-03)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [133][ 30/391]\tTime  0.084 ( 0.102)\tLoss 8.8237e-03 (9.4743e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [133][ 60/391]\tTime  0.091 ( 0.098)\tLoss 5.9645e-03 (9.6255e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [133][ 90/391]\tTime  0.086 ( 0.096)\tLoss 5.3674e-03 (9.4683e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [133][120/391]\tTime  0.094 ( 0.096)\tLoss 9.0833e-03 (9.4725e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [133][150/391]\tTime  0.091 ( 0.096)\tLoss 1.5712e-02 (9.3755e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [133][180/391]\tTime  0.081 ( 0.096)\tLoss 1.5382e-02 (9.4137e-03)\tAcc@1  99.22 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [133][210/391]\tTime  0.095 ( 0.096)\tLoss 8.5193e-03 (9.4265e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [133][240/391]\tTime  0.098 ( 0.096)\tLoss 9.6031e-03 (9.3896e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [133][270/391]\tTime  0.112 ( 0.096)\tLoss 9.4359e-03 (9.3873e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [133][300/391]\tTime  0.089 ( 0.096)\tLoss 1.1584e-02 (9.4718e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [133][330/391]\tTime  0.092 ( 0.096)\tLoss 2.6606e-02 (9.5182e-03)\tAcc@1  99.22 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [133][360/391]\tTime  0.103 ( 0.096)\tLoss 8.2844e-03 (9.4883e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [133][390/391]\tTime  0.083 ( 0.096)\tLoss 9.4924e-03 (9.4400e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.952 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.910 || Acc@5 94.070\n",
            "==> 39.89 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 134, lr: 0.0008000000000000003 -----\n",
            "Epoch: [134][  0/391]\tTime  0.284 ( 0.284)\tLoss 5.2763e-03 (5.2763e-03)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [134][ 30/391]\tTime  0.097 ( 0.101)\tLoss 6.4586e-03 (9.2786e-03)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [134][ 60/391]\tTime  0.099 ( 0.097)\tLoss 1.5892e-02 (9.7120e-03)\tAcc@1  99.22 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [134][ 90/391]\tTime  0.091 ( 0.096)\tLoss 8.9352e-03 (9.7569e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [134][120/391]\tTime  0.099 ( 0.096)\tLoss 6.9162e-03 (9.5667e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [134][150/391]\tTime  0.097 ( 0.096)\tLoss 7.2485e-03 (9.5103e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [134][180/391]\tTime  0.107 ( 0.096)\tLoss 6.1072e-03 (9.4513e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [134][210/391]\tTime  0.094 ( 0.095)\tLoss 6.9627e-03 (9.5921e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [134][240/391]\tTime  0.092 ( 0.095)\tLoss 5.2087e-03 (9.5435e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [134][270/391]\tTime  0.086 ( 0.095)\tLoss 5.7411e-03 (9.5312e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [134][300/391]\tTime  0.090 ( 0.095)\tLoss 2.2892e-02 (9.4958e-03)\tAcc@1  99.22 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [134][330/391]\tTime  0.088 ( 0.095)\tLoss 6.2637e-03 (9.4535e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [134][360/391]\tTime  0.089 ( 0.095)\tLoss 7.0777e-03 (9.3994e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [134][390/391]\tTime  0.082 ( 0.095)\tLoss 1.3889e-02 (9.3753e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.950 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 78.020 || Acc@5 94.020\n",
            "==> 39.53 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 135, lr: 0.0008000000000000003 -----\n",
            "Epoch: [135][  0/391]\tTime  0.294 ( 0.294)\tLoss 8.6508e-03 (8.6508e-03)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [135][ 30/391]\tTime  0.098 ( 0.102)\tLoss 7.2574e-03 (9.9693e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [135][ 60/391]\tTime  0.084 ( 0.098)\tLoss 1.0868e-02 (9.3654e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [135][ 90/391]\tTime  0.104 ( 0.097)\tLoss 1.3842e-02 (9.4353e-03)\tAcc@1  99.22 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [135][120/391]\tTime  0.108 ( 0.097)\tLoss 8.7312e-03 (9.4833e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [135][150/391]\tTime  0.099 ( 0.096)\tLoss 9.5571e-03 (9.3049e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [135][180/391]\tTime  0.099 ( 0.096)\tLoss 8.2633e-03 (9.1373e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [135][210/391]\tTime  0.098 ( 0.095)\tLoss 8.9779e-03 (9.2286e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [135][240/391]\tTime  0.092 ( 0.095)\tLoss 1.0094e-02 (9.2855e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [135][270/391]\tTime  0.090 ( 0.095)\tLoss 8.5130e-03 (9.2689e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [135][300/391]\tTime  0.086 ( 0.095)\tLoss 7.0672e-03 (9.2593e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [135][330/391]\tTime  0.092 ( 0.095)\tLoss 9.6612e-03 (9.2483e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [135][360/391]\tTime  0.093 ( 0.095)\tLoss 6.4888e-03 (9.2266e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [135][390/391]\tTime  0.082 ( 0.094)\tLoss 7.9244e-03 (9.2557e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.960 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.920 || Acc@5 93.940\n",
            "==> 39.46 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 136, lr: 0.0008000000000000003 -----\n",
            "Epoch: [136][  0/391]\tTime  0.279 ( 0.279)\tLoss 1.2887e-02 (1.2887e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [136][ 30/391]\tTime  0.090 ( 0.101)\tLoss 7.3859e-03 (8.7841e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [136][ 60/391]\tTime  0.094 ( 0.097)\tLoss 1.2908e-02 (8.4803e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [136][ 90/391]\tTime  0.097 ( 0.096)\tLoss 6.9201e-03 (8.8459e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [136][120/391]\tTime  0.091 ( 0.096)\tLoss 6.8993e-03 (9.0610e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [136][150/391]\tTime  0.096 ( 0.095)\tLoss 8.4717e-03 (9.0306e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [136][180/391]\tTime  0.078 ( 0.095)\tLoss 7.8172e-03 (9.0614e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [136][210/391]\tTime  0.091 ( 0.095)\tLoss 1.1205e-02 (9.0999e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [136][240/391]\tTime  0.101 ( 0.095)\tLoss 1.2133e-02 (9.1786e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [136][270/391]\tTime  0.091 ( 0.095)\tLoss 1.1426e-02 (9.2392e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [136][300/391]\tTime  0.093 ( 0.095)\tLoss 8.0713e-03 (9.3264e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [136][330/391]\tTime  0.092 ( 0.095)\tLoss 1.1224e-02 (9.4402e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [136][360/391]\tTime  0.093 ( 0.095)\tLoss 6.6606e-03 (9.3022e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [136][390/391]\tTime  0.082 ( 0.095)\tLoss 8.1341e-03 (9.2664e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.958 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.930 || Acc@5 93.920\n",
            "==> 39.59 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 137, lr: 0.0008000000000000003 -----\n",
            "Epoch: [137][  0/391]\tTime  0.296 ( 0.296)\tLoss 7.1590e-03 (7.1590e-03)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [137][ 30/391]\tTime  0.091 ( 0.102)\tLoss 5.5900e-03 (9.3027e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [137][ 60/391]\tTime  0.092 ( 0.098)\tLoss 8.5482e-03 (9.0775e-03)\tAcc@1 100.00 ( 99.99)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [137][ 90/391]\tTime  0.093 ( 0.097)\tLoss 9.2058e-03 (9.1207e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [137][120/391]\tTime  0.108 ( 0.096)\tLoss 5.0942e-03 (9.1094e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [137][150/391]\tTime  0.097 ( 0.096)\tLoss 2.0535e-02 (9.0722e-03)\tAcc@1  99.22 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [137][180/391]\tTime  0.095 ( 0.096)\tLoss 9.3799e-03 (9.2492e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [137][210/391]\tTime  0.092 ( 0.096)\tLoss 4.8702e-03 (9.0978e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [137][240/391]\tTime  0.099 ( 0.096)\tLoss 9.1419e-03 (9.2535e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [137][270/391]\tTime  0.107 ( 0.096)\tLoss 8.4642e-03 (9.2763e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [137][300/391]\tTime  0.096 ( 0.096)\tLoss 1.2149e-02 (9.3513e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [137][330/391]\tTime  0.090 ( 0.096)\tLoss 5.7656e-03 (9.3823e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [137][360/391]\tTime  0.095 ( 0.096)\tLoss 7.4794e-03 (9.5128e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [137][390/391]\tTime  0.081 ( 0.096)\tLoss 1.0055e-02 (9.4985e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.942 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.950 || Acc@5 93.950\n",
            "==> 40.16 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 138, lr: 0.0008000000000000003 -----\n",
            "Epoch: [138][  0/391]\tTime  0.317 ( 0.317)\tLoss 1.2319e-02 (1.2319e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [138][ 30/391]\tTime  0.101 ( 0.105)\tLoss 1.0682e-02 (1.0035e-02)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [138][ 60/391]\tTime  0.100 ( 0.101)\tLoss 1.0658e-02 (1.0304e-02)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [138][ 90/391]\tTime  0.096 ( 0.099)\tLoss 7.6215e-03 (9.8966e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [138][120/391]\tTime  0.087 ( 0.099)\tLoss 9.2267e-03 (9.8386e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [138][150/391]\tTime  0.086 ( 0.098)\tLoss 8.3572e-03 (1.0067e-02)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [138][180/391]\tTime  0.092 ( 0.098)\tLoss 9.9145e-03 (9.9448e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [138][210/391]\tTime  0.083 ( 0.098)\tLoss 5.9333e-03 (9.7889e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [138][240/391]\tTime  0.094 ( 0.098)\tLoss 6.8668e-03 (9.7923e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [138][270/391]\tTime  0.099 ( 0.098)\tLoss 8.2927e-03 (9.7024e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [138][300/391]\tTime  0.105 ( 0.097)\tLoss 7.3944e-03 (9.6856e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [138][330/391]\tTime  0.111 ( 0.097)\tLoss 1.0971e-02 (9.8272e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [138][360/391]\tTime  0.110 ( 0.097)\tLoss 5.0841e-03 (9.8058e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [138][390/391]\tTime  0.082 ( 0.097)\tLoss 7.5560e-03 (9.7646e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.944 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 78.020 || Acc@5 93.980\n",
            "==> 40.41 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 139, lr: 0.0008000000000000003 -----\n",
            "Epoch: [139][  0/391]\tTime  0.291 ( 0.291)\tLoss 1.2275e-02 (1.2275e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [139][ 30/391]\tTime  0.080 ( 0.101)\tLoss 6.2594e-03 (8.9957e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [139][ 60/391]\tTime  0.086 ( 0.098)\tLoss 1.8512e-02 (9.7048e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [139][ 90/391]\tTime  0.092 ( 0.097)\tLoss 1.1559e-02 (9.3849e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [139][120/391]\tTime  0.092 ( 0.096)\tLoss 6.1417e-03 (9.2233e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [139][150/391]\tTime  0.089 ( 0.096)\tLoss 9.0004e-03 (9.2093e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [139][180/391]\tTime  0.092 ( 0.095)\tLoss 8.9661e-03 (9.3559e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [139][210/391]\tTime  0.091 ( 0.095)\tLoss 8.7277e-03 (9.5852e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [139][240/391]\tTime  0.093 ( 0.095)\tLoss 7.0890e-03 (9.6204e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [139][270/391]\tTime  0.097 ( 0.095)\tLoss 6.8746e-03 (9.5346e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [139][300/391]\tTime  0.094 ( 0.095)\tLoss 7.0500e-03 (9.5429e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [139][330/391]\tTime  0.092 ( 0.095)\tLoss 6.3626e-03 (9.4459e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [139][360/391]\tTime  0.083 ( 0.095)\tLoss 1.0025e-02 (9.4352e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [139][390/391]\tTime  0.082 ( 0.095)\tLoss 1.3190e-02 (9.3636e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.952 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 78.030 || Acc@5 93.950\n",
            "==> 39.60 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 140, lr: 0.0008000000000000003 -----\n",
            "Epoch: [140][  0/391]\tTime  0.309 ( 0.309)\tLoss 7.9339e-03 (7.9339e-03)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [140][ 30/391]\tTime  0.096 ( 0.102)\tLoss 6.7453e-03 (9.1237e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [140][ 60/391]\tTime  0.080 ( 0.098)\tLoss 6.2853e-03 (9.2897e-03)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [140][ 90/391]\tTime  0.096 ( 0.097)\tLoss 7.4173e-03 (9.1628e-03)\tAcc@1 100.00 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [140][120/391]\tTime  0.095 ( 0.096)\tLoss 1.0701e-02 (9.2433e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [140][150/391]\tTime  0.100 ( 0.096)\tLoss 1.1382e-02 (9.3975e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [140][180/391]\tTime  0.096 ( 0.096)\tLoss 7.4494e-03 (9.5327e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [140][210/391]\tTime  0.096 ( 0.096)\tLoss 8.8772e-03 (9.4126e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [140][240/391]\tTime  0.079 ( 0.095)\tLoss 6.9610e-03 (9.4975e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [140][270/391]\tTime  0.091 ( 0.095)\tLoss 1.2084e-02 (9.5548e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [140][300/391]\tTime  0.094 ( 0.095)\tLoss 7.2929e-03 (9.6319e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [140][330/391]\tTime  0.092 ( 0.095)\tLoss 1.0424e-02 (9.5648e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [140][360/391]\tTime  0.092 ( 0.095)\tLoss 6.6417e-03 (9.4759e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [140][390/391]\tTime  0.082 ( 0.095)\tLoss 1.0360e-02 (9.5074e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.942 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.990 || Acc@5 94.020\n",
            "==> 39.56 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 141, lr: 0.0008000000000000003 -----\n",
            "Epoch: [141][  0/391]\tTime  0.294 ( 0.294)\tLoss 2.1403e-02 (2.1403e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [141][ 30/391]\tTime  0.091 ( 0.102)\tLoss 7.3730e-03 (9.5398e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [141][ 60/391]\tTime  0.096 ( 0.098)\tLoss 6.1814e-03 (8.9573e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [141][ 90/391]\tTime  0.092 ( 0.097)\tLoss 6.9442e-03 (9.0976e-03)\tAcc@1 100.00 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [141][120/391]\tTime  0.094 ( 0.096)\tLoss 1.1023e-02 (9.3759e-03)\tAcc@1 100.00 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [141][150/391]\tTime  0.084 ( 0.096)\tLoss 6.7055e-03 (9.3366e-03)\tAcc@1 100.00 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [141][180/391]\tTime  0.083 ( 0.096)\tLoss 7.2650e-03 (9.2929e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [141][210/391]\tTime  0.094 ( 0.095)\tLoss 6.3975e-03 (9.1715e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [141][240/391]\tTime  0.097 ( 0.095)\tLoss 9.5125e-03 (9.3034e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [141][270/391]\tTime  0.096 ( 0.095)\tLoss 2.0200e-02 (9.3572e-03)\tAcc@1  98.44 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [141][300/391]\tTime  0.092 ( 0.095)\tLoss 9.8123e-03 (9.4643e-03)\tAcc@1 100.00 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [141][330/391]\tTime  0.090 ( 0.095)\tLoss 8.7433e-03 (9.3918e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [141][360/391]\tTime  0.092 ( 0.095)\tLoss 1.4746e-02 (9.3951e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [141][390/391]\tTime  0.082 ( 0.095)\tLoss 1.0055e-02 (9.4488e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.938 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.940 || Acc@5 94.030\n",
            "==> 39.62 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 142, lr: 0.0008000000000000003 -----\n",
            "Epoch: [142][  0/391]\tTime  0.302 ( 0.302)\tLoss 1.5181e-02 (1.5181e-02)\tAcc@1  99.22 ( 99.22)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [142][ 30/391]\tTime  0.095 ( 0.102)\tLoss 8.8051e-03 (9.4859e-03)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [142][ 60/391]\tTime  0.091 ( 0.098)\tLoss 9.2080e-03 (9.0139e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [142][ 90/391]\tTime  0.104 ( 0.097)\tLoss 6.2788e-03 (9.4728e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [142][120/391]\tTime  0.085 ( 0.097)\tLoss 7.5135e-03 (9.5880e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [142][150/391]\tTime  0.110 ( 0.096)\tLoss 1.0915e-02 (9.4446e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [142][180/391]\tTime  0.089 ( 0.096)\tLoss 8.2501e-03 (9.4318e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [142][210/391]\tTime  0.096 ( 0.095)\tLoss 9.9143e-03 (9.3667e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [142][240/391]\tTime  0.088 ( 0.095)\tLoss 7.9511e-03 (9.3057e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [142][270/391]\tTime  0.092 ( 0.095)\tLoss 5.0559e-03 (9.3261e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [142][300/391]\tTime  0.095 ( 0.095)\tLoss 1.4041e-02 (9.2605e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [142][330/391]\tTime  0.095 ( 0.095)\tLoss 7.7461e-03 (9.2137e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [142][360/391]\tTime  0.096 ( 0.095)\tLoss 7.5640e-03 (9.2278e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [142][390/391]\tTime  0.082 ( 0.094)\tLoss 1.3816e-02 (9.2576e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.958 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 78.060 || Acc@5 94.000\n",
            "==> 39.51 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 143, lr: 0.0008000000000000003 -----\n",
            "Epoch: [143][  0/391]\tTime  0.326 ( 0.326)\tLoss 7.8443e-03 (7.8443e-03)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [143][ 30/391]\tTime  0.085 ( 0.103)\tLoss 8.1718e-03 (9.3673e-03)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [143][ 60/391]\tTime  0.080 ( 0.099)\tLoss 6.6478e-03 (9.5000e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [143][ 90/391]\tTime  0.093 ( 0.097)\tLoss 6.5377e-03 (9.4749e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [143][120/391]\tTime  0.095 ( 0.097)\tLoss 7.1895e-03 (9.4627e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [143][150/391]\tTime  0.092 ( 0.096)\tLoss 7.1717e-03 (9.5191e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [143][180/391]\tTime  0.096 ( 0.096)\tLoss 7.6099e-03 (9.6427e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [143][210/391]\tTime  0.097 ( 0.096)\tLoss 8.4225e-03 (9.4665e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [143][240/391]\tTime  0.087 ( 0.096)\tLoss 6.9217e-03 (9.3753e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [143][270/391]\tTime  0.090 ( 0.095)\tLoss 1.0042e-02 (9.3797e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [143][300/391]\tTime  0.106 ( 0.095)\tLoss 6.4873e-03 (9.5829e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [143][330/391]\tTime  0.091 ( 0.095)\tLoss 7.4743e-03 (9.5810e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [143][360/391]\tTime  0.092 ( 0.095)\tLoss 1.1680e-02 (9.5447e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [143][390/391]\tTime  0.081 ( 0.095)\tLoss 1.2504e-02 (9.5430e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.954 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 78.120 || Acc@5 94.040\n",
            "==> 39.45 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 144, lr: 0.0008000000000000003 -----\n",
            "Epoch: [144][  0/391]\tTime  0.279 ( 0.279)\tLoss 7.9232e-03 (7.9232e-03)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [144][ 30/391]\tTime  0.095 ( 0.102)\tLoss 8.7269e-03 (9.4875e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [144][ 60/391]\tTime  0.094 ( 0.097)\tLoss 7.1328e-03 (9.1954e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [144][ 90/391]\tTime  0.095 ( 0.096)\tLoss 8.8327e-03 (9.7024e-03)\tAcc@1 100.00 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [144][120/391]\tTime  0.094 ( 0.095)\tLoss 6.5386e-03 (9.6510e-03)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [144][150/391]\tTime  0.101 ( 0.095)\tLoss 1.1187e-02 (9.4512e-03)\tAcc@1 100.00 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [144][180/391]\tTime  0.094 ( 0.094)\tLoss 1.2906e-02 (9.4670e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [144][210/391]\tTime  0.094 ( 0.094)\tLoss 9.7172e-03 (9.3533e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [144][240/391]\tTime  0.096 ( 0.094)\tLoss 9.8987e-03 (9.2819e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [144][270/391]\tTime  0.092 ( 0.094)\tLoss 7.6640e-03 (9.2558e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [144][300/391]\tTime  0.083 ( 0.094)\tLoss 6.7165e-03 (9.3161e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [144][330/391]\tTime  0.090 ( 0.094)\tLoss 1.5927e-02 (9.3373e-03)\tAcc@1  99.22 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [144][360/391]\tTime  0.097 ( 0.094)\tLoss 5.7630e-03 (9.3027e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [144][390/391]\tTime  0.082 ( 0.094)\tLoss 8.6666e-03 (9.3195e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.938 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 78.010 || Acc@5 94.000\n",
            "==> 39.19 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 145, lr: 0.0008000000000000003 -----\n",
            "Epoch: [145][  0/391]\tTime  0.291 ( 0.291)\tLoss 1.2881e-02 (1.2881e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [145][ 30/391]\tTime  0.095 ( 0.101)\tLoss 8.3395e-03 (1.0077e-02)\tAcc@1 100.00 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [145][ 60/391]\tTime  0.089 ( 0.096)\tLoss 9.5451e-03 (1.0375e-02)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [145][ 90/391]\tTime  0.102 ( 0.095)\tLoss 1.0741e-02 (1.0020e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [145][120/391]\tTime  0.092 ( 0.094)\tLoss 9.4101e-03 (9.8639e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [145][150/391]\tTime  0.091 ( 0.094)\tLoss 4.9028e-03 (9.7580e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [145][180/391]\tTime  0.087 ( 0.094)\tLoss 6.0179e-03 (9.5730e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [145][210/391]\tTime  0.103 ( 0.094)\tLoss 9.3276e-03 (9.7182e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [145][240/391]\tTime  0.094 ( 0.094)\tLoss 1.0769e-02 (9.5765e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [145][270/391]\tTime  0.084 ( 0.093)\tLoss 1.8866e-02 (9.6437e-03)\tAcc@1  99.22 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [145][300/391]\tTime  0.092 ( 0.093)\tLoss 9.1856e-03 (9.6710e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [145][330/391]\tTime  0.091 ( 0.093)\tLoss 6.6047e-03 (9.6958e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [145][360/391]\tTime  0.092 ( 0.093)\tLoss 1.1715e-02 (9.6210e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [145][390/391]\tTime  0.082 ( 0.093)\tLoss 6.3516e-03 (9.5374e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.950 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 78.060 || Acc@5 94.070\n",
            "==> 38.91 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 146, lr: 0.0008000000000000003 -----\n",
            "Epoch: [146][  0/391]\tTime  0.285 ( 0.285)\tLoss 5.9158e-03 (5.9158e-03)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [146][ 30/391]\tTime  0.085 ( 0.100)\tLoss 8.6736e-03 (8.8751e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [146][ 60/391]\tTime  0.090 ( 0.096)\tLoss 7.0565e-03 (9.0649e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [146][ 90/391]\tTime  0.104 ( 0.095)\tLoss 1.5600e-02 (8.9508e-03)\tAcc@1  99.22 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [146][120/391]\tTime  0.095 ( 0.095)\tLoss 8.1801e-03 (8.8429e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [146][150/391]\tTime  0.091 ( 0.095)\tLoss 6.9964e-03 (8.7744e-03)\tAcc@1 100.00 ( 99.98)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [146][180/391]\tTime  0.095 ( 0.094)\tLoss 1.2947e-02 (8.9109e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [146][210/391]\tTime  0.088 ( 0.094)\tLoss 7.2070e-03 (8.8571e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [146][240/391]\tTime  0.091 ( 0.094)\tLoss 5.8134e-03 (9.0663e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [146][270/391]\tTime  0.091 ( 0.094)\tLoss 9.7302e-03 (9.3516e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [146][300/391]\tTime  0.087 ( 0.094)\tLoss 1.3146e-02 (9.2741e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [146][330/391]\tTime  0.095 ( 0.094)\tLoss 1.5151e-02 (9.1722e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [146][360/391]\tTime  0.091 ( 0.094)\tLoss 7.2247e-03 (9.1744e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [146][390/391]\tTime  0.082 ( 0.093)\tLoss 1.3322e-02 (9.2479e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.954 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.900 || Acc@5 94.080\n",
            "==> 39.04 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 147, lr: 0.0008000000000000003 -----\n",
            "Epoch: [147][  0/391]\tTime  0.285 ( 0.285)\tLoss 9.9876e-03 (9.9876e-03)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [147][ 30/391]\tTime  0.094 ( 0.100)\tLoss 7.2010e-03 (9.4796e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [147][ 60/391]\tTime  0.105 ( 0.097)\tLoss 1.0026e-02 (9.6501e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [147][ 90/391]\tTime  0.086 ( 0.096)\tLoss 7.2316e-03 (9.1000e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [147][120/391]\tTime  0.091 ( 0.095)\tLoss 7.7029e-03 (9.2956e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [147][150/391]\tTime  0.090 ( 0.095)\tLoss 1.0343e-02 (9.3291e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [147][180/391]\tTime  0.093 ( 0.094)\tLoss 6.4700e-03 (9.2272e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [147][210/391]\tTime  0.095 ( 0.094)\tLoss 9.5141e-03 (9.3259e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [147][240/391]\tTime  0.093 ( 0.094)\tLoss 6.7956e-03 (9.3005e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [147][270/391]\tTime  0.093 ( 0.094)\tLoss 1.0747e-02 (9.2872e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [147][300/391]\tTime  0.103 ( 0.094)\tLoss 1.7671e-02 (9.2984e-03)\tAcc@1  99.22 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [147][330/391]\tTime  0.093 ( 0.094)\tLoss 6.3079e-03 (9.2790e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [147][360/391]\tTime  0.090 ( 0.094)\tLoss 1.3140e-02 (9.2706e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [147][390/391]\tTime  0.082 ( 0.094)\tLoss 8.2424e-03 (9.2530e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.956 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.940 || Acc@5 93.940\n",
            "==> 39.12 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 148, lr: 0.0008000000000000003 -----\n",
            "Epoch: [148][  0/391]\tTime  0.291 ( 0.291)\tLoss 8.3583e-03 (8.3583e-03)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [148][ 30/391]\tTime  0.093 ( 0.100)\tLoss 8.9969e-03 (1.1469e-02)\tAcc@1 100.00 ( 99.85)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [148][ 60/391]\tTime  0.097 ( 0.097)\tLoss 1.2161e-02 (1.0009e-02)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [148][ 90/391]\tTime  0.093 ( 0.095)\tLoss 6.7669e-03 (9.5719e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [148][120/391]\tTime  0.094 ( 0.094)\tLoss 1.7408e-02 (9.4320e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [148][150/391]\tTime  0.088 ( 0.094)\tLoss 5.3294e-03 (9.6353e-03)\tAcc@1 100.00 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [148][180/391]\tTime  0.097 ( 0.094)\tLoss 4.2439e-03 (9.6067e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [148][210/391]\tTime  0.092 ( 0.094)\tLoss 1.4517e-02 (9.5751e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [148][240/391]\tTime  0.105 ( 0.094)\tLoss 6.6562e-03 (9.6090e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [148][270/391]\tTime  0.090 ( 0.093)\tLoss 1.0536e-02 (9.5627e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [148][300/391]\tTime  0.090 ( 0.093)\tLoss 6.6998e-03 (9.5386e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [148][330/391]\tTime  0.091 ( 0.093)\tLoss 1.1177e-02 (9.5110e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [148][360/391]\tTime  0.091 ( 0.093)\tLoss 5.5790e-03 (9.4893e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [148][390/391]\tTime  0.082 ( 0.093)\tLoss 9.1726e-03 (9.4403e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.948 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 78.090 || Acc@5 93.840\n",
            "==> 38.95 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 149, lr: 0.0008000000000000003 -----\n",
            "Epoch: [149][  0/391]\tTime  0.285 ( 0.285)\tLoss 7.6817e-03 (7.6817e-03)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [149][ 30/391]\tTime  0.089 ( 0.100)\tLoss 6.4218e-03 (8.3672e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [149][ 60/391]\tTime  0.096 ( 0.097)\tLoss 1.2471e-02 (8.9430e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [149][ 90/391]\tTime  0.091 ( 0.095)\tLoss 7.4472e-03 (9.0145e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [149][120/391]\tTime  0.096 ( 0.095)\tLoss 6.0478e-03 (8.9241e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [149][150/391]\tTime  0.087 ( 0.095)\tLoss 8.6253e-03 (8.8326e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [149][180/391]\tTime  0.092 ( 0.094)\tLoss 1.0173e-02 (8.8823e-03)\tAcc@1 100.00 ( 99.98)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [149][210/391]\tTime  0.091 ( 0.094)\tLoss 4.9496e-03 (8.9011e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [149][240/391]\tTime  0.089 ( 0.094)\tLoss 8.1046e-03 (8.8154e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [149][270/391]\tTime  0.093 ( 0.094)\tLoss 6.1766e-03 (8.7976e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [149][300/391]\tTime  0.094 ( 0.094)\tLoss 7.2124e-03 (8.9876e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [149][330/391]\tTime  0.087 ( 0.094)\tLoss 6.8999e-03 (9.0523e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [149][360/391]\tTime  0.087 ( 0.093)\tLoss 8.2258e-03 (9.0949e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [149][390/391]\tTime  0.081 ( 0.093)\tLoss 7.4810e-03 (9.1673e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.954 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 78.070 || Acc@5 94.030\n",
            "==> 38.97 seconds to train this epoch\n",
            "\n",
            "Best Top-1 Accuracy: 78.12\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}